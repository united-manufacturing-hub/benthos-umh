{
  "$id": "https://github.com/united-manufacturing-hub/benthos-umh/schemas/benthos-v0.11.6.json",
  "$schema": "http://json-schema.org/draft-07/schema#",
  "definitions": {
    "ads": {
      "description": "This input plugin enables Benthos to read data directly from Beckhoff PLCs using the ADS protocol. Configure the plugin by specifying the PLC's IP address, runtime port, target AMS net ID, etc. etc, add more here.",
      "properties": {
        "cycleTime": {
          "default": 1000,
          "description": "Requested read interval time for PLC to scan for changes if read type notification, in milliseconds.",
          "type": "number"
        },
        "hostAMS": {
          "default": "auto",
          "description": "The host AMS net ID, use auto (default) to automatically derive AMS from host IP. Enter manually if auto not working",
          "type": "string"
        },
        "hostPort": {
          "default": 10500,
          "description": "Host port. Default 48898 (Twincat 2)",
          "type": "number"
        },
        "intervalTime": {
          "default": 1000,
          "description": "The interval time between reads milliseconds for read requests.",
          "type": "number"
        },
        "logLevel": {
          "default": "disabled",
          "description": "Log level for ADS connection. Default disabled",
          "type": "string"
        },
        "maxDelay": {
          "default": 100,
          "description": "Max delay time after value change before PLC should send message, in milliseconds. Default 100",
          "type": "number"
        },
        "readType": {
          "default": "notification",
          "description": "Read type, interval or notification (default)",
          "type": "string"
        },
        "runtimePort": {
          "default": 801,
          "description": "Target runtime port. Default 801(Twincat 2)",
          "type": "number"
        },
        "symbols": {
          "description": "List of symbols to read in the format 'function.name', e.g., 'MAIN.counter', '.globalCounter' If using custom max delay and cycle time for a symbol the format is 'function.name:maxDelay:cycleTime', e.g,. 'MAIN.counter:0:100', '.globalCounter:100:10'",
          "type": "string"
        },
        "targetAMS": {
          "description": "Target AMS net ID.",
          "type": "string"
        },
        "targetIP": {
          "description": "IP address of the Beckhoff PLC.",
          "type": "string"
        },
        "targetPort": {
          "default": 48898,
          "description": "Target port. Default 48898 (Twincat 2)",
          "type": "number"
        },
        "upperCase": {
          "default": true,
          "description": "Convert symbol names to uppercase(needed on some older PLCs). Default true ",
          "type": "boolean"
        }
      },
      "required": [
        "maxDelay",
        "intervalTime",
        "upperCase",
        "symbols",
        "targetAMS",
        "targetPort",
        "hostPort",
        "readType",
        "cycleTime",
        "logLevel",
        "targetIP",
        "runtimePort",
        "hostAMS"
      ],
      "type": "object"
    },
    "alarm": {
      "description": "This processor plugin enables Benthos to send data when specific conditions are met. Configure the plugin by specifying the alarm value, reset value, operator and reset operator.",
      "properties": {
        "addMeta": {
          "default": false,
          "description": "Add existing metadata to message",
          "type": "boolean"
        },
        "addToJson": {
          "default": false,
          "description": "Add the alarm to the json structure",
          "type": "boolean"
        },
        "addValue": {
          "default": false,
          "description": "Add the current value to the alarm text",
          "type": "boolean"
        },
        "alarmJsonStruct": {
          "default": "",
          "description": "specific json struct for output. Default ''",
          "type": "string"
        },
        "alarmObject": {
          "default": "alarm",
          "description": "Name of the json object for the alarm. Default 'alarm'",
          "type": "string"
        },
        "alarmText": {
          "default": "Alarm",
          "description": "Alarm text to be added to the alarm. Default 'Alarm'",
          "type": "string"
        },
        "cleanMsg": {
          "default": true,
          "description": "Create a new clean msg with alarmtext only",
          "type": "boolean"
        },
        "filterTime": {
          "default": "0s",
          "description": "Time filter before trigger. Default 0s",
          "type": "string"
        },
        "json": {
          "default": "",
          "description": "tag name is value is json)",
          "type": "string"
        },
        "operator": {
          "default": "\u003e",
          "description": "allowed operators: \u003c,\u003e,=",
          "type": "string"
        },
        "reset": {
          "default": 0,
          "description": "reset value",
          "type": "number"
        },
        "resetOperator": {
          "default": "\u003c",
          "description": "reset operator",
          "type": "string"
        },
        "sendAlarmOnly": {
          "default": true,
          "description": "Block all messages except alarm",
          "type": "boolean"
        },
        "sendInterval": {
          "default": "0s",
          "description": "Interval time before resending alarm. Default 0s",
          "type": "string"
        },
        "stringValue": {
          "default": "",
          "description": "Alarm value if using string)",
          "type": "string"
        },
        "value": {
          "default": 100,
          "description": "Alarm value, default '100'",
          "type": "number"
        }
      },
      "required": [
        "addToJson",
        "addValue",
        "json",
        "stringValue",
        "resetOperator",
        "sendInterval",
        "value",
        "sendAlarmOnly",
        "filterTime",
        "alarmText",
        "alarmObject",
        "alarmJsonStruct",
        "cleanMsg",
        "addMeta",
        "operator",
        "reset"
      ],
      "type": "object"
    },
    "amqp_0_9": {
      "description": "The metadata from each message are delivered as headers.\n\nIt's possible for this output type to create the target exchange by setting `exchange_declare.enabled` to `true`, if the exchange already exists then the declaration passively verifies that the settings match.\n\nTLS is automatic when connecting to an `amqps` URL, but custom settings can be enabled in the `tls` section.\n\nThe fields 'key', 'exchange' and 'type' can be dynamically set using xref:configuration:interpolation.adoc#bloblang-queries[function interpolations].",
      "properties": {
        "app_id": {
          "default": "",
          "description": "Set the application ID of each message with a dynamic interpolated expression.",
          "type": "string",
          "x-advanced": true
        },
        "content_encoding": {
          "default": "",
          "description": "The content encoding attribute to set for each message.",
          "type": "string",
          "x-advanced": true
        },
        "content_type": {
          "default": "application/octet-stream",
          "description": "The content type attribute to set for each message.",
          "type": "string",
          "x-advanced": true
        },
        "correlation_id": {
          "default": "",
          "description": "Set the correlation ID of each message with a dynamic interpolated expression.",
          "type": "string",
          "x-advanced": true
        },
        "exchange": {
          "description": "An AMQP exchange to publish to.",
          "type": "string"
        },
        "exchange_declare": {
          "description": "Optionally declare the target exchange (passive).",
          "properties": {
            "arguments": {
              "description": "Optional arguments specific to the server's implementation of the exchange that can be sent for exchange types which require extra parameters.",
              "type": "string",
              "x-advanced": true
            },
            "durable": {
              "default": true,
              "description": "Whether the exchange should be durable.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to declare the exchange.",
              "type": "boolean",
              "x-advanced": true
            },
            "type": {
              "default": "direct",
              "description": "The type of the exchange.",
              "enum": [
                "direct",
                "fanout",
                "topic",
                "x-custom"
              ],
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "type",
            "durable"
          ],
          "type": "object",
          "x-advanced": true
        },
        "expiration": {
          "default": "",
          "description": "Set the per-message TTL",
          "type": "string",
          "x-advanced": true
        },
        "immediate": {
          "default": false,
          "description": "Whether to set the immediate flag on published messages. When set if there are no ready consumers of a queue then the message is dropped instead of waiting.",
          "type": "boolean",
          "x-advanced": true
        },
        "key": {
          "default": "",
          "description": "The binding key to set for each message.",
          "type": "string"
        },
        "mandatory": {
          "default": false,
          "description": "Whether to set the mandatory flag on published messages. When set if a published message is routed to zero queues it is returned.",
          "type": "boolean",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "message_id": {
          "default": "",
          "description": "Set the message ID of each message with a dynamic interpolated expression.",
          "type": "string",
          "x-advanced": true
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are attached to messages as headers.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "persistent": {
          "default": false,
          "description": "Whether message delivery should be persistent (transient by default).",
          "type": "boolean",
          "x-advanced": true
        },
        "priority": {
          "default": "",
          "description": "Set the priority of each message with a dynamic interpolated expression.",
          "type": "string",
          "x-advanced": true
        },
        "reply_to": {
          "default": "",
          "description": "Carries response queue name - set with a dynamic interpolated expression.",
          "type": "string",
          "x-advanced": true
        },
        "timeout": {
          "default": "",
          "description": "The maximum period to wait before abandoning it and reattempting. If not set, wait indefinitely.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "type": {
          "default": "",
          "description": "The type property to set for each message.",
          "type": "string"
        },
        "urls": {
          "description": "A list of URLs to connect to. The first URL to successfully establish a connection will be used until the connection is closed. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        },
        "user_id": {
          "default": "",
          "description": "Set the user ID to the name of the publisher.  If this property is set by a publisher, its value must be equal to the name of the user used to open the connection.",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "exchange",
        "type",
        "content_type",
        "content_encoding",
        "reply_to",
        "user_id",
        "persistent",
        "correlation_id",
        "expiration",
        "message_id",
        "app_id",
        "metadata",
        "priority",
        "mandatory",
        "timeout",
        "max_in_flight",
        "tls",
        "urls",
        "key",
        "immediate"
      ],
      "type": "object"
    },
    "amqp_1": {
      "description": "\n== Metadata\n\nMessage metadata is added to each AMQP message as string annotations. In order to control which metadata keys are added use the `metadata` config field.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "application_properties_map": {
          "description": "An optional Bloblang mapping that can be defined in order to set the `application-properties` on output messages.",
          "type": "string",
          "x-advanced": true
        },
        "content_type": {
          "default": "opaque_binary",
          "description": "Specify the message body content type. The option `string` will transfer the message as an AMQP value of type string. Consider choosing the option `string` if your intention is to transfer UTF-8 string messages (like JSON messages) to the destination.",
          "enum": [
            "opaque_binary",
            "string"
          ],
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are attached to messages as headers.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "sasl": {
          "description": "Enables SASL authentication.",
          "properties": {
            "mechanism": {
              "default": "none",
              "description": "The SASL authentication mechanism to use.",
              "type": "string",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A SASL plain text password. It is recommended that you use environment variables to populate this field.",
              "type": "string",
              "x-advanced": true
            },
            "user": {
              "default": "",
              "description": "A SASL plain text username. It is recommended that you use environment variables to populate this field.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "mechanism",
            "user",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "target_address": {
          "description": "The target address to write to.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "A URL to connect to.",
          "type": "string"
        },
        "urls": {
          "description": "A list of URLs to connect to. The first URL to successfully establish a connection will be used until the connection is closed. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "target_address",
        "tls",
        "content_type",
        "max_in_flight",
        "metadata"
      ],
      "type": "object"
    },
    "archive": {
      "description": "\nSome archive formats (such as tar, zip) treat each archive item (message part) as a file with a path. Since message parts only contain raw data a unique path must be generated for each part. This can be done by using function interpolations on the 'path' field as described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries]. For types that aren't file based (such as binary) the file field is ignored.\n\nThe resulting archived message adopts the metadata of the _first_ message part of the batch.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "format": {
          "description": "The archiving format to apply.",
          "type": "string"
        },
        "path": {
          "default": "",
          "description": "The path to set for each message in the archive (when applicable).",
          "type": "string"
        }
      },
      "required": [
        "format",
        "path"
      ],
      "type": "object"
    },
    "avro": {
      "description": "\nWARNING: If you are consuming or generating messages using a schema registry service then it is likely this processor will fail as those services require messages to be prefixed with the identifier of the schema version being used. Instead, try the xref:components:processors/schema_registry_encode.adoc[`schema_registry_encode`] and xref:components:processors/schema_registry_decode.adoc[`schema_registry_decode`] processors.\n\n== Operators\n\n=== `to_json`\n\nConverts Avro documents into a JSON structure. This makes it easier to\nmanipulate the contents of the document within Benthos. The encoding field\nspecifies how the source documents are encoded.\n\n=== `from_json`\n\nAttempts to convert JSON documents into Avro documents according to the\nspecified encoding.",
      "properties": {
        "encoding": {
          "default": "textual",
          "description": "An Avro encoding format to use for conversions to and from a schema.",
          "enum": [
            "textual",
            "binary",
            "single"
          ],
          "type": "string"
        },
        "operator": {
          "description": "The \u003c\u003coperators, operator\u003e\u003e to execute",
          "enum": [
            "to_json",
            "from_json"
          ],
          "type": "string"
        },
        "schema": {
          "default": "",
          "description": "A full Avro schema to use.",
          "type": "string"
        },
        "schema_path": {
          "default": "",
          "description": "The path of a schema document to apply. Use either this or the `schema` field.",
          "type": "string"
        }
      },
      "required": [
        "operator",
        "encoding",
        "schema",
        "schema_path"
      ],
      "type": "object"
    },
    "awk": {
      "description": "\nWorks by feeding message contents as the program input based on a chosen \u003c\u003ccodecs,codec\u003e\u003e and replaces the contents of each message with the result. If the result is empty (nothing is printed by the program) then the original message contents remain unchanged.\n\nComes with a wide range of \u003c\u003cawk-functions,custom functions\u003e\u003e for accessing message metadata, json fields, printing logs, etc. These functions can be overridden by functions within the program.\n\nCheck out the \u003c\u003cexamples,examples section\u003e\u003e in order to see how this processor can be used.\n\nThis processor uses https://github.com/benhoyt/goawk[GoAWK^], in order to understand the differences in how the program works you can read more about it in https://github.com/benhoyt/goawk#differences-from-awk[goawk.differences^].",
      "properties": {
        "codec": {
          "description": "A \u003c\u003ccodecs,codec\u003e\u003e defines how messages should be inserted into the AWK program as variables. The codec does not change which \u003c\u003cawk-functions,custom Redpanda Connect functions\u003e\u003e are available. The `text` codec is the closest to a typical AWK use case.",
          "enum": [
            "none",
            "text",
            "json"
          ],
          "type": "string"
        },
        "program": {
          "description": "An AWK program to execute",
          "type": "string"
        }
      },
      "required": [
        "codec",
        "program"
      ],
      "type": "object"
    },
    "aws_dynamodb": {
      "description": "\nThe field `string_columns` is a map of column names to string values, where the values are xref:configuration:interpolation.adoc#bloblang-queries[function interpolated] per message of a batch. This allows you to populate string columns of an item by extracting fields within the document payload or metadata like follows:\n\n```yml\nstring_columns:\n  id: ${!json(\"id\")}\n  title: ${!json(\"body.title\")}\n  topic: ${!meta(\"kafka_topic\")}\n  full_content: ${!content()}\n```\n\nThe field `json_map_columns` is a map of column names to json paths, where the xref:configuration:field_paths.adoc[dot path] is extracted from each document and converted into a map value. Both an empty path and the path `.` are interpreted as the root of the document. This allows you to populate map columns of an item like follows:\n\n```yml\njson_map_columns:\n  user: path.to.user\n  whole_document: .\n```\n\nA column name can be empty:\n\n```yml\njson_map_columns:\n  \"\": .\n```\n\nIn which case the top level document fields will be written at the root of the item, potentially overwriting previously defined column values. If a path is not found within a document the column will not be populated.\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].\n",
      "properties": {
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "1s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "30s",
              "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "5s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "json_map_columns": {
          "default": {},
          "description": "A map of column keys to xref:configuration:field_paths.adoc[field paths] pointing to value data within messages.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "max_retries": {
          "default": 3,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "string_columns": {
          "default": {},
          "description": "A map of column keys to string values to store.",
          "type": "string"
        },
        "table": {
          "description": "The table to store messages in.",
          "type": "string"
        },
        "ttl": {
          "default": "",
          "description": "An optional TTL to set for items, calculated from the moment the message is sent.",
          "type": "string",
          "x-advanced": true
        },
        "ttl_key": {
          "default": "",
          "description": "The column key to place the TTL value within.",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "table",
        "ttl_key",
        "max_in_flight",
        "batching",
        "endpoint",
        "backoff",
        "string_columns",
        "json_map_columns",
        "ttl",
        "region",
        "credentials",
        "max_retries"
      ],
      "type": "object"
    },
    "aws_dynamodb_partiql": {
      "description": "Both writes or reads are supported, when the query is a read the contents of the message will be replaced with the result. This processor is more efficient when messages are pre-batched as the whole batch will be executed in a single call.",
      "properties": {
        "args_mapping": {
          "default": "",
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that, for each message, creates a list of arguments to use with the query.",
          "type": "string"
        },
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "query": {
          "description": "A PartiQL query to execute for each message.",
          "type": "string"
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "unsafe_dynamic_query": {
          "default": false,
          "description": "Whether to enable dynamic queries that support interpolation functions.",
          "type": "boolean",
          "x-advanced": true
        }
      },
      "required": [
        "endpoint",
        "credentials",
        "query",
        "unsafe_dynamic_query",
        "args_mapping",
        "region"
      ],
      "type": "object"
    },
    "aws_kinesis": {
      "description": "\nBoth the `partition_key`(required) and `hash_key` (optional) fields can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages the interpolations are performed per message part.\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "1s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "30s",
              "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "5s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "hash_key": {
          "description": "A optional hash key for partitioning messages.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of parallel message batches to have in flight at any given time.",
          "type": "number"
        },
        "max_retries": {
          "default": 0,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "partition_key": {
          "description": "A required key for partitioning messages.",
          "type": "string"
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "stream": {
          "description": "The stream to publish messages to. Streams can either be specified by their name or full ARN.",
          "type": "string"
        }
      },
      "required": [
        "backoff",
        "max_in_flight",
        "batching",
        "region",
        "stream",
        "partition_key",
        "endpoint",
        "credentials",
        "max_retries"
      ],
      "type": "object"
    },
    "aws_kinesis_firehose": {
      "description": "\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].\n",
      "properties": {
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "1s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "30s",
              "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "5s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "max_retries": {
          "default": 0,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "stream": {
          "description": "The stream to publish messages to.",
          "type": "string"
        }
      },
      "required": [
        "batching",
        "region",
        "endpoint",
        "credentials",
        "max_retries",
        "backoff",
        "stream",
        "max_in_flight"
      ],
      "type": "object"
    },
    "aws_lambda": {
      "description": "The `rate_limit` field can be used to specify a rate limit xref:components:rate_limits/about.adoc[resource] to cap the rate of requests across parallel components service wide.\n\nIn order to map or encode the payload to a specific request body, and map the response back into the original payload instead of replacing it entirely, you can use the xref:components:processors/branch.adoc[`branch` processor].\n\n== Error handling\n\nWhen Redpanda Connect is unable to connect to the AWS endpoint or is otherwise unable to invoke the target lambda function it will retry the request according to the configured number of retries. Once these attempts have been exhausted the failed message will continue through the pipeline with it's contents unchanged, but flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].\n\nHowever, if the invocation of the function is successful but the function itself throws an error, then the message will have it's contents updated with a JSON payload describing the reason for the failure, and a metadata field `lambda_function_error` will be added to the message allowing you to detect and handle function errors with a xref:components:processors/branch.adoc[`branch`]:\n\n```yaml\npipeline:\n  processors:\n    - branch:\n        processors:\n          - aws_lambda:\n              function: foo\n        result_map: |\n          root = if meta().exists(\"lambda_function_error\") {\n            throw(\"Invocation failed due to %v: %v\".format(this.errorType, this.errorMessage))\n          } else {\n            this\n          }\noutput:\n  switch:\n    retry_until_success: false\n    cases:\n      - check: errored()\n        output:\n          reject: ${! error() }\n      - output:\n          resource: somewhere_else\n```\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].",
      "properties": {
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "function": {
          "description": "The function to invoke.",
          "type": "string"
        },
        "parallel": {
          "default": false,
          "description": "Whether messages of a batch should be dispatched in parallel.",
          "type": "boolean"
        },
        "rate_limit": {
          "default": "",
          "description": "An optional xref:components:rate_limits/about.adoc[`rate_limit`] to throttle invocations by.",
          "type": "string",
          "x-advanced": true
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "retries": {
          "default": 3,
          "description": "The maximum number of retry attempts for each message.",
          "type": "number",
          "x-advanced": true
        },
        "timeout": {
          "default": "5s",
          "description": "The maximum period of time to wait before abandoning an invocation.",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "retries",
        "parallel",
        "function",
        "rate_limit",
        "region",
        "endpoint",
        "credentials",
        "timeout"
      ],
      "type": "object"
    },
    "aws_s3": {
      "description": "\nIn order to have a different path for each object you should use function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries], which are calculated per message of a batch.\n\n== Metadata\n\nMetadata fields on messages will be sent as headers, in order to mutate these values (or remove them) check out the xref:configuration:metadata.adoc[metadata docs].\n\n== Tags\n\nThe tags field allows you to specify key/value pairs to attach to objects as tags, where the values support xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]:\n\n```yaml\noutput:\n  aws_s3:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.tar.gz\n    tags:\n      Key1: Value1\n      Timestamp: ${!meta(\"Timestamp\")}\n```\n\n=== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Batching\n\nIt's common to want to upload messages to S3 as batched archives, the easiest way to do this is to batch your messages at the output level and join the batch of messages with an xref:components:processors/archive.adoc[`archive`] and/or xref:components:processors/compress.adoc[`compress`] processor.\n\nFor example, if we wished to upload messages as a .tar.gz archive of documents we could achieve that with the following config:\n\n```yaml\noutput:\n  aws_s3:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.tar.gz\n    batching:\n      count: 100\n      period: 10s\n      processors:\n        - archive:\n            format: tar\n        - compress:\n            algorithm: gzip\n```\n\nAlternatively, if we wished to upload JSON documents as a single large document containing an array of objects we can do that with:\n\n```yaml\noutput:\n  aws_s3:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.json\n    batching:\n      count: 100\n      processors:\n        - archive:\n            format: json_array\n```\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "bucket": {
          "description": "The bucket to upload messages to.",
          "type": "string"
        },
        "cache_control": {
          "default": "",
          "description": "The cache control to set for each object.",
          "type": "string",
          "x-advanced": true
        },
        "checksum_algorithm": {
          "default": "",
          "description": "The algorithm used to create the checksum for each object.",
          "enum": [
            "CRC32",
            "CRC32C",
            "SHA1",
            "SHA256"
          ],
          "type": "string",
          "x-advanced": true
        },
        "content_disposition": {
          "default": "",
          "description": "The content disposition to set for each object.",
          "type": "string",
          "x-advanced": true
        },
        "content_encoding": {
          "default": "",
          "description": "An optional content encoding to set for each object.",
          "type": "string",
          "x-advanced": true
        },
        "content_language": {
          "default": "",
          "description": "The content language to set for each object.",
          "type": "string",
          "x-advanced": true
        },
        "content_md5": {
          "default": "",
          "description": "The content MD5 to set for each object.",
          "type": "string",
          "x-advanced": true
        },
        "content_type": {
          "default": "application/octet-stream",
          "description": "The content type to set for each object.",
          "type": "string"
        },
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "force_path_style_urls": {
          "default": false,
          "description": "Forces the client API to use path style URLs, which helps when connecting to custom endpoints.",
          "type": "boolean",
          "x-advanced": true
        },
        "kms_key_id": {
          "default": "",
          "description": "An optional server side encryption key.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are attached to objects as headers.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "path": {
          "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
          "description": "The path of each message to upload.",
          "type": "string"
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "server_side_encryption": {
          "default": "",
          "description": "An optional server side encryption algorithm.",
          "type": "string",
          "x-advanced": true
        },
        "storage_class": {
          "default": "STANDARD",
          "description": "The storage class to set for each object.",
          "enum": [
            "STANDARD",
            "REDUCED_REDUNDANCY",
            "GLACIER",
            "STANDARD_IA",
            "ONEZONE_IA",
            "INTELLIGENT_TIERING",
            "DEEP_ARCHIVE"
          ],
          "type": "string",
          "x-advanced": true
        },
        "tags": {
          "default": {},
          "description": "Key/value pairs to store with the object as tags.",
          "type": "string"
        },
        "timeout": {
          "default": "5s",
          "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
          "type": "string",
          "x-advanced": true
        },
        "website_redirect_location": {
          "default": "",
          "description": "The website redirect location to set for each object.",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "tags",
        "content_language",
        "content_md5",
        "endpoint",
        "credentials",
        "cache_control",
        "storage_class",
        "kms_key_id",
        "server_side_encryption",
        "force_path_style_urls",
        "max_in_flight",
        "region",
        "checksum_algorithm",
        "bucket",
        "content_type",
        "content_disposition",
        "website_redirect_location",
        "metadata",
        "timeout",
        "batching",
        "path",
        "content_encoding"
      ],
      "type": "object"
    },
    "aws_sns": {
      "description": "\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "message_deduplication_id": {
          "description": "An optional deduplication ID to set for messages.",
          "type": "string"
        },
        "message_group_id": {
          "description": "An optional group ID to set for messages.",
          "type": "string"
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are sent as headers.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "timeout": {
          "default": "5s",
          "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
          "type": "string",
          "x-advanced": true
        },
        "topic_arn": {
          "description": "The topic to publish to.",
          "type": "string"
        }
      },
      "required": [
        "metadata",
        "credentials",
        "topic_arn",
        "max_in_flight",
        "timeout",
        "region",
        "endpoint"
      ],
      "type": "object"
    },
    "aws_sqs": {
      "description": "\nMetadata values are sent along with the payload as attributes with the data type String. If the number of metadata values in a message exceeds the message attribute limit (10) then the top ten keys ordered alphabetically will be selected.\n\nThe fields `message_group_id`, `message_deduplication_id` and `delay_seconds` can be set dynamically using xref:configuration:interpolation.adoc#bloblang-queries[function interpolations], which are resolved individually for each message of a batch.\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to AWS services. It's also possible to set them explicitly at the component level, allowing you to transfer data across accounts. You can find out more in xref:guides:cloud/aws.adoc[].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "1s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "30s",
              "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "5s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "credentials": {
          "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
          "properties": {
            "from_ec2_role": {
              "default": false,
              "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
              "type": "boolean",
              "x-advanced": true
            },
            "id": {
              "default": "",
              "description": "The ID of credentials to use.",
              "type": "string",
              "x-advanced": true
            },
            "profile": {
              "default": "",
              "description": "A profile from `~/.aws/credentials` to use.",
              "type": "string",
              "x-advanced": true
            },
            "role": {
              "default": "",
              "description": "A role ARN to assume.",
              "type": "string",
              "x-advanced": true
            },
            "role_external_id": {
              "default": "",
              "description": "An external ID to provide when assuming a role.",
              "type": "string",
              "x-advanced": true
            },
            "secret": {
              "default": "",
              "description": "The secret for the credentials being used.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token for the credentials being used, required when using short term credentials.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "profile",
            "id",
            "secret",
            "token",
            "from_ec2_role",
            "role",
            "role_external_id"
          ],
          "type": "object",
          "x-advanced": true
        },
        "delay_seconds": {
          "description": "An optional delay time in seconds for message. Value between 0 and 900",
          "type": "string"
        },
        "endpoint": {
          "default": "",
          "description": "Allows you to specify a custom endpoint for the AWS API.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of parallel message batches to have in flight at any given time.",
          "type": "number"
        },
        "max_records_per_request": {
          "default": 10,
          "description": "Customize the maximum number of records delivered in a single SQS request. This value must be greater than 0 but no greater than 10.",
          "type": "number",
          "x-advanced": true
        },
        "max_retries": {
          "default": 0,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "message_deduplication_id": {
          "description": "An optional deduplication ID to set for messages.",
          "type": "string"
        },
        "message_group_id": {
          "description": "An optional group ID to set for messages.",
          "type": "string"
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are sent as headers.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "region": {
          "default": "",
          "description": "The AWS region to target.",
          "type": "string",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target SQS queue.",
          "type": "string"
        }
      },
      "required": [
        "batching",
        "max_records_per_request",
        "region",
        "endpoint",
        "credentials",
        "url",
        "max_in_flight",
        "metadata",
        "max_retries",
        "backoff"
      ],
      "type": "object"
    },
    "azure_blob_storage": {
      "description": "\nIn order to have a different path for each object you should use function\ninterpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are\ncalculated per message of a batch.\n\nSupports multiple authentication methods but only one of the following is required:\n\n- `storage_connection_string`\n- `storage_account` and `storage_access_key`\n- `storage_account` and `storage_sas_token`\n- `storage_account` to access via https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n\nIf multiple are set then the `storage_connection_string` is given priority.\n\nIf the `storage_connection_string` does not contain the `AccountName` parameter, please specify it in the\n`storage_account` field.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "blob_type": {
          "default": "BLOCK",
          "description": "Block and Append blobs are comprized of blocks, and each blob can support up to 50,000 blocks. The default value is `+\"`BLOCK`\"+`.`",
          "enum": [
            "BLOCK",
            "APPEND"
          ],
          "type": "string",
          "x-advanced": true
        },
        "container": {
          "description": "The container for uploading the messages to.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "path": {
          "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
          "description": "The path of each message to upload.",
          "type": "string"
        },
        "public_access_level": {
          "default": "PRIVATE",
          "description": "The container's public access level. The default value is `PRIVATE`.",
          "enum": [
            "PRIVATE",
            "BLOB",
            "CONTAINER"
          ],
          "type": "string",
          "x-advanced": true
        },
        "storage_access_key": {
          "default": "",
          "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_account": {
          "default": "",
          "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_connection_string": {
          "default": "",
          "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
          "type": "string"
        },
        "storage_sas_token": {
          "default": "",
          "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
          "type": "string"
        }
      },
      "required": [
        "public_access_level",
        "storage_access_key",
        "storage_connection_string",
        "storage_sas_token",
        "path",
        "blob_type",
        "max_in_flight",
        "storage_account",
        "container"
      ],
      "type": "object"
    },
    "azure_cosmosdb": {
      "description": "\nWhen creating documents, each message must have the `id` property (case-sensitive) set (or use `auto_id: true`). It is the unique name that identifies the document, that is, no two documents share the same `id` within a logical partition. The `id` field must not exceed 255 characters. https://learn.microsoft.com/en-us/rest/api/cosmos-db/documents[See details^].\n\nThe `partition_keys` field must resolve to the same value(s) across the entire message batch.\n\n\n== Credentials\n\nYou can use one of the following authentication mechanisms:\n\n- Set the `endpoint` field and the `account_key` field\n- Set only the `endpoint` field to use https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n- Set the `connection_string` field\n\n\n== Batching\n\nCosmosDB limits the maximum batch size to 100 messages and the payload must not exceed 2MB (https://learn.microsoft.com/en-us/azure/cosmos-db/concepts-limits#per-request-limits[details here^]).\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "account_key": {
          "description": "Account key.",
          "type": "string"
        },
        "auto_id": {
          "default": true,
          "description": "Automatically set the item `id` field to a random UUID v4. If the `id` field is already set, then it will not be overwritten. Setting this to `false` can improve performance, since the messages will not have to be parsed.",
          "type": "boolean",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "connection_string": {
          "description": "Connection string.",
          "type": "string"
        },
        "container": {
          "description": "Container.",
          "type": "string"
        },
        "database": {
          "description": "Database.",
          "type": "string"
        },
        "endpoint": {
          "description": "CosmosDB endpoint.",
          "type": "string"
        },
        "item_id": {
          "description": "ID of item to replace or delete. Only used by the Replace and Delete operations",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "operation": {
          "default": "Create",
          "description": "Operation.",
          "type": "string"
        },
        "partition_keys_map": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a single partition key value or an array of partition key values of type string, integer or boolean. Currently, hierarchical partition keys are not supported so only one value may be provided.",
          "type": "string"
        },
        "patch_condition": {
          "description": "Patch operation condition.",
          "type": "string",
          "x-advanced": true
        },
        "patch_operations": {
          "description": "Patch operations to be performed when `operation: Patch` .",
          "properties": {
            "operation": {
              "default": "Add",
              "description": "Operation.",
              "type": "string",
              "x-advanced": true
            },
            "path": {
              "description": "Path.",
              "type": "string",
              "x-advanced": true
            },
            "value_map": {
              "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to a value of any type that is supported by CosmosDB.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "operation",
            "path"
          ],
          "type": "object",
          "x-advanced": true
        }
      },
      "required": [
        "database",
        "container",
        "max_in_flight",
        "partition_keys_map",
        "operation",
        "auto_id",
        "batching"
      ],
      "type": "object"
    },
    "azure_data_lake_gen2": {
      "description": "\nIn order to have a different path for each file you should use function\ninterpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are\ncalculated per message of a batch.\n\nSupports multiple authentication methods but only one of the following is required:\n\n- `storage_connection_string`\n- `storage_account` and `storage_access_key`\n- `storage_account` and `storage_sas_token`\n- `storage_account` to access via https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential[DefaultAzureCredential^]\n\nIf multiple are set then the `storage_connection_string` is given priority.\n\nIf the `storage_connection_string` does not contain the `AccountName` parameter, please specify it in the\n`storage_account` field.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "filesystem": {
          "description": "The data lake storage filesystem name for uploading the messages to.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "path": {
          "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
          "description": "The path of each message to upload within the filesystem.",
          "type": "string"
        },
        "storage_access_key": {
          "default": "",
          "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_account": {
          "default": "",
          "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_connection_string": {
          "default": "",
          "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
          "type": "string"
        },
        "storage_sas_token": {
          "default": "",
          "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
          "type": "string"
        }
      },
      "required": [
        "storage_sas_token",
        "filesystem",
        "path",
        "max_in_flight",
        "storage_account",
        "storage_access_key",
        "storage_connection_string"
      ],
      "type": "object"
    },
    "azure_queue_storage": {
      "description": "\nOnly one authentication method is required, `storage_connection_string` or `storage_account` and `storage_access_key`. If both are set then the `storage_connection_string` is given priority.\n\nIn order to set the `queue_name` you can use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are calculated per message of a batch.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of parallel message batches to have in flight at any given time.",
          "type": "number"
        },
        "queue_name": {
          "description": "The name of the target Queue Storage queue.",
          "type": "string"
        },
        "storage_access_key": {
          "default": "",
          "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_account": {
          "default": "",
          "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_connection_string": {
          "default": "",
          "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
          "type": "string"
        },
        "storage_sas_token": {
          "default": "",
          "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
          "type": "string"
        },
        "ttl": {
          "default": "",
          "description": "The TTL of each individual message as a duration string. Defaults to 0, meaning no retention period is set",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "ttl",
        "max_in_flight",
        "batching",
        "storage_account",
        "storage_access_key",
        "storage_connection_string",
        "storage_sas_token",
        "queue_name"
      ],
      "type": "object"
    },
    "azure_table_storage": {
      "description": "\nOnly one authentication method is required, `storage_connection_string` or `storage_account` and `storage_access_key`. If both are set then the `storage_connection_string` is given priority.\n\nIn order to set the `table_name`,  `partition_key` and `row_key` you can use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here], which are calculated per message of a batch.\n\nIf the `properties` are not set in the config, all the `json` fields are marshalled and stored in the table, which will be created if it does not exist.\n\nThe `object` and `array` fields are marshaled as strings. e.g.:\n\nThe JSON message:\n\n```json\n{\n  \"foo\": 55,\n  \"bar\": {\n    \"baz\": \"a\",\n    \"bez\": \"b\"\n  },\n  \"diz\": [\"a\", \"b\"]\n}\n```\n\nWill store in the table the following properties:\n\n```yml\nfoo: '55'\nbar: '{ \"baz\": \"a\", \"bez\": \"b\" }'\ndiz: '[\"a\", \"b\"]'\n```\n\nIt's also possible to use function interpolations to get or transform the properties values, e.g.:\n\n```yml\nproperties:\n  device: '${! json(\"device\") }'\n  timestamp: '${! json(\"timestamp\") }'\n```\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "insert_type": {
          "default": "",
          "description": "Type of insert operation. Valid options are `INSERT`, `INSERT_MERGE` and `INSERT_REPLACE`",
          "enum": [
            "INSERT",
            "INSERT_MERGE",
            "INSERT_REPLACE"
          ],
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of parallel message batches to have in flight at any given time.",
          "type": "number"
        },
        "partition_key": {
          "default": "",
          "description": "The partition key.",
          "type": "string"
        },
        "properties": {
          "default": {},
          "description": "A map of properties to store into the table.",
          "type": "string"
        },
        "row_key": {
          "default": "",
          "description": "The row key.",
          "type": "string"
        },
        "storage_access_key": {
          "default": "",
          "description": "The storage account access key. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_account": {
          "default": "",
          "description": "The storage account to access. This field is ignored if `storage_connection_string` is set.",
          "type": "string"
        },
        "storage_connection_string": {
          "default": "",
          "description": "A storage account connection string. This field is required if `storage_account` and `storage_access_key` / `storage_sas_token` are not set.",
          "type": "string"
        },
        "storage_sas_token": {
          "default": "",
          "description": "The storage account SAS token. This field is ignored if `storage_connection_string` or `storage_access_key` are set.",
          "type": "string"
        },
        "table_name": {
          "description": "The table to store messages into.",
          "type": "string"
        },
        "timeout": {
          "default": "5s",
          "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
          "type": "string",
          "x-advanced": true
        },
        "transaction_type": {
          "default": "INSERT",
          "description": "Type of transaction operation.",
          "enum": [
            "INSERT",
            "INSERT_MERGE",
            "INSERT_REPLACE",
            "UPDATE_MERGE",
            "UPDATE_REPLACE",
            "DELETE"
          ],
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "insert_type",
        "transaction_type",
        "max_in_flight",
        "timeout",
        "storage_account",
        "storage_access_key",
        "partition_key",
        "properties",
        "batching",
        "storage_connection_string",
        "storage_sas_token",
        "table_name",
        "row_key"
      ],
      "type": "object"
    },
    "batched": {
      "description": "Batching at the input level is sometimes useful for processing across micro-batches, and can also sometimes be a useful performance trick. However, most inputs are fine without it so unless you have a specific plan for batching this component is not worth using.",
      "properties": {
        "child": {
          "description": "The child input.",
          "type": "string"
        },
        "policy": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        }
      },
      "required": [
        "policy",
        "child"
      ],
      "type": "object"
    },
    "beanstalkd": {
      "description": "Write messages to a Beanstalkd queue.",
      "properties": {
        "address": {
          "description": "An address to connect to.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase to improve throughput.",
          "type": "number"
        }
      },
      "required": [
        "address",
        "max_in_flight"
      ],
      "type": "object"
    },
    "benchmark": {
      "description": "Logs messages per second and bytes per second of messages that are processed at a regular interval. A summary of the amount of messages processed over the entire lifetime of the processor will also be printed when the processor shuts down.",
      "properties": {
        "count_bytes": {
          "default": true,
          "description": "Whether or not to measure the number of bytes per second of throughput. Counting the number of bytes requires serializing structured data, which can cause an unnecessary performance hit if serialization is not required elsewhere in the pipeline.",
          "type": "boolean"
        },
        "interval": {
          "default": "5s",
          "description": "How often to emit rolling statistics. If set to 0, only a summary will be logged when the processor shuts down.",
          "type": "string"
        }
      },
      "required": [
        "interval",
        "count_bytes"
      ],
      "type": "object"
    },
    "bloblang": {
      "description": "\nBloblang is a powerful language that enables a wide range of mapping, transformation and filtering tasks. For more information see xref:guides:bloblang/about.adoc[].\n\nIf your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"\u003cpath\u003e\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from.\n\n== Component rename\n\nThis processor was recently renamed to the xref:components:processors/mapping.adoc[`mapping` processor] in order to make the purpose of the processor more prominent. It is still valid to use the existing `bloblang` name but eventually it will be deprecated and replaced by the new name in example configs.",
      "type": "object"
    },
    "bounds_check": {
      "description": "Removes messages (and batches) that do not fit within certain size boundaries.",
      "properties": {
        "max_part_size": {
          "default": 1073741824,
          "description": "The maximum size of a message to allow (in bytes)",
          "type": "number"
        },
        "max_parts": {
          "default": 100,
          "description": "The maximum size of message batches to allow (in message count)",
          "type": "number",
          "x-advanced": true
        },
        "min_part_size": {
          "default": 1,
          "description": "The minimum size of a message to allow (in bytes)",
          "type": "number"
        },
        "min_parts": {
          "default": 1,
          "description": "The minimum size of message batches to allow (in message count)",
          "type": "number",
          "x-advanced": true
        }
      },
      "required": [
        "max_part_size",
        "min_part_size",
        "max_parts",
        "min_parts"
      ],
      "type": "object"
    },
    "branch": {
      "description": "\nThis is useful for preserving the original message contents when using processors that would otherwise replace the entire contents.\n\n== Metadata\n\nMetadata fields that are added to messages during branch processing will not be automatically copied into the resulting message. In order to do this you should explicitly declare in your `result_map` either a wholesale copy with `meta = metadata()`, or selective copies with `meta foo = metadata(\"bar\")` and so on. It is also possible to reference the metadata of the origin message in the `result_map` using the xref:guides:bloblang/about.adoc#metadata[`@` operator].\n\n== Error handling\n\nIf the `request_map` fails the child processors will not be executed. If the child processors themselves result in an (uncaught) error then the `result_map` will not be executed. If the `result_map` fails the message will remain unchanged. Under any of these conditions standard xref:configuration:error_handling.adoc[error handling methods] can be used in order to filter, DLQ or recover the failed messages.\n\n== Conditional branching\n\nIf the root of your request map is set to `deleted()` then the branch processors are skipped for the given message, this allows you to conditionally branch messages.",
      "properties": {
        "processors": {
          "description": "A list of processors to apply to mapped requests. When processing message batches the resulting batch must match the size and ordering of the input batch, therefore filtering, grouping should not be performed within these processors.",
          "type": "string"
        },
        "request_map": {
          "default": "",
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how to create a request payload suitable for the child processors of this branch. If left empty then the branch will begin with an exact copy of the origin message (including metadata).",
          "type": "string"
        },
        "result_map": {
          "default": "",
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how the resulting messages from branched processing should be mapped back into the original payload. If left empty the origin message will remain unchanged (including metadata).",
          "type": "string"
        }
      },
      "required": [
        "request_map",
        "processors",
        "result_map"
      ],
      "type": "object"
    },
    "broker": {
      "description": "\nxref:components:processors/about.adoc[Processors] can be listed to apply across individual outputs or all outputs:\n\n```yaml\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n      - resource: foo\n      - resource: bar\n        # Processors only applied to messages sent to bar.\n        processors:\n          - resource: bar_processor\n\n  # Processors applied to messages sent to all brokered outputs.\n  processors:\n    - resource: general_processor\n```",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "copies": {
          "default": 1,
          "description": "The number of copies of each configured output to spawn.",
          "type": "number",
          "x-advanced": true
        },
        "outputs": {
          "description": "A list of child outputs to broker.",
          "type": "string"
        },
        "pattern": {
          "default": "fan_out",
          "description": "The brokering pattern to use.",
          "enum": [
            "fan_out",
            "fan_out_fail_fast",
            "fan_out_sequential",
            "fan_out_sequential_fail_fast",
            "round_robin",
            "greedy"
          ],
          "type": "string"
        }
      },
      "required": [
        "copies",
        "pattern",
        "outputs",
        "batching"
      ],
      "type": "object"
    },
    "cache": {
      "description": "Caches are configured as xref:components:caches/about.adoc[resources], where there's a wide variety to choose from.\n\n:cache-support: aws_dynamodb=certified, aws_s3=certified, file=certified, memcached=certified, memory=certified, nats_kv=certified, redis=certified, ristretto=certified, couchbase=community, mongodb=community, sql=community, multilevel=community, ttlru=community, gcp_cloud_storage=community, lru=community, noop=community\n\nThe `target` field must reference a configured cache resource label like follows:\n\n```yaml\noutput:\n  cache:\n    target: foo\n    key: ${!json(\"document.id\")}\n\ncache_resources:\n  - label: foo\n    memcached:\n      addresses:\n        - localhost:11211\n      default_ttl: 60s\n```\n\nIn order to create a unique `key` value per item you should use function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "key": {
          "default": "${!count(\"items\")}-${!timestamp_unix_nano()}",
          "description": "The key to store messages by, function interpolation should be used in order to derive a unique key for each message.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "target": {
          "description": "The target cache to store messages in.",
          "type": "string"
        },
        "ttl": {
          "description": "The TTL of each individual item as a duration string. After this period an item will be eligible for removal during the next compaction. Not all caches support per-key TTLs, and those that do not will fall back to their generally configured TTL setting.",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "target",
        "key",
        "max_in_flight"
      ],
      "type": "object"
    },
    "cached": {
      "description": "The format of the data when stored within the cache is a custom and versioned schema chosen to balance performance and storage space. It is therefore not possible to point this processor to a cache that is pre-populated with data that this processor has not created itself.",
      "properties": {
        "cache": {
          "description": "The cache resource to read and write processor results from.",
          "type": "string"
        },
        "key": {
          "description": "A key to be resolved for each message, if the key already exists in the cache then the cached result is used, otherwise the processors are applied and the result is cached under this key. The key could be static and therefore apply generally to all messages or it could be an interpolated expression that is potentially unique for each message.",
          "type": "string"
        },
        "processors": {
          "description": "The list of processors whose result will be cached.",
          "type": "string"
        },
        "skip_on": {
          "description": "A condition that can be used to skip caching the results from the processors.",
          "type": "string"
        },
        "ttl": {
          "description": "An optional expiry period to set for each cache entry. Some caches only have a general TTL and will therefore ignore this setting.",
          "type": "string"
        }
      },
      "required": [
        "processors",
        "cache",
        "key"
      ],
      "type": "object"
    },
    "cassandra": {
      "description": "\nQuery arguments can be set using a bloblang array for the fields using the `args_mapping` field.\n\nWhen populating timestamp columns the value must either be a string in ISO 8601 format (2006-01-02T15:04:05Z07:00), or an integer representing unix time in seconds.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "addresses": {
          "description": "A list of Cassandra nodes to connect to. Multiple comma separated addresses can be specified on a single line.",
          "type": "string"
        },
        "args_mapping": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that can be used to provide arguments to Cassandra queries. The result of the query must be an array containing a matching number of elements to the query arguments.",
          "type": "string"
        },
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "1s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "5s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "consistency": {
          "default": "QUORUM",
          "description": "The consistency level to use.",
          "enum": [
            "ANY",
            "ONE",
            "TWO",
            "THREE",
            "QUORUM",
            "ALL",
            "LOCAL_QUORUM",
            "EACH_QUORUM",
            "LOCAL_ONE"
          ],
          "type": "string",
          "x-advanced": true
        },
        "disable_initial_host_lookup": {
          "default": false,
          "description": "If enabled the driver will not attempt to get host info from the system.peers table. This can speed up queries but will mean that data_centre, rack and token information will not be available.",
          "type": "boolean",
          "x-advanced": true
        },
        "logged_batch": {
          "default": true,
          "description": "If enabled the driver will perform a logged batch. Disabling this prompts unlogged batches to be used instead, which are less efficient but necessary for alternative storages that do not support logged batches.",
          "type": "boolean",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "max_retries": {
          "default": 3,
          "description": "The maximum number of retries before giving up on a request.",
          "type": "number",
          "x-advanced": true
        },
        "password_authenticator": {
          "description": "Optional configuration of Cassandra authentication parameters.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use password authentication",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "The password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "The username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "query": {
          "description": "A query to execute for each message.",
          "type": "string"
        },
        "timeout": {
          "default": "600ms",
          "description": "The client connection timeout.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        }
      },
      "required": [
        "disable_initial_host_lookup",
        "query",
        "logged_batch",
        "max_in_flight",
        "batching",
        "tls",
        "max_retries",
        "backoff",
        "timeout",
        "consistency",
        "addresses",
        "password_authenticator"
      ],
      "type": "object"
    },
    "catch": {
      "description": "\nBehaves similarly to the xref:components:processors/for_each.adoc[`for_each`] processor, where a list of child processors are applied to individual messages of a batch. However, processors are only applied to messages that failed a processing step prior to the catch.\n\nFor example, with the following config:\n\n```yaml\npipeline:\n  processors:\n    - resource: foo\n    - catch:\n      - resource: bar\n      - resource: baz\n```\n\nIf the processor `foo` fails for a particular message, that message will be fed into the processors `bar` and `baz`. Messages that do not fail for the processor `foo` will skip these processors.\n\nWhen messages leave the catch block their fail flags are cleared. This processor is useful for when it's possible to recover failed messages, or when special actions (such as logging/metrics) are required before dropping them.\n\nMore information about error handling can be found in xref:configuration:error_handling.adoc[].",
      "type": "object"
    },
    "classic_to_core": {
      "description": "The classic_to_core processor converts Historian Data Contract messages containing multiple values \nand tag groups into individual Core format messages, following the \"one tag, one message, one topic\" principle.\n\nInput format (Historian Data Contract):\n- Single message with timestamp_ms and multiple data fields or tag groups\n- Topic: umh.v1.\u003clocation\u003e._historian.\u003ccontext\u003e\n- Supports flat tags: {\"timestamp_ms\": 123, \"temperature\": 23.4}\n- Supports tag groups: {\"timestamp_ms\": 123, \"axis\": {\"x\": 1.0, \"y\": 2.0}}\n- Supports arrays: {\"timestamp_ms\": 123, \"values\": [10, 20, 30]}\n- Supports meta/metadata fields: {\"timestamp_ms\": 123, \"temperature\": 23.4, \"meta\": {\"sensor_id\": \"ABC123\"}}\n\nOutput format (Core):\n- Multiple messages, one per tag (including flattened tag groups and converted arrays)\n- Each with {\"value\": \u003cfield_value\u003e, \"timestamp_ms\": \u003ctimestamp\u003e}\n- Topics: umh.v1.\u003clocation\u003e.\u003ctarget_data_contract\u003e.\u003ccontext\u003e.\u003ctag_name\u003e\n- Tag groups flattened with dot separators: \"axis.x\", \"axis.y\"\n- Arrays converted to string format: \"values\": \"[10 20 30]\"\n- Meta/metadata fields applied as metadata to all output messages\n\nThe processor will:\n1. Extract the timestamp field from the payload\n2. Extract meta and metadata fields for applying to all output messages  \n3. Flatten any nested tag groups using dot separator for intuitive paths\n4. Convert arrays to string representation to ensure UMH-Core scalar-only compliance\n5. Create one output message per tag\n6. Construct new topics by appending tag names\n7. Preserve original metadata while updating topic-related fields\n8. Apply meta/metadata field contents as metadata to all generated messages",
      "properties": {
        "target_data_contract": {
          "default": "",
          "description": "Target data contract for output topics. If empty, uses the input's data contract (e.g., _historian)",
          "type": "string"
        }
      },
      "type": "object"
    },
    "cockroachdb_changefeed": {
      "description": "This input will continue to listen to the changefeed until shutdown. A backfill of the full current state of the table will be delivered upon each run unless a cache is configured for storing cursor timestamps, as this is how Redpanda Connect keeps track as to which changes have been successfully delivered.\n\nNote: You must have `SET CLUSTER SETTING kv.rangefeed.enabled = true;` on your CRDB cluster, for more information refer to https://www.cockroachlabs.com/docs/stable/changefeed-examples?filters=core[the official CockroachDB documentation^].",
      "properties": {
        "auto_replay_nacks": {
          "default": true,
          "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
          "type": "boolean"
        },
        "cursor_cache": {
          "description": "A https://docs.redpanda.com/redpanda-connect/components/caches/about[cache resource^] to use for storing the current latest cursor that has been successfully delivered, this allows Redpanda Connect to continue from that cursor upon restart, rather than consume the entire state of the table.",
          "type": "string"
        },
        "dsn": {
          "description": "A Data Source Name to identify the target database.",
          "type": "string"
        },
        "options": {
          "description": "A list of options to be included in the changefeed (WITH X, Y...).\n\nNOTE: Both the CURSOR option and UPDATED will be ignored from these options when a `cursor_cache` is specified, as they are set explicitly by Redpanda Connect in this case.",
          "type": "string",
          "x-advanced": true
        },
        "tables": {
          "description": "CSV of tables to be included in the changefeed",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        }
      },
      "required": [
        "tls",
        "tables",
        "auto_replay_nacks",
        "dsn"
      ],
      "type": "object"
    },
    "command": {
      "description": "\nThe specified command is executed for each message processed, with the raw bytes of the message being fed into the stdin of the command process, and the resulting message having its contents replaced with the stdout of it.\n\n== Performance\n\nSince this processor executes a new process for each message performance will likely be an issue for high throughput streams. If this is the case then consider using the xref:components:processors/subprocess.adoc[`subprocess` processor] instead as it keeps the underlying process alive long term and uses codecs to insert and extract inputs and outputs to it via stdin/stdout.\n\n== Error handling\n\nIf a non-zero error code is returned by the command then an error containing the entirety of stderr (or a generic message if nothing is written) is set on the message. These failed messages will continue through the pipeline unchanged, but can be dropped or placed in a dead letter queue according to your config, you can read about xref:configuration:error_handling.adoc[these patterns].\n\nIf the command is successful but stderr is written to then a metadata field `command_stderr` is populated with its contents.\n",
      "properties": {
        "args_mapping": {
          "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that, when specified, should resolve into an array of arguments to pass to the command. Command arguments are expressed this way in order to support dynamic behavior.",
          "type": "string"
        },
        "name": {
          "description": "The name of the command to execute.",
          "type": "string"
        }
      },
      "required": [
        "name"
      ],
      "type": "object"
    },
    "compress": {
      "description": "The 'level' field might not apply to all algorithms.",
      "properties": {
        "algorithm": {
          "description": "The compression algorithm to use.",
          "enum": [
            "flate",
            "gzip",
            "lz4",
            "pgzip",
            "snappy",
            "zlib"
          ],
          "type": "string"
        },
        "level": {
          "default": -1,
          "description": "The level of compression to use. May not be applicable to all algorithms.",
          "type": "number"
        }
      },
      "required": [
        "algorithm",
        "level"
      ],
      "type": "object"
    },
    "couchbase": {
      "description": "When inserting, replacing or upserting documents, each must have the `content` property set.\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "bucket": {
          "description": "Couchbase bucket.",
          "type": "string"
        },
        "collection": {
          "default": "_default",
          "description": "Bucket collection.",
          "type": "string",
          "x-advanced": true
        },
        "content": {
          "description": "Document content.",
          "type": "string"
        },
        "id": {
          "description": "Document id.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "operation": {
          "default": "upsert",
          "description": "Couchbase operation to perform.",
          "type": "string"
        },
        "password": {
          "description": "Password to connect to the cluster.",
          "type": "string"
        },
        "timeout": {
          "default": "15s",
          "description": "Operation timeout.",
          "type": "string",
          "x-advanced": true
        },
        "transcoder": {
          "default": "legacy",
          "description": "Couchbase transcoder to use.",
          "type": "string",
          "x-advanced": true
        },
        "url": {
          "description": "Couchbase connection string.",
          "type": "string"
        },
        "username": {
          "description": "Username to connect to the cluster.",
          "type": "string"
        }
      },
      "required": [
        "bucket",
        "timeout",
        "operation",
        "batching",
        "url",
        "transcoder",
        "id",
        "max_in_flight"
      ],
      "type": "object"
    },
    "crash": {
      "description": "Crashes the process using a fatal log message. The log message can be set using function interpolations described in  xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries] which allows you to log the contents and metadata of messages.",
      "type": "object"
    },
    "csv": {
      "description": "\nThis input offers more control over CSV parsing than the xref:components:inputs/file.adoc[`file` input].\n\nWhen parsing with a header row each line of the file will be consumed as a structured object, where the key names are determined from the header now. For example, the following CSV file:\n\n```csv\nfoo,bar,baz\nfirst foo,first bar,first baz\nsecond foo,second bar,second baz\n```\n\nWould produce the following messages:\n\n```json\n{\"foo\":\"first foo\",\"bar\":\"first bar\",\"baz\":\"first baz\"}\n{\"foo\":\"second foo\",\"bar\":\"second bar\",\"baz\":\"second baz\"}\n```\n\nIf, however, the field `parse_header_row` is set to `false` then arrays are produced instead, like follows:\n\n```json\n[\"first foo\",\"first bar\",\"first baz\"]\n[\"second foo\",\"second bar\",\"second baz\"]\n```\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- header\n- path\n- mod_time_unix\n- mod_time (RFC3339)\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\nNote: The `header` field is only set when `parse_header_row` is `true`.\n\n=== Output CSV column order\n\nWhen xref:guides:bloblang/advanced.adoc#creating-csv[creating CSV] from Redpanda Connect messages, the columns must be sorted lexicographically to make the output deterministic. Alternatively, when using the `csv` input, one can leverage the `header` metadata field to retrieve the column order:\n\n```yaml\ninput:\n  csv:\n    paths:\n      - ./foo.csv\n      - ./bar.csv\n    parse_header_row: true\n\n  processors:\n    - mapping: |\n        map escape_csv {\n          root = if this.re_match(\"[\\\"\\n,]+\") {\n            \"\\\"\" + this.replace_all(\"\\\"\", \"\\\"\\\"\") + \"\\\"\"\n          } else {\n            this\n          }\n        }\n\n        let header = if count(@path) == 1 {\n          @header.map_each(c -\u003e c.apply(\"escape_csv\")).join(\",\") + \"\\n\"\n        } else { \"\" }\n\n        root = $header + @header.map_each(c -\u003e this.get(c).string().apply(\"escape_csv\")).join(\",\")\n\noutput:\n  file:\n    path: ./output/${! @path.filepath_split().index(-1) }\n```\n",
      "properties": {
        "auto_replay_nacks": {
          "default": true,
          "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
          "type": "boolean"
        },
        "batch_count": {
          "default": 1,
          "description": "Optionally process records in batches. This can help to speed up the consumption of exceptionally large CSV files. When the end of the file is reached the remaining records are processed as a (potentially smaller) batch.",
          "type": "number",
          "x-advanced": true
        },
        "delete_on_finish": {
          "default": false,
          "description": "Whether to delete input files from the disk once they are fully consumed.",
          "type": "boolean",
          "x-advanced": true
        },
        "delimiter": {
          "default": ",",
          "description": "The delimiter to use for splitting values in each record. It must be a single character.",
          "type": "string"
        },
        "lazy_quotes": {
          "default": false,
          "description": "If set to `true`, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field.",
          "type": "boolean"
        },
        "parse_header_row": {
          "default": true,
          "description": "Whether to reference the first row as a header row. If set to true the output structure for messages will be an object where field keys are determined by the header row. Otherwise, each message will consist of an array of values from the corresponding CSV row.",
          "type": "boolean"
        },
        "paths": {
          "description": "A list of file paths to read from. Each file will be read sequentially until the list is exhausted, at which point the input will close. Glob patterns are supported, including super globs (double star).",
          "type": "string"
        }
      },
      "required": [
        "delete_on_finish",
        "batch_count",
        "auto_replay_nacks",
        "paths",
        "parse_header_row",
        "delimiter",
        "lazy_quotes"
      ],
      "type": "object"
    },
    "cypher": {
      "description": "The cypher output type writes a batch of messages to any graph database that supports the Neo4j or Bolt protocols.",
      "properties": {
        "args_mapping": {
          "description": "The mapping from the message to the data that is passed in as parameters to the cypher expression. Must be an object. By default the entire payload is used.",
          "type": "string"
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean"
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string"
            },
            "realm": {
              "default": "",
              "description": "The realm for authentication challenges.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string"
            }
          },
          "required": [
            "enabled",
            "username",
            "password",
            "realm"
          ],
          "type": "object"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "cypher": {
          "description": "The cypher expression to execute against the graph database.",
          "type": "string"
        },
        "database_name": {
          "default": "",
          "description": "Set the target database for which expressions are evaluated against.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "uri": {
          "description": "The connection URI to connect to.\nSee https://neo4j.com/docs/go-manual/current/connect-advanced/[Neo4j's documentation^] for more information. ",
          "type": "string"
        }
      },
      "required": [
        "tls",
        "batching",
        "max_in_flight",
        "uri",
        "cypher",
        "database_name"
      ],
      "type": "object"
    },
    "decompress": {
      "description": "Decompresses messages according to the selected algorithm. Supported decompression algorithms are: [bzip2 flate gzip lz4 pgzip snappy zlib]",
      "properties": {
        "algorithm": {
          "description": "The decompression algorithm to use.",
          "enum": [
            "bzip2",
            "flate",
            "gzip",
            "lz4",
            "pgzip",
            "snappy",
            "zlib"
          ],
          "type": "string"
        }
      },
      "required": [
        "algorithm"
      ],
      "type": "object"
    },
    "dedupe": {
      "description": "\nCaches must be configured as resources, for more information check out the xref:components:caches/about.adoc[cache documentation].\n\nWhen using this processor with an output target that might fail you should always wrap the output within an indefinite xref:components:outputs/retry.adoc[`retry`] block. This ensures that during outages your messages aren't reprocessed after failures, which would result in messages being dropped.\n\n== Batch deduplication\n\nThis processor enacts on individual messages only, in order to perform a deduplication on behalf of a batch (or window) of messages instead use the xref:components:processors/cache.adoc#examples[`cache` processor].\n\n== Delivery guarantees\n\nPerforming deduplication on a stream using a distributed cache voids any at-least-once guarantees that it previously had. This is because the cache will preserve message signatures even if the message fails to leave the Redpanda Connect pipeline, which would cause message loss in the event of an outage at the output sink followed by a restart of the Redpanda Connect instance (or a server crash, etc).\n\nThis problem can be mitigated by using an in-memory cache and distributing messages to horizontally scaled Redpanda Connect pipelines partitioned by the deduplication key. However, in situations where at-least-once delivery guarantees are important it is worth avoiding deduplication in favour of implement idempotent behavior at the edge of your stream pipelines.",
      "properties": {
        "cache": {
          "description": "The xref:components:caches/about.adoc[`cache` resource] to target with this processor.",
          "type": "string"
        },
        "drop_on_err": {
          "default": true,
          "description": "Whether messages should be dropped when the cache returns a general error such as a network issue.",
          "type": "boolean"
        },
        "key": {
          "description": "An interpolated string yielding the key to deduplicate by for each message.",
          "type": "string"
        }
      },
      "required": [
        "cache",
        "key",
        "drop_on_err"
      ],
      "type": "object"
    },
    "discord": {
      "description": "\nThis output POSTs messages to the `/channels/\\{channel_id}/messages` Discord API endpoint authenticated as a bot using token based authentication.\n\nIf the format of a message is a JSON object matching the https://discord.com/developers/docs/resources/channel#message-object[Discord API message type^] then it is sent directly, otherwise an object matching the API type is created with the content of the message added as a string.\n",
      "properties": {
        "bot_token": {
          "description": "A bot token used for authentication.",
          "type": "string"
        },
        "channel_id": {
          "description": "A discord channel ID to write messages to.",
          "type": "string"
        },
        "rate_limit": {
          "default": "An optional rate limit resource to restrict API requests with.",
          "type": "string"
        }
      },
      "required": [
        "bot_token",
        "rate_limit",
        "channel_id"
      ],
      "type": "object"
    },
    "downsampler": {
      "description": "The downsampler reduces data volume by filtering out insignificant changes in time-series data using configurable algorithms.\n\nIt processes UMH-core time-series data with data_contract \"_historian\",\npassing all other messages through unchanged. Each message that passes the downsampling filter is annotated\nwith metadata indicating the algorithm used.\n\nIn typical UMH deployments, the downsampler is enabled by default with conservative settings to automatically\ncompress time-series data. The tag_processor can be used upstream to selectively bypass downsampling for\ncritical data by setting the ds_ignore metadata field.\n\nSupported format:\n- UMH-core: Single \"value\" field with timestamp (one tag, one message, one topic)\n- Requires \"umh_topic\" metadata field to identify the time series\n\nThe plugin maintains separate state for each time series (identified by umh_topic) and applies the configured algorithm\nto determine whether each data point represents a significant change worth preserving.\n\n## Data Type Handling\n\nThe downsampler handles different data types as follows:\n\n- **Numeric values** (int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64, float32, float64):\n  Converted to float64 for algorithm processing and output. This ensures consistent precision and compatibility\n  with all downsampling algorithms.\n\n- **Boolean values** (true, false):\n  Preserved as-is. Uses change-based logic - only emits when the boolean value changes.\n\n- **String values**:\n  Preserved as-is. Uses change-based logic - only emits when the string value changes.\n\n- **Other types**:\n  Rejected with an error to ensure data integrity.\n\n## Selective Bypass with ds_ignore\n\nThe ds_ignore metadata key allows selective bypass of downsampling on a per-message basis:\n\n- Any message with ds_ignore metadata (any non-empty value) completely bypasses all downsampling logic\n- Designed for use with tag_processor to identify critical data that must be preserved unchanged\n- Common use cases: emergency alarms, state changes, calibration data, precision measurements\n- Bypassed messages are marked with downsampled_by: \"ignored\" and counted in messages_ignored metric\n\nUse with tag_processor for UMH deployments to selectively bypass downsampling based on message characteristics.",
      "properties": {
        "allow_meta_overrides": {
          "default": true,
          "description": "Honour per-message ds_* metadata.",
          "type": "boolean"
        },
        "default": {
          "description": "Default algorithm parameters applied to all topics unless overridden.",
          "properties": {
            "deadband": {
              "description": "Default deadband algorithm parameters.",
              "properties": {
                "max_time": {
                  "description": "Default maximum time interval for deadband algorithm.",
                  "type": "string"
                },
                "min_time": {
                  "description": "Default minimum time between emissions for deadband algorithm.",
                  "type": "string"
                },
                "threshold": {
                  "description": "Default threshold for deadband algorithm.",
                  "type": "number"
                }
              },
              "type": "object"
            },
            "late_policy": {
              "default": "passthrough",
              "description": "Default policy for handling late-arriving messages (passthrough=forward unchanged, drop=discard with warning).",
              "enum": [
                "passthrough",
                "drop"
              ],
              "type": "string"
            },
            "swinging_door": {
              "description": "Default swinging door algorithm parameters.",
              "properties": {
                "max_time": {
                  "description": "Default maximum time interval for swinging door algorithm.",
                  "type": "string"
                },
                "min_time": {
                  "description": "Default minimum time between emissions for swinging door algorithm.",
                  "type": "string"
                },
                "threshold": {
                  "description": "Default compression deviation for swinging door algorithm.",
                  "type": "number"
                }
              },
              "type": "object"
            }
          },
          "type": "object"
        },
        "overrides": {
          "description": "Topic-specific parameter overrides using pattern matching. Supports exact topic names and shell-style wildcards (* matches any sequence, ? matches any character).",
          "properties": {
            "deadband": {
              "description": "Deadband algorithm parameter overrides.",
              "properties": {
                "max_time": {
                  "description": "Override maximum time interval for deadband algorithm.",
                  "type": "string"
                },
                "min_time": {
                  "description": "Override minimum time between emissions for deadband algorithm.",
                  "type": "string"
                },
                "threshold": {
                  "description": "Override threshold for deadband algorithm.",
                  "type": "number"
                }
              },
              "type": "object"
            },
            "late_policy": {
              "description": "Override policy for handling late-arriving messages (passthrough=forward unchanged, drop=discard with warning).",
              "enum": [
                "passthrough",
                "drop"
              ],
              "type": "string"
            },
            "pattern": {
              "description": "Topic pattern for matching (supports exact matches and shell-style wildcards with * and ?). Examples: 'umh.v1.acme._historian.temp.sensor1' (exact), '*.temperature.*' (wildcard), '*pressure*' (contains).",
              "type": "string"
            },
            "swinging_door": {
              "description": "Swinging door algorithm parameter overrides.",
              "properties": {
                "max_time": {
                  "description": "Override maximum time interval for swinging door algorithm.",
                  "type": "string"
                },
                "min_time": {
                  "description": "Override minimum time between emissions for swinging door algorithm.",
                  "type": "string"
                },
                "threshold": {
                  "description": "Override compression deviation for swinging door algorithm.",
                  "type": "number"
                }
              },
              "type": "object"
            }
          },
          "required": [
            "pattern"
          ],
          "type": "object"
        }
      },
      "required": [
        "default",
        "allow_meta_overrides"
      ],
      "type": "object"
    },
    "drop": {
      "description": "Drops all messages.",
      "type": "object"
    },
    "drop_on": {
      "description": "Regular Redpanda Connect outputs will apply back pressure when downstream services aren't accessible, and Redpanda Connect retries (or nacks) all messages that fail to be delivered. However, in some circumstances, or for certain output types, we instead might want to relax these mechanisms, which is when this output becomes useful.",
      "properties": {
        "back_pressure": {
          "description": "An optional duration string that determines the maximum length of time to wait for a given message to be accepted by the child output before the message should be dropped instead. The most common reason for an output to block is when waiting for a lost connection to be re-established. Once a message has been dropped due to back pressure all subsequent messages are dropped immediately until the output is ready to process them again. Note that if `error` is set to `false` and this field is specified then messages dropped due to back pressure will return an error response (are nacked or reattempted).",
          "type": "string"
        },
        "error": {
          "default": false,
          "description": "Whether messages should be dropped when the child output returns an error of any type. For example, this could be when an `http_client` output gets a 4XX response code. In order to instead drop only on specific error patterns use the `error_matches` field instead.",
          "type": "boolean"
        },
        "error_patterns": {
          "description": "A list of regular expressions (re2) where if the child output returns an error that matches any part of any of these patterns the message will be dropped.",
          "type": "string"
        },
        "output": {
          "description": "A child output to wrap with this drop mechanism.",
          "type": "string"
        }
      },
      "required": [
        "error",
        "output"
      ],
      "type": "object"
    },
    "dynamic": {
      "description": "The broker pattern used is always `fan_out`, meaning each message will be delivered to each dynamic output.",
      "properties": {
        "outputs": {
          "default": {},
          "description": "A map of outputs to statically create.",
          "type": "string"
        },
        "prefix": {
          "default": "",
          "description": "A path prefix for HTTP endpoints that are registered.",
          "type": "string"
        }
      },
      "required": [
        "outputs",
        "prefix"
      ],
      "type": "object"
    },
    "elasticsearch": {
      "description": "\nBoth the `id` and `index` fields can be dynamically set using function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries]. When sending batched messages these interpolations are performed per message part.\n\n== AWS\n\nIt's possible to enable AWS connectivity with this output using the `aws` fields. However, you may need to set `sniff` and `healthcheck` to false for connections to succeed.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "action": {
          "default": "index",
          "description": "The action to take on the document. This field must resolve to one of the following action types: `create`, `index`, `update`, `upsert` or `delete`.",
          "type": "string",
          "x-advanced": true
        },
        "api_key": {
          "description": "The key to set in the Authorization header if using API keys for authentication.",
          "type": "string"
        },
        "aws": {
          "description": "Enables and customises connectivity to Amazon Elastic Service.",
          "properties": {
            "credentials": {
              "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
              "properties": {
                "from_ec2_role": {
                  "default": false,
                  "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                  "type": "boolean",
                  "x-advanced": true
                },
                "id": {
                  "default": "",
                  "description": "The ID of credentials to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "profile": {
                  "default": "",
                  "description": "A profile from `~/.aws/credentials` to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "role": {
                  "default": "",
                  "description": "A role ARN to assume.",
                  "type": "string",
                  "x-advanced": true
                },
                "role_external_id": {
                  "default": "",
                  "description": "An external ID to provide when assuming a role.",
                  "type": "string",
                  "x-advanced": true
                },
                "secret": {
                  "default": "",
                  "description": "The secret for the credentials being used.",
                  "type": "string",
                  "x-advanced": true
                },
                "token": {
                  "default": "",
                  "description": "The token for the credentials being used, required when using short term credentials.",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "profile",
                "id",
                "secret",
                "token",
                "from_ec2_role",
                "role",
                "role_external_id"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to connect to Amazon Elastic Service.",
              "type": "boolean",
              "x-advanced": true
            },
            "endpoint": {
              "default": "",
              "description": "Allows you to specify a custom endpoint for the AWS API.",
              "type": "string",
              "x-advanced": true
            },
            "region": {
              "default": "",
              "description": "The AWS region to target.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "region",
            "endpoint",
            "credentials"
          ],
          "type": "object",
          "x-advanced": true
        },
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "1s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "30s",
              "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "5s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "gzip_compression": {
          "default": false,
          "description": "Enable gzip compression on the request side.",
          "type": "boolean",
          "x-advanced": true
        },
        "healthcheck": {
          "default": true,
          "description": "Whether to enable healthchecks.",
          "type": "boolean",
          "x-advanced": true
        },
        "id": {
          "default": "${!counter()}-${!timestamp_unix()}",
          "description": "The ID for indexed messages. Interpolation should be used in order to create a unique ID for each message.",
          "type": "string"
        },
        "index": {
          "description": "The index to place messages.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "max_retries": {
          "default": 0,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "pipeline": {
          "default": "",
          "description": "An optional pipeline id to preprocess incoming documents.",
          "type": "string",
          "x-advanced": true
        },
        "retry_on_conflict": {
          "default": 0,
          "description": "When using the update or upsert action, retry_on_conflict can be used to specify how many times an update should be retried in the case of a version conflict.",
          "type": "number",
          "x-advanced": true
        },
        "routing": {
          "default": "",
          "description": "The routing key to use for the document.",
          "type": "string",
          "x-advanced": true
        },
        "sniff": {
          "default": true,
          "description": "Prompts Redpanda Connect to sniff for brokers to connect to when establishing a connection.",
          "type": "boolean",
          "x-advanced": true
        },
        "timeout": {
          "default": "5s",
          "description": "The maximum time to wait before abandoning a request (and trying again).",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "type": {
          "default": "",
          "description": "The document mapping type. This field is required for versions of elasticsearch earlier than 6.0.0, but are invalid for versions 7.0.0 or later.",
          "type": "string"
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "healthcheck",
        "max_in_flight",
        "batching",
        "urls",
        "pipeline",
        "routing",
        "retry_on_conflict",
        "sniff",
        "backoff",
        "aws",
        "index",
        "action",
        "timeout",
        "max_retries",
        "gzip_compression",
        "id",
        "type",
        "tls"
      ],
      "type": "object"
    },
    "elasticsearch_v8": {
      "description": "\nBoth the `id` and `index` fields can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "action": {
          "description": "The action to take on the document. This field must resolve to one of the following action types: `index`, `update` or `delete`. See the `Updating Documents` example for more on how the `update` action works.",
          "type": "string"
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "id": {
          "description": "The ID for indexed messages. Interpolation should be used in order to create a unique ID for each message.",
          "type": "string"
        },
        "index": {
          "description": "The index to place messages.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "pipeline": {
          "default": "",
          "description": "An optional pipeline id to preprocess incoming documents.",
          "type": "string",
          "x-advanced": true
        },
        "retry_on_conflict": {
          "default": 0,
          "description": "Specify how many times should an update operation be retried when a conflict occurs",
          "type": "number",
          "x-advanced": true
        },
        "routing": {
          "default": "",
          "description": "The routing key to use for the document.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "index",
        "pipeline",
        "routing",
        "tls",
        "max_in_flight",
        "urls",
        "action",
        "id",
        "retry_on_conflict",
        "batching"
      ],
      "type": "object"
    },
    "ethernetip": {
      "description": "This input plugin enables Benthos to read data directly from Ethernet/IP-Devices using the CIP protocol. Configure the plugin by specifying the PLC's IP address, path and pollRate, and the data blocks to read.",
      "properties": {
        "attributes": {
          "properties": {
            "alias": {
              "description": "You can set an alias so the data will be stored with this alias set as name via metadata.",
              "type": "string"
            },
            "path": {
              "description": "The Path consists of the following: CIP-Class - CIP-Instance - CIP-Attribute, e.g. 1-1-1. They might vary based on which controller you're using.",
              "type": "string"
            },
            "type": {
              "description": "The type of the attribute you want to read: e.g. 'bool', 'int16', 'byte'.",
              "type": "string"
            }
          },
          "required": [
            "path",
            "type"
          ],
          "type": "object"
        },
        "endpoint": {
          "description": "IP address of the Ethernet/IP-Device.",
          "type": "string"
        },
        "listAllTags": {
          "default": false,
          "description": "You can use this option to list all available Tags, but only specific controllers support this method.",
          "type": "boolean"
        },
        "path": {
          "default": "1,0",
          "type": "string"
        },
        "pollRate": {
          "default": 1000,
          "description": "The rate in milliseconds on which we try to read data out of the plc.",
          "type": "number"
        },
        "socketTimeoutMs": {
          "default": 10000,
          "description": "The timeout in milliseconds for socket operations (connection establishment, reads, and writes).",
          "type": "number",
          "x-advanced": true
        },
        "tags": {
          "properties": {
            "alias": {
              "description": "You can set an alias so the data will be stored with this alias set as name via metadata.",
              "type": "string"
            },
            "length": {
              "default": 1,
              "description": "The Length of the array, when specified as 'arrayof...'",
              "type": "number"
            },
            "name": {
              "description": "The tag name is usually provided by something like this: `Program:Gologix.MyTagSet.TestBool`",
              "type": "string"
            },
            "type": {
              "description": "The type of the tag you want to read: e.g. 'bool', 'int16', 'byte'.",
              "type": "string"
            }
          },
          "required": [
            "name",
            "type",
            "length"
          ],
          "type": "object"
        },
        "useMultiRead": {
          "default": true,
          "description": "You can use this option to increase the reading time, but be aware that only specific controllers support this method.",
          "type": "boolean"
        }
      },
      "required": [
        "endpoint",
        "path",
        "pollRate",
        "listAllTags",
        "useMultiRead",
        "attributes",
        "tags"
      ],
      "type": "object"
    },
    "fallback": {
      "description": "\nThis pattern is useful for triggering events in the case where certain output targets have broken. For example, if you had an output type `http_client` but wished to reroute messages whenever the endpoint becomes unreachable you could use this pattern:\n\n```yaml\noutput:\n  fallback:\n    - http_client:\n        url: http://foo:4195/post/might/become/unreachable\n        retries: 3\n        retry_period: 1s\n    - http_client:\n        url: http://bar:4196/somewhere/else\n        retries: 3\n        retry_period: 1s\n      processors:\n        - mapping: 'root = \"failed to send this message to foo: \" + content()'\n    - file:\n        path: /usr/local/benthos/everything_failed.jsonl\n```\n\n== Metadata\n\nWhen a given output fails the message routed to the following output will have a metadata value named `fallback_error` containing a string error message outlining the cause of the failure. The content of this string will depend on the particular output and can be used to enrich the message or provide information used to broker the data to an appropriate output using something like a `switch` output.\n\n== Batching\n\nWhen an output within a fallback sequence uses batching, like so:\n\n```yaml\noutput:\n  fallback:\n    - aws_dynamodb:\n        table: foo\n        string_columns:\n          id: ${!json(\"id\")}\n          content: ${!content()}\n        batching:\n          count: 10\n          period: 1s\n    - file:\n        path: /usr/local/benthos/failed_stuff.jsonl\n```\n\nRedpanda Connect makes a best attempt at inferring which specific messages of the batch failed, and only propagates those individual messages to the next fallback tier.\n\nHowever, depending on the output and the error returned it is sometimes not possible to determine the individual messages that failed, in which case the whole batch is passed to the next tier in order to preserve at-least-once delivery guarantees.",
      "type": "object"
    },
    "file": {
      "description": "Messages can be written to different files by using xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions] in the path field. However, only one file is ever open at a given time, and therefore when the path changes the previously open file is closed.",
      "properties": {
        "codec": {
          "default": "lines",
          "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
          "type": "string"
        },
        "path": {
          "description": "The file to write to, if the file does not yet exist it will be created.",
          "type": "string"
        }
      },
      "required": [
        "path",
        "codec"
      ],
      "type": "object"
    },
    "for_each": {
      "description": "\nThis is useful for forcing batch wide processors such as xref:components:processors/dedupe.adoc[`dedupe`] or interpolations such as the `value` field of the `metadata` processor to execute on individual message parts of a batch instead.\n\nPlease note that most processors already process per message of a batch, and this processor is not needed in those cases.",
      "type": "object"
    },
    "gcp_bigquery": {
      "description": "\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to GCP services. You can find out more in xref:guides:cloud/gcp.adoc[].\n\n== Format\n\nThis output currently supports only CSV, NEWLINE_DELIMITED_JSON and PARQUET, formats. Learn more about how to use GCP BigQuery with them here:\n\n- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json[`NEWLINE_DELIMITED_JSON`^]\n- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv[`CSV`^]\n- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet[`PARQUET`^]\n\nEach message may contain multiple elements separated by newlines. For example a single message containing:\n\n```json\n{\"key\": \"1\"}\n{\"key\": \"2\"}\n```\n\nIs equivalent to two separate messages:\n\n```json\n{\"key\": \"1\"}\n```\n\nAnd:\n\n```json\n{\"key\": \"2\"}\n```\n\nThe same is true for the CSV format.\n\n=== CSV\n\nFor the CSV format when the field `csv.header` is specified a header row will be inserted as the first line of each message batch. If this field is not provided then the first message of each message batch must include a header line.\n\n=== Parquet\n\nFor parquet, the data can be encoded using the `parquet_encode` processor and each message that is sent to the output must be a full parquet message.\n\n\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "auto_detect": {
          "default": false,
          "description": "Indicates if we should automatically infer the options and schema for CSV and JSON sources. If the table doesn't exist and this field is set to `false` the output may not be able to insert data and will throw insertion error. Be careful using this field since it delegates to the GCP BigQuery service the schema detection and values like `\"no\"` may be treated as booleans for the CSV format.",
          "type": "boolean",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "create_disposition": {
          "default": "CREATE_IF_NEEDED",
          "description": "Specifies the circumstances under which destination table will be created. If CREATE_IF_NEEDED is used the GCP BigQuery will create the table if it does not already exist and tables are created atomically on successful completion of a job. The CREATE_NEVER option ensures the table must already exist and will not be automatically created.",
          "enum": [
            "CREATE_IF_NEEDED",
            "CREATE_NEVER"
          ],
          "type": "string",
          "x-advanced": true
        },
        "credentials_json": {
          "default": "",
          "description": "An optional field to set Google Service Account Credentials json.",
          "type": "string"
        },
        "csv": {
          "description": "Specify how CSV data should be interpretted.",
          "properties": {
            "allow_jagged_rows": {
              "default": false,
              "description": "Causes missing trailing optional columns to be tolerated when reading CSV data. Missing values are treated as nulls.",
              "type": "boolean",
              "x-advanced": true
            },
            "allow_quoted_newlines": {
              "default": false,
              "description": "Sets whether quoted data sections containing newlines are allowed when reading CSV data.",
              "type": "boolean",
              "x-advanced": true
            },
            "encoding": {
              "default": "UTF-8",
              "description": "Encoding is the character encoding of data to be read.",
              "enum": [
                "UTF-8",
                "ISO-8859-1"
              ],
              "type": "string",
              "x-advanced": true
            },
            "field_delimiter": {
              "default": ",",
              "description": "The separator for fields in a CSV file, used when reading or exporting data.",
              "type": "string"
            },
            "header": {
              "default": [],
              "description": "A list of values to use as header for each batch of messages. If not specified the first line of each message will be used as header.",
              "type": "string"
            },
            "skip_leading_rows": {
              "default": 1,
              "description": "The number of rows at the top of a CSV file that BigQuery will skip when reading data. The default value is 1 since Redpanda Connect will add the specified header in the first line of each batch sent to BigQuery.",
              "type": "number",
              "x-advanced": true
            }
          },
          "required": [
            "header",
            "field_delimiter",
            "allow_jagged_rows",
            "allow_quoted_newlines",
            "encoding",
            "skip_leading_rows"
          ],
          "type": "object"
        },
        "dataset": {
          "description": "The BigQuery Dataset ID.",
          "type": "string"
        },
        "format": {
          "default": "NEWLINE_DELIMITED_JSON",
          "description": "The format of each incoming message.",
          "enum": [
            "NEWLINE_DELIMITED_JSON",
            "CSV",
            "PARQUET"
          ],
          "type": "string"
        },
        "ignore_unknown_values": {
          "default": false,
          "description": "Causes values not matching the schema to be tolerated. Unknown values are ignored. For CSV this ignores extra values at the end of a line. For JSON this ignores named values that do not match any column name. If this field is set to false (the default value), records containing unknown values are treated as bad records. The max_bad_records field can be used to customize how bad records are handled.",
          "type": "boolean",
          "x-advanced": true
        },
        "job_labels": {
          "default": {},
          "description": "A list of labels to add to the load job.",
          "type": "string"
        },
        "job_project": {
          "default": "",
          "description": "The project ID in which jobs will be exectuted. If not set, project will be used.",
          "type": "string"
        },
        "max_bad_records": {
          "default": 0,
          "description": "The maximum number of bad records that will be ignored when reading data.",
          "type": "number",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of message batches to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "project": {
          "default": "",
          "description": "The project ID of the dataset to insert data to. If not set, it will be inferred from the credentials or read from the GOOGLE_CLOUD_PROJECT environment variable.",
          "type": "string"
        },
        "table": {
          "description": "The table to insert messages to.",
          "type": "string"
        },
        "write_disposition": {
          "default": "WRITE_APPEND",
          "description": "Specifies how existing data in a destination table is treated.",
          "enum": [
            "WRITE_APPEND",
            "WRITE_EMPTY",
            "WRITE_TRUNCATE"
          ],
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "dataset",
        "write_disposition",
        "auto_detect",
        "job_project",
        "format",
        "max_in_flight",
        "create_disposition",
        "ignore_unknown_values",
        "job_labels",
        "csv",
        "project",
        "table",
        "max_bad_records",
        "credentials_json",
        "batching"
      ],
      "type": "object"
    },
    "gcp_bigquery_select": {
      "description": "Executes a `SELECT` query against BigQuery and replaces messages with the rows returned.",
      "properties": {
        "args_mapping": {
          "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `where`.",
          "type": "string"
        },
        "columns": {
          "description": "A list of columns to query.",
          "type": "string"
        },
        "credentials_json": {
          "default": "",
          "description": "An optional field to set Google Service Account Credentials json.",
          "type": "string"
        },
        "job_labels": {
          "default": {},
          "description": "A list of labels to add to the query job.",
          "type": "string"
        },
        "prefix": {
          "description": "An optional prefix to prepend to the select query (before SELECT).",
          "type": "string"
        },
        "project": {
          "description": "GCP project where the query job will execute.",
          "type": "string"
        },
        "suffix": {
          "description": "An optional suffix to append to the select query.",
          "type": "string"
        },
        "table": {
          "description": "Fully-qualified BigQuery table name to query.",
          "type": "string"
        },
        "where": {
          "description": "An optional where clause to add. Placeholder arguments are populated with the `args_mapping` field. Placeholders should always be question marks (`?`).",
          "type": "string"
        }
      },
      "required": [
        "columns",
        "project",
        "credentials_json",
        "table",
        "job_labels"
      ],
      "type": "object"
    },
    "gcp_cloud_storage": {
      "description": "\nIn order to have a different path for each object you should use function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries], which are calculated per message of a batch.\n\n== Metadata\n\nMetadata fields on messages will be sent as headers, in order to mutate these values (or remove them) check out the xref:configuration:metadata.adoc[metadata docs].\n\n== Credentials\n\nBy default Redpanda Connect will use a shared credentials file when connecting to GCP services. You can find out more in xref:guides:cloud/gcp.adoc[].\n\n== Batching\n\nIt's common to want to upload messages to Google Cloud Storage as batched archives, the easiest way to do this is to batch your messages at the output level and join the batch of messages with an xref:components:processors/archive.adoc[`archive`] and/or xref:components:processors/compress.adoc[`compress`] processor.\n\nFor example, if we wished to upload messages as a .tar.gz archive of documents we could achieve that with the following config:\n\n```yaml\noutput:\n  gcp_cloud_storage:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.tar.gz\n    batching:\n      count: 100\n      period: 10s\n      processors:\n        - archive:\n            format: tar\n        - compress:\n            algorithm: gzip\n```\n\nAlternatively, if we wished to upload JSON documents as a single large document containing an array of objects we can do that with:\n\n```yaml\noutput:\n  gcp_cloud_storage:\n    bucket: TODO\n    path: ${!counter()}-${!timestamp_unix_nano()}.json\n    batching:\n      count: 100\n      processors:\n        - archive:\n            format: json_array\n```\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "bucket": {
          "description": "The bucket to upload messages to.",
          "type": "string"
        },
        "chunk_size": {
          "default": 16777216,
          "description": "An optional chunk size which controls the maximum number of bytes of the object that the Writer will attempt to send to the server in a single request. If ChunkSize is set to zero, chunking will be disabled.",
          "type": "number",
          "x-advanced": true
        },
        "collision_mode": {
          "default": "overwrite",
          "description": "Determines how file path collisions should be dealt with.",
          "type": "string"
        },
        "content_encoding": {
          "default": "",
          "description": "An optional content encoding to set for each object.",
          "type": "string",
          "x-advanced": true
        },
        "content_type": {
          "default": "application/octet-stream",
          "description": "The content type to set for each object.",
          "type": "string"
        },
        "credentials_json": {
          "default": "",
          "description": "An optional field to set Google Service Account Credentials json.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of message batches to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "path": {
          "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
          "description": "The path of each message to upload.",
          "type": "string"
        },
        "timeout": {
          "default": "3s",
          "description": "The maximum period to wait on an upload before abandoning it and reattempting.",
          "type": "string"
        }
      },
      "required": [
        "timeout",
        "batching",
        "bucket",
        "content_type",
        "chunk_size",
        "credentials_json",
        "max_in_flight",
        "path",
        "content_encoding",
        "collision_mode"
      ],
      "type": "object"
    },
    "gcp_pubsub": {
      "description": "\nFor information on how to set up credentials, see https://cloud.google.com/docs/authentication/production[this guide^].\n\n== Troubleshooting\n\nIf you're consistently seeing `Failed to send message to gcp_pubsub: context deadline exceeded` error logs without any further information it is possible that you are encountering https://github.com/benthosdev/benthos/issues/1042, which occurs when metadata values contain characters that are not valid utf-8. This can frequently occur when consuming from Kafka as the key metadata field may be populated with an arbitrary binary value, but this issue is not exclusive to Kafka.\n\nIf you are blocked by this issue then a work around is to delete either the specific problematic keys:\n\n```yaml\npipeline:\n  processors:\n    - mapping: |\n        meta kafka_key = deleted()\n```\n\nOr delete all keys with:\n\n```yaml\npipeline:\n  processors:\n    - mapping: meta = deleted()\n```",
      "properties": {
        "batching": {
          "description": "Configures a batching policy on this output. While the PubSub client maintains its own internal buffering mechanism, preparing larger batches of messages can further trade-off some latency for throughput.",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "byte_threshold": {
          "default": 1000000,
          "description": "Publish a batch when its size in bytes reaches this value.",
          "type": "number"
        },
        "count_threshold": {
          "default": 100,
          "description": "Publish a pubsub buffer when it has this many messages",
          "type": "number"
        },
        "credentials_json": {
          "default": "",
          "description": "An optional field to set Google Service Account Credentials json.",
          "type": "string"
        },
        "delay_threshold": {
          "default": "10ms",
          "description": "Publish a non-empty pubsub buffer after this delay has passed.",
          "type": "string"
        },
        "endpoint": {
          "default": "",
          "description": "An optional endpoint to override the default of `pubsub.googleapis.com:443`. This can be used to connect to a region specific pubsub endpoint. For a list of valid values, see https://cloud.google.com/pubsub/docs/reference/service_apis_overview#list_of_regional_endpoints[this document^].",
          "type": "string"
        },
        "flow_control": {
          "description": "For a given topic, configures the PubSub client's internal buffer for messages to be published.",
          "properties": {
            "limit_exceeded_behavior": {
              "default": "block",
              "description": "Configures the behavior when trying to publish additional messages while the flow controller is full. The available options are block (default), ignore (disable), and signal_error (publish results will return an error).",
              "enum": [
                "ignore",
                "block",
                "signal_error"
              ],
              "type": "string",
              "x-advanced": true
            },
            "max_outstanding_bytes": {
              "default": -1,
              "description": "Maximum size of buffered messages to be published. If less than or equal to zero, this is disabled.",
              "type": "number",
              "x-advanced": true
            },
            "max_outstanding_messages": {
              "default": 1000,
              "description": "Maximum number of buffered messages to be published. If less than or equal to zero, this is disabled.",
              "type": "number",
              "x-advanced": true
            }
          },
          "required": [
            "max_outstanding_bytes",
            "max_outstanding_messages",
            "limit_exceeded_behavior"
          ],
          "type": "object",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increasing this may improve throughput.",
          "type": "number"
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are sent as attributes, all are sent by default.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "ordering_key": {
          "description": "The ordering key to use for publishing messages.",
          "type": "string",
          "x-advanced": true
        },
        "project": {
          "description": "The project ID of the topic to publish to.",
          "type": "string"
        },
        "publish_timeout": {
          "default": "1m0s",
          "description": "The maximum length of time to wait before abandoning a publish attempt for a message.",
          "type": "string",
          "x-advanced": true
        },
        "topic": {
          "description": "The topic to publish to.",
          "type": "string"
        }
      },
      "required": [
        "flow_control",
        "project",
        "credentials_json",
        "endpoint",
        "max_in_flight",
        "count_threshold",
        "delay_threshold",
        "batching",
        "topic",
        "byte_threshold",
        "publish_timeout"
      ],
      "type": "object"
    },
    "generate": {
      "description": "Generates messages at a given interval using a xref:guides:bloblang/about.adoc[Bloblang] mapping executed without a context. This allows you to generate messages for testing your pipeline configs.",
      "properties": {
        "auto_replay_nacks": {
          "default": true,
          "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
          "type": "boolean"
        },
        "batch_size": {
          "default": 1,
          "description": "The number of generated messages that should be accumulated into each batch flushed at the specified interval.",
          "type": "number"
        },
        "count": {
          "default": 0,
          "description": "An optional number of messages to generate, if set above 0 the specified number of messages is generated and then the input will shut down.",
          "type": "number"
        },
        "interval": {
          "default": "1s",
          "description": "The time interval at which messages should be generated, expressed either as a duration string or as a cron expression. If set to an empty string messages will be generated as fast as downstream services can process them. Cron expressions can specify a timezone by prefixing the expression with `TZ=\u003clocation name\u003e`, where the location name corresponds to a file within the IANA Time Zone database.",
          "type": "string"
        },
        "mapping": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang] mapping to use for generating messages.",
          "type": "string"
        }
      },
      "required": [
        "mapping",
        "interval",
        "count",
        "batch_size",
        "auto_replay_nacks"
      ],
      "type": "object"
    },
    "grok": {
      "description": "\nType hints within patterns are respected, therefore with the pattern `%\\{WORD:first},%{INT:second:int}` and a payload of `foo,1` the resulting payload would be `\\{\"first\":\"foo\",\"second\":1}`.\n\n== Performance\n\nThis processor currently uses the https://golang.org/s/re2syntax[Go RE2^] regular expression engine, which is guaranteed to run in time linear to the size of the input. However, this property often makes it less performant than PCRE based implementations of grok. For more information, see https://swtch.com/~rsc/regexp/regexp1.html.",
      "properties": {
        "expressions": {
          "description": "One or more Grok expressions to attempt against incoming messages. The first expression to match at least one value will be used to form a result.",
          "type": "string"
        },
        "named_captures_only": {
          "default": true,
          "description": "Whether to only capture values from named patterns.",
          "type": "boolean",
          "x-advanced": true
        },
        "pattern_definitions": {
          "default": {},
          "description": "A map of pattern definitions that can be referenced within `patterns`.",
          "type": "string"
        },
        "pattern_paths": {
          "default": [],
          "description": "A list of paths to load Grok patterns from. This field supports wildcards, including super globs (double star).",
          "type": "string"
        },
        "remove_empty_values": {
          "default": true,
          "description": "Whether to remove values that are empty from the resulting structure.",
          "type": "boolean",
          "x-advanced": true
        },
        "use_default_patterns": {
          "default": true,
          "description": "Whether to use a \u003c\u003cdefault-patterns, default set of patterns\u003e\u003e.",
          "type": "boolean",
          "x-advanced": true
        }
      },
      "required": [
        "expressions",
        "pattern_definitions",
        "pattern_paths",
        "named_captures_only",
        "use_default_patterns",
        "remove_empty_values"
      ],
      "type": "object"
    },
    "group_by": {
      "description": "\nOnce the groups are established a list of processors are applied to their respective grouped batch, which can be used to label the batch as per their grouping. Messages that do not pass the check of any specified group are placed in their own group.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "check": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message belongs to a given group.",
          "type": "string"
        },
        "processors": {
          "default": [],
          "description": "A list of xref:components:processors/about.adoc[processors] to execute on the newly formed group.",
          "type": "string"
        }
      },
      "required": [
        "check",
        "processors"
      ],
      "type": "object"
    },
    "group_by_value": {
      "description": "\nThis allows you to group messages using arbitrary fields within their content or metadata, process them individually, and send them to unique locations as per their group.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "value": {
          "description": "The interpolated string to group based on.",
          "type": "string"
        }
      },
      "required": [
        "value"
      ],
      "type": "object"
    },
    "hdfs": {
      "description": "Each file is written with the path specified with the 'path' field, in order to have a different path for each object you should use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "directory": {
          "description": "A directory to store message files within. If the directory does not exist it will be created.",
          "type": "string"
        },
        "hosts": {
          "description": "A list of target host addresses to connect to.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "path": {
          "default": "${!counter()}-${!timestamp_unix_nano()}.txt",
          "description": "The path to upload messages as, interpolation functions should be used in order to generate unique file paths.",
          "type": "string"
        },
        "user": {
          "default": "",
          "description": "A user ID to connect as.",
          "type": "string"
        }
      },
      "required": [
        "directory",
        "path",
        "max_in_flight",
        "batching",
        "hosts",
        "user"
      ],
      "type": "object"
    },
    "http": {
      "description": "\nThe `rate_limit` field can be used to specify a rate limit xref:components:rate_limits/about.adoc[resource] to cap the rate of requests across all parallel components service wide.\n\nThe URL and header values of this type can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here].\n\nIn order to map or encode the payload to a specific request body, and map the response back into the original payload instead of replacing it entirely, you can use the xref:components:processors/branch.adoc[`branch` processor].\n\n== Response codes\n\nRedpanda Connect considers any response code between 200 and 299 inclusive to indicate a successful response, you can add more success status codes with the field `successful_on`.\n\nWhen a request returns a response code within the `backoff_on` field it will be retried after increasing intervals.\n\nWhen a request returns a response code within the `drop_on` field it will not be reattempted and is immediately considered a failed request.\n\n== Add metadata\n\nIf the request returns an error response code this processor sets a metadata field `http_status_code` on the resulting message.\n\nUse the field `extract_headers` to specify rules for which other headers should be copied into the resulting message from the response.\n\n== Error handling\n\nWhen all retry attempts for a message are exhausted the processor cancels the attempt. These failed messages will continue through the pipeline unchanged, but can be dropped or placed in a dead letter queue according to your config, you can read about xref:configuration:error_handling.adoc[these patterns].",
      "properties": {
        "backoff_on": {
          "default": [
            429
          ],
          "description": "A list of status codes whereby the request should be considered to have failed and retries should be attempted, but the period between them should be increased gradually.",
          "type": "number",
          "x-advanced": true
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batch_as_multipart": {
          "default": false,
          "description": "Send message batches as a single request using https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^].",
          "type": "boolean",
          "x-advanced": true
        },
        "disable_http2": {
          "default": false,
          "description": "Whether or not to disable disable HTTP/2",
          "type": "boolean",
          "x-advanced": true
        },
        "drop_on": {
          "default": [],
          "description": "A list of status codes whereby the request should be considered to have failed but retries should not be attempted. This is useful for preventing wasted retries for requests that will never succeed. Note that with these status codes the _request_ is dropped, but _message_ that caused the request will not be dropped.",
          "type": "number",
          "x-advanced": true
        },
        "dump_request_log_level": {
          "default": "",
          "description": "EXPERIMENTAL: Optionally set a level at which the request and response payload of each request made will be logged.",
          "enum": [
            "TRACE",
            "DEBUG",
            "INFO",
            "WARN",
            "ERROR",
            "FATAL",
            ""
          ],
          "type": "string",
          "x-advanced": true
        },
        "extract_headers": {
          "description": "Specify which response headers should be added to resulting messages as metadata. Header keys are lowercased before matching, so ensure that your patterns target lowercased versions of the header keys that you expect.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string",
              "x-advanced": true
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object",
          "x-advanced": true
        },
        "follow_redirects": {
          "default": true,
          "description": "Whether or not to transparently follow redirects, i.e. responses with 300-399 status codes. If disabled, the response message will contain the body, status, and headers from the redirect response and the processor will not make a request to the URL set in the Location header of the response.",
          "type": "boolean",
          "x-advanced": true
        },
        "headers": {
          "default": {},
          "description": "A map of headers to add to the request.",
          "type": "string"
        },
        "jwt": {
          "description": "BETA: Allows you to specify JWT authentication.",
          "properties": {
            "claims": {
              "default": {},
              "description": "A value used to identify the claims that issued the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use JWT authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "headers": {
              "default": {},
              "description": "Add optional key/value headers to the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "private_key_file": {
              "default": "",
              "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
              "type": "string",
              "x-advanced": true
            },
            "signing_method": {
              "default": "",
              "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "private_key_file",
            "signing_method",
            "claims",
            "headers"
          ],
          "type": "object",
          "x-advanced": true
        },
        "max_retry_backoff": {
          "default": "300s",
          "description": "The maximum period to wait between failed requests.",
          "type": "string",
          "x-advanced": true
        },
        "metadata": {
          "description": "Specify optional matching rules to determine which metadata keys should be added to the HTTP request as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string",
              "x-advanced": true
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object",
          "x-advanced": true
        },
        "oauth": {
          "description": "Allows you to specify open authentication via OAuth version 1.",
          "properties": {
            "access_token": {
              "default": "",
              "description": "A value used to gain access to the protected resources on behalf of the user.",
              "type": "string",
              "x-advanced": true
            },
            "access_token_secret": {
              "default": "",
              "description": "A secret provided in order to establish ownership of a given access token.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_key": {
              "default": "",
              "description": "A value used to identify the client to the service provider.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_secret": {
              "default": "",
              "description": "A secret used to establish ownership of the consumer key.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use OAuth version 1 in requests.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "consumer_key",
            "consumer_secret",
            "access_token",
            "access_token_secret"
          ],
          "type": "object",
          "x-advanced": true
        },
        "oauth2": {
          "description": "Allows you to specify open authentication via OAuth version 2 using the client credentials token flow.",
          "properties": {
            "client_key": {
              "default": "",
              "description": "A value used to identify the client to the token provider.",
              "type": "string",
              "x-advanced": true
            },
            "client_secret": {
              "default": "",
              "description": "A secret used to establish ownership of the client key.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use OAuth version 2 in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "endpoint_params": {
              "default": {},
              "description": "A list of optional endpoint parameters, values should be arrays of strings.",
              "type": "string",
              "x-advanced": true
            },
            "scopes": {
              "default": [],
              "description": "A list of optional requested permissions.",
              "type": "string",
              "x-advanced": true
            },
            "token_url": {
              "default": "",
              "description": "The URL of the token provider.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "client_key",
            "client_secret",
            "token_url",
            "scopes"
          ],
          "type": "object",
          "x-advanced": true
        },
        "parallel": {
          "default": false,
          "description": "When processing batched messages, whether to send messages of the batch in parallel, otherwise they are sent serially.",
          "type": "boolean"
        },
        "proxy_url": {
          "description": "An optional HTTP proxy URL.",
          "type": "string",
          "x-advanced": true
        },
        "rate_limit": {
          "description": "An optional xref:components:rate_limits/about.adoc[rate limit] to throttle requests by.",
          "type": "string"
        },
        "retries": {
          "default": 3,
          "description": "The maximum number of retry attempts to make.",
          "type": "number",
          "x-advanced": true
        },
        "retry_period": {
          "default": "1s",
          "description": "The base period to wait between failed requests.",
          "type": "string",
          "x-advanced": true
        },
        "successful_on": {
          "default": [],
          "description": "A list of status codes whereby the attempt should be considered successful, this is useful for dropping requests that return non-2XX codes indicating that the message has been dealt with, such as a 303 See Other or a 409 Conflict. All 2XX codes are considered successful unless they are present within `backoff_on` or `drop_on`, regardless of this field.",
          "type": "number",
          "x-advanced": true
        },
        "timeout": {
          "default": "5s",
          "description": "A static timeout to apply to requests.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL to connect to.",
          "type": "string"
        },
        "verb": {
          "default": "POST",
          "description": "A verb to connect with",
          "type": "string"
        }
      },
      "required": [
        "verb",
        "dump_request_log_level",
        "jwt",
        "timeout",
        "retries",
        "parallel",
        "url",
        "tls",
        "extract_headers",
        "retry_period",
        "headers",
        "max_retry_backoff",
        "backoff_on",
        "disable_http2",
        "batch_as_multipart",
        "follow_redirects",
        "drop_on",
        "successful_on"
      ],
      "type": "object"
    },
    "http_client": {
      "description": "\nWhen the number of retries expires the output will reject the message, the behavior after this will depend on the pipeline but usually this simply means the send is attempted again until successful whilst applying back pressure.\n\nThe URL and header values of this type can be dynamically set using function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].\n\nThe body of the HTTP request is the raw contents of the message payload. If the message has multiple parts (is a batch) the request will be sent according to https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. This behavior can be disabled by setting the field \u003c\u003cbatch_as_multipart, `batch_as_multipart`\u003e\u003e to `false`.\n\n== Propagate responses\n\nIt's possible to propagate the response from each HTTP request back to the input source by setting `propagate_response` to `true`. Only inputs that support xref:guides:sync_responses.adoc[synchronous responses] are able to make use of these propagated responses.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "backoff_on": {
          "default": [
            429
          ],
          "description": "A list of status codes whereby the request should be considered to have failed and retries should be attempted, but the period between them should be increased gradually.",
          "type": "number",
          "x-advanced": true
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batch_as_multipart": {
          "default": false,
          "description": "Send message batches as a single request using https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. If disabled messages in batches will be sent as individual requests.",
          "type": "boolean",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "disable_http2": {
          "default": false,
          "description": "Whether or not to disable disable HTTP/2",
          "type": "boolean",
          "x-advanced": true
        },
        "drop_on": {
          "default": [],
          "description": "A list of status codes whereby the request should be considered to have failed but retries should not be attempted. This is useful for preventing wasted retries for requests that will never succeed. Note that with these status codes the _request_ is dropped, but _message_ that caused the request will not be dropped.",
          "type": "number",
          "x-advanced": true
        },
        "dump_request_log_level": {
          "default": "",
          "description": "EXPERIMENTAL: Optionally set a level at which the request and response payload of each request made will be logged.",
          "enum": [
            "TRACE",
            "DEBUG",
            "INFO",
            "WARN",
            "ERROR",
            "FATAL",
            ""
          ],
          "type": "string",
          "x-advanced": true
        },
        "extract_headers": {
          "description": "Specify which response headers should be added to resulting synchronous response messages as metadata. Header keys are lowercased before matching, so ensure that your patterns target lowercased versions of the header keys that you expect. This field is not applicable unless `propagate_response` is set to `true`.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string",
              "x-advanced": true
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object",
          "x-advanced": true
        },
        "follow_redirects": {
          "default": true,
          "description": "Whether or not to transparently follow redirects, i.e. responses with 300-399 status codes. If disabled, the response message will contain the body, status, and headers from the redirect response and the processor will not make a request to the URL set in the Location header of the response.",
          "type": "boolean",
          "x-advanced": true
        },
        "headers": {
          "default": {},
          "description": "A map of headers to add to the request.",
          "type": "string"
        },
        "jwt": {
          "description": "BETA: Allows you to specify JWT authentication.",
          "properties": {
            "claims": {
              "default": {},
              "description": "A value used to identify the claims that issued the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use JWT authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "headers": {
              "default": {},
              "description": "Add optional key/value headers to the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "private_key_file": {
              "default": "",
              "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
              "type": "string",
              "x-advanced": true
            },
            "signing_method": {
              "default": "",
              "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "private_key_file",
            "signing_method",
            "claims",
            "headers"
          ],
          "type": "object",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of parallel message batches to have in flight at any given time.",
          "type": "number"
        },
        "max_retry_backoff": {
          "default": "300s",
          "description": "The maximum period to wait between failed requests.",
          "type": "string",
          "x-advanced": true
        },
        "metadata": {
          "description": "Specify optional matching rules to determine which metadata keys should be added to the HTTP request as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string",
              "x-advanced": true
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object",
          "x-advanced": true
        },
        "multipart": {
          "default": [],
          "description": "EXPERIMENTAL: Create explicit multipart HTTP requests by specifying an array of parts to add to the request, each part specified consists of content headers and a data field that can be populated dynamically. If this field is populated it will override the default request creation behavior.",
          "properties": {
            "body": {
              "default": "",
              "description": "The body of the individual message part.",
              "type": "string",
              "x-advanced": true
            },
            "content_disposition": {
              "default": "",
              "description": "The content disposition of the individual message part.",
              "type": "string",
              "x-advanced": true
            },
            "content_type": {
              "default": "",
              "description": "The content type of the individual message part.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "content_type",
            "content_disposition",
            "body"
          ],
          "type": "object",
          "x-advanced": true
        },
        "oauth": {
          "description": "Allows you to specify open authentication via OAuth version 1.",
          "properties": {
            "access_token": {
              "default": "",
              "description": "A value used to gain access to the protected resources on behalf of the user.",
              "type": "string",
              "x-advanced": true
            },
            "access_token_secret": {
              "default": "",
              "description": "A secret provided in order to establish ownership of a given access token.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_key": {
              "default": "",
              "description": "A value used to identify the client to the service provider.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_secret": {
              "default": "",
              "description": "A secret used to establish ownership of the consumer key.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use OAuth version 1 in requests.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "consumer_key",
            "consumer_secret",
            "access_token",
            "access_token_secret"
          ],
          "type": "object",
          "x-advanced": true
        },
        "oauth2": {
          "description": "Allows you to specify open authentication via OAuth version 2 using the client credentials token flow.",
          "properties": {
            "client_key": {
              "default": "",
              "description": "A value used to identify the client to the token provider.",
              "type": "string",
              "x-advanced": true
            },
            "client_secret": {
              "default": "",
              "description": "A secret used to establish ownership of the client key.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use OAuth version 2 in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "endpoint_params": {
              "default": {},
              "description": "A list of optional endpoint parameters, values should be arrays of strings.",
              "type": "string",
              "x-advanced": true
            },
            "scopes": {
              "default": [],
              "description": "A list of optional requested permissions.",
              "type": "string",
              "x-advanced": true
            },
            "token_url": {
              "default": "",
              "description": "The URL of the token provider.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "client_key",
            "client_secret",
            "token_url",
            "scopes"
          ],
          "type": "object",
          "x-advanced": true
        },
        "propagate_response": {
          "default": false,
          "description": "Whether responses from the server should be xref:guides:sync_responses.adoc[propagated back] to the input.",
          "type": "boolean",
          "x-advanced": true
        },
        "proxy_url": {
          "description": "An optional HTTP proxy URL.",
          "type": "string",
          "x-advanced": true
        },
        "rate_limit": {
          "description": "An optional xref:components:rate_limits/about.adoc[rate limit] to throttle requests by.",
          "type": "string"
        },
        "retries": {
          "default": 3,
          "description": "The maximum number of retry attempts to make.",
          "type": "number",
          "x-advanced": true
        },
        "retry_period": {
          "default": "1s",
          "description": "The base period to wait between failed requests.",
          "type": "string",
          "x-advanced": true
        },
        "successful_on": {
          "default": [],
          "description": "A list of status codes whereby the attempt should be considered successful, this is useful for dropping requests that return non-2XX codes indicating that the message has been dealt with, such as a 303 See Other or a 409 Conflict. All 2XX codes are considered successful unless they are present within `backoff_on` or `drop_on`, regardless of this field.",
          "type": "number",
          "x-advanced": true
        },
        "timeout": {
          "default": "5s",
          "description": "A static timeout to apply to requests.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL to connect to.",
          "type": "string"
        },
        "verb": {
          "default": "POST",
          "description": "A verb to connect with",
          "type": "string"
        }
      },
      "required": [
        "timeout",
        "backoff_on",
        "drop_on",
        "multipart",
        "verb",
        "extract_headers",
        "max_retry_backoff",
        "follow_redirects",
        "batch_as_multipart",
        "headers",
        "jwt",
        "retry_period",
        "successful_on",
        "max_in_flight",
        "tls",
        "retries",
        "disable_http2",
        "propagate_response",
        "batching",
        "url",
        "dump_request_log_level"
      ],
      "type": "object"
    },
    "http_server": {
      "description": "Sets up an HTTP server that will send messages over HTTP(S) GET requests. If the `address` config field is left blank the xref:components:http/about.adoc[service-wide HTTP server] will be used.\n\nThree endpoints will be registered at the paths specified by the fields `path`, `stream_path` and `ws_path`. Which allow you to consume a single message batch, a continuous stream of line delimited messages, or a websocket of messages for each request respectively.\n\nWhen messages are batched the `path` endpoint encodes the batch according to https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. This behavior can be overridden by xref:configuration:batching.adoc#post-batch-processing[archiving your batches].\n\nPlease note, messages are considered delivered as soon as the data is written to the client. There is no concept of at least once delivery on this output.\n\n\n[CAUTION]\n.Endpoint caveats\n====\nComponents within a Redpanda Connect config will register their respective endpoints in a non-deterministic order. This means that establishing precedence of endpoints that are registered via multiple `http_server` inputs or outputs (either within brokers or from cohabiting streams) is not possible in a predictable way.\n\nThis ambiguity makes it difficult to ensure that paths which are both a subset of a path registered by a separate component, and end in a slash (`/`) and will therefore match against all extensions of that path, do not prevent the more specific path from matching against requests.\n\nIt is therefore recommended that you ensure paths of separate components do not collide unless they are explicitly non-competing.\n\nFor example, if you were to deploy two separate `http_server` inputs, one with a path `/foo/` and the other with a path `/foo/bar`, it would not be possible to ensure that the path `/foo/` does not swallow requests made to `/foo/bar`.\n====\n",
      "properties": {
        "address": {
          "default": "",
          "description": "An alternative address to host from. If left empty the service wide address is used.",
          "type": "string"
        },
        "allowed_verbs": {
          "default": [
            "GET"
          ],
          "description": "An array of verbs that are allowed for the `path` and `stream_path` HTTP endpoint.",
          "type": "string"
        },
        "cert_file": {
          "default": "",
          "description": "Enable TLS by specifying a certificate and key file. Only valid with a custom `address`.",
          "type": "string",
          "x-advanced": true
        },
        "cors": {
          "description": "Adds Cross-Origin Resource Sharing headers. Only valid with a custom `address`.",
          "properties": {
            "allowed_origins": {
              "default": [],
              "description": "An explicit list of origins that are allowed for CORS requests.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to allow CORS requests.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "allowed_origins"
          ],
          "type": "object",
          "x-advanced": true
        },
        "key_file": {
          "default": "",
          "description": "Enable TLS by specifying a certificate and key file. Only valid with a custom `address`.",
          "type": "string",
          "x-advanced": true
        },
        "path": {
          "default": "/get",
          "description": "The path from which discrete messages can be consumed.",
          "type": "string"
        },
        "stream_path": {
          "default": "/get/stream",
          "description": "The path from which a continuous stream of messages can be consumed.",
          "type": "string"
        },
        "timeout": {
          "default": "5s",
          "description": "The maximum time to wait before a blocking, inactive connection is dropped (only applies to the `path` endpoint).",
          "type": "string",
          "x-advanced": true
        },
        "ws_path": {
          "default": "/get/ws",
          "description": "The path from which websocket connections can be established.",
          "type": "string"
        }
      },
      "required": [
        "key_file",
        "stream_path",
        "ws_path",
        "timeout",
        "cert_file",
        "cors",
        "address",
        "path",
        "allowed_verbs"
      ],
      "type": "object"
    },
    "inproc": {
      "description": "\nSends data directly to Redpanda Connect inputs by connecting to a unique ID. This allows you to hook up isolated streams whilst running Redpanda Connect in xref:guides:streams_mode/about.adoc[streams mode], it is NOT recommended that you connect the inputs of a stream with an output of the same stream, as feedback loops can lead to deadlocks in your message flow.\n\nIt is possible to connect multiple inputs to the same inproc ID, resulting in messages dispatching in a round-robin fashion to connected inputs. However, only one output can assume an inproc ID, and will replace existing outputs if a collision occurs.",
      "type": "object"
    },
    "insert_part": {
      "description": "\nThe index can be negative, and if so the message will be inserted from the end counting backwards starting from -1. E.g. if index = -1 then the new message will become the last of the batch, if index = -2 then the new message will be inserted before the last message, and so on. If the negative index is greater than the length of the existing batch it will be inserted at the beginning.\n\nThe new message will have metadata copied from the first pre-existing message of the batch.\n\nThis processor will interpolate functions within the 'content' field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].",
      "properties": {
        "content": {
          "default": "",
          "description": "The content of the message being inserted.",
          "type": "string"
        },
        "index": {
          "default": -1,
          "description": "The index within the batch to insert the message at.",
          "type": "number"
        }
      },
      "required": [
        "index",
        "content"
      ],
      "type": "object"
    },
    "javascript": {
      "description": "\nThe https://github.com/dop251/goja[execution engine^] behind this processor provides full ECMAScript 5.1 support (including regex and strict mode). Most of the ECMAScript 6 spec is implemented but this is a work in progress.\n\nImports via `require` should work similarly to NodeJS, and access to the console is supported which will print via the Redpanda Connect logger. More caveats can be found on https://github.com/dop251/goja#known-incompatibilities-and-caveats[GitHub^].\n\nThis processor is implemented using the https://github.com/dop251/goja[github.com/dop251/goja^] library.",
      "properties": {
        "code": {
          "description": "An inline JavaScript program to run. One of `code` or `file` must be defined.",
          "type": "string"
        },
        "file": {
          "description": "A file containing a JavaScript program to run. One of `code` or `file` must be defined.",
          "type": "string"
        },
        "global_folders": {
          "default": [],
          "description": "List of folders that will be used to load modules from if the requested JS module is not found elsewhere.",
          "type": "string"
        }
      },
      "required": [
        "global_folders"
      ],
      "type": "object"
    },
    "jmespath": {
      "description": "\n[TIP]\n.Try out Bloblang\n====\nFor better performance and improved capabilities try native Redpanda Connect mapping with the xref:components:processors/mapping.adoc[`mapping` processor].\n====\n",
      "properties": {
        "query": {
          "description": "The JMESPath query to apply to messages.",
          "type": "string"
        }
      },
      "required": [
        "query"
      ],
      "type": "object"
    },
    "jq": {
      "description": "\n[TIP]\n.Try out Bloblang\n====\nFor better performance and improved capabilities try out native Redpanda Connect mapping with the xref:components:processors/mapping.adoc[`mapping` processor].\n====\n\nThe provided query is executed on each message, targeting either the contents as a structured JSON value or as a raw string using the field `raw`, and the message is replaced with the query result.\n\nMessage metadata is also accessible within the query from the variable `$metadata`.\n\nThis processor uses the https://github.com/itchyny/gojq[gojq library^], and therefore does not require jq to be installed as a dependency. However, this also means there are some https://github.com/itchyny/gojq#difference-to-jq[differences in how these queries are executed^] versus the jq cli.\n\nIf the query does not emit any value then the message is filtered, if the query returns multiple values then the resulting message will be an array containing all values.\n\nThe full query syntax is described in https://stedolan.github.io/jq/manual/[jq's documentation^].\n\n== Error handling\n\nQueries can fail, in which case the message remains unchanged, errors are logged, and the message is flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].",
      "properties": {
        "output_raw": {
          "default": false,
          "description": "Whether to output raw text (unquoted) instead of JSON strings when the emitted values are string types.",
          "type": "boolean",
          "x-advanced": true
        },
        "query": {
          "description": "The jq query to filter and transform messages with.",
          "type": "string"
        },
        "raw": {
          "default": false,
          "description": "Whether to process the input as a raw string instead of as JSON.",
          "type": "boolean",
          "x-advanced": true
        }
      },
      "required": [
        "raw",
        "output_raw",
        "query"
      ],
      "type": "object"
    },
    "json_schema": {
      "description": "Please refer to the https://json-schema.org/[JSON Schema website^] for information and tutorials regarding the syntax of the schema.",
      "properties": {
        "schema": {
          "description": "A schema to apply. Use either this or the `schema_path` field.",
          "type": "string"
        },
        "schema_path": {
          "description": "The path of a schema document to apply. Use either this or the `schema` field.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "kafka": {
      "description": "\nThe config field `ack_replicas` determines whether we wait for acknowledgement from all replicas or just a single broker.\n\nBoth the `key` and `topic` fields can be dynamically set using function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].\n\nxref:configuration:metadata.adoc[Metadata] will be added to each message sent as headers (version 0.11+), but can be restricted using the field \u003c\u003cmetadata, `metadata`\u003e\u003e.\n\n== Strict ordering and retries\n\nWhen strict ordering is required for messages written to topic partitions it is important to ensure that both the field `max_in_flight` is set to `1` and that the field `retry_as_batch` is set to `true`.\n\nYou must also ensure that failed batches are never rerouted back to the same output. This can be done by setting the field `max_retries` to `0` and `backoff.max_elapsed_time` to empty, which will apply back pressure indefinitely until the batch is sent successfully.\n\nHowever, this also means that manual intervention will eventually be required in cases where the batch cannot be sent due to configuration problems such as an incorrect `max_msg_bytes` estimate. A less strict but automated alternative would be to route failed batches to a dead letter queue using a xref:components:outputs/fallback.adoc[`fallback` broker], but this would allow subsequent batches to be delivered in the meantime whilst those failed batches are dealt with.\n\n== Troubleshooting\n\nIf you're seeing issues writing to or reading from Kafka with this component then it's worth trying out the newer xref:components:outputs/kafka_franz.adoc[`kafka_franz` output].\n\n- I'm seeing logs that report `Failed to connect to kafka: kafka: client has run out of available brokers to talk to (Is your cluster reachable?)`, but the brokers are definitely reachable.\n\nUnfortunately this error message will appear for a wide range of connection problems even when the broker endpoint can be reached. Double check your authentication configuration and also ensure that you have \u003c\u003ctlsenabled, enabled TLS\u003e\u003e if applicable.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "ack_replicas": {
          "default": false,
          "description": "Ensure that messages have been copied across all replicas before acknowledging receipt.",
          "type": "boolean",
          "x-advanced": true
        },
        "addresses": {
          "description": "A list of broker addresses to connect to. If an item of the list contains commas it will be expanded into multiple addresses.",
          "type": "string"
        },
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "3s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "30s",
              "description": "The maximum overall period of time to spend on retry attempts before the request is aborted. Setting this value to a zeroed duration (such as `0s`) will result in unbounded retries.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "10s",
              "description": "The maximum period to wait between retry attempts",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "client_id": {
          "default": "benthos",
          "description": "An identifier for the client connection.",
          "type": "string",
          "x-advanced": true
        },
        "compression": {
          "default": "none",
          "description": "The compression algorithm to use.",
          "enum": [
            "none",
            "snappy",
            "lz4",
            "gzip",
            "zstd"
          ],
          "type": "string"
        },
        "custom_topic_creation": {
          "description": "If enabled, topics will be created with the specified number of partitions and replication factor if they do not already exist.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to enable custom topic creation.",
              "type": "boolean",
              "x-advanced": true
            },
            "partitions": {
              "default": -1,
              "description": "The number of partitions to create for new topics. Leave at -1 to use the broker configured default. Must be \u003e= 1.",
              "type": "number",
              "x-advanced": true
            },
            "replication_factor": {
              "default": -1,
              "description": "The replication factor to use for new topics. Leave at -1 to use the broker configured default. Must be an odd number, and less then or equal to the number of brokers.",
              "type": "number",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "partitions",
            "replication_factor"
          ],
          "type": "object",
          "x-advanced": true
        },
        "idempotent_write": {
          "default": false,
          "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
          "type": "boolean",
          "x-advanced": true
        },
        "inject_tracing_map": {
          "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
          "type": "string",
          "x-advanced": true
        },
        "key": {
          "default": "",
          "description": "The key to publish messages with.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "max_msg_bytes": {
          "default": 1000000,
          "description": "The maximum size in bytes of messages sent to the target topic.",
          "type": "number",
          "x-advanced": true
        },
        "max_retries": {
          "default": 0,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are sent with messages as headers.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "partition": {
          "default": "",
          "description": "The manually-specified partition to publish messages to, relevant only when the field `partitioner` is set to `manual`. Must be able to parse as a 32-bit integer.",
          "type": "string",
          "x-advanced": true
        },
        "partitioner": {
          "default": "fnv1a_hash",
          "description": "The partitioning algorithm to use.",
          "enum": [
            "fnv1a_hash",
            "murmur2_hash",
            "random",
            "round_robin",
            "manual"
          ],
          "type": "string"
        },
        "rack_id": {
          "default": "",
          "description": "A rack identifier for this client.",
          "type": "string",
          "x-advanced": true
        },
        "retry_as_batch": {
          "default": false,
          "description": "When enabled forces an entire batch of messages to be retried if any individual message fails on a send, otherwise only the individual messages that failed are retried. Disabling this helps to reduce message duplicates during intermittent errors, but also makes it impossible to guarantee strict ordering of messages.",
          "type": "boolean",
          "x-advanced": true
        },
        "sasl": {
          "description": "Enables SASL authentication.",
          "properties": {
            "access_token": {
              "default": "",
              "description": "A static OAUTHBEARER access token",
              "type": "string",
              "x-advanced": true
            },
            "mechanism": {
              "default": "none",
              "description": "The SASL authentication mechanism, if left empty SASL authentication is not used.",
              "type": "string",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A PLAIN password. It is recommended that you use environment variables to populate this field.",
              "type": "string",
              "x-advanced": true
            },
            "token_cache": {
              "default": "",
              "description": "Instead of using a static `access_token` allows you to query a xref:components:caches/about.adoc[`cache`] resource to fetch OAUTHBEARER tokens from",
              "type": "string",
              "x-advanced": true
            },
            "token_key": {
              "default": "",
              "description": "Required when using a `token_cache`, the key to query the cache with for tokens.",
              "type": "string",
              "x-advanced": true
            },
            "user": {
              "default": "",
              "description": "A PLAIN username. It is recommended that you use environment variables to populate this field.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "mechanism",
            "user",
            "password",
            "access_token",
            "token_cache",
            "token_key"
          ],
          "type": "object",
          "x-advanced": true
        },
        "static_headers": {
          "description": "An optional map of static headers that should be added to messages in addition to metadata.",
          "type": "string"
        },
        "target_version": {
          "description": "The version of the Kafka protocol to use. This limits the capabilities used by the client and should ideally match the version of your brokers. Defaults to the oldest supported stable version.",
          "type": "string"
        },
        "timeout": {
          "default": "5s",
          "description": "The maximum period of time to wait for message sends before abandoning the request and retrying.",
          "type": "string",
          "x-advanced": true
        },
        "timestamp": {
          "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
          "type": "string",
          "x-advanced": true
        },
        "timestamp_ms": {
          "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "topic": {
          "description": "The topic to publish messages to.",
          "type": "string"
        }
      },
      "required": [
        "metadata",
        "max_retries",
        "backoff",
        "addresses",
        "key",
        "partitioner",
        "ack_replicas",
        "timeout",
        "tls",
        "partition",
        "max_in_flight",
        "idempotent_write",
        "retry_as_batch",
        "topic",
        "max_msg_bytes",
        "batching",
        "client_id",
        "rack_id",
        "compression"
      ],
      "type": "object"
    },
    "kafka_franz": {
      "description": "\nWrites a batch of messages to Kafka brokers and waits for acknowledgement before propagating it back to the input.\n\nThis output often out-performs the traditional `kafka` output as well as providing more useful logs and error messages.\n",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "broker_write_max_bytes": {
          "default": "100MiB",
          "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
          "type": "string",
          "x-advanced": true
        },
        "client_id": {
          "default": "benthos",
          "description": "An identifier for the client connection.",
          "type": "string",
          "x-advanced": true
        },
        "compression": {
          "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
          "enum": [
            "lz4",
            "snappy",
            "gzip",
            "none",
            "zstd"
          ],
          "type": "string",
          "x-advanced": true
        },
        "idempotent_write": {
          "default": true,
          "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
          "type": "boolean",
          "x-advanced": true
        },
        "key": {
          "description": "An optional key to populate for each message.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 10,
          "description": "The maximum number of batches to be sending in parallel at any given time.",
          "type": "number"
        },
        "max_message_bytes": {
          "default": "1MiB",
          "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
          "type": "string",
          "x-advanced": true
        },
        "metadata": {
          "description": "Determine which (if any) metadata values should be added to messages as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string"
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string"
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object"
        },
        "metadata_max_age": {
          "default": "5m",
          "description": "The maximum age of metadata before it is refreshed.",
          "type": "string",
          "x-advanced": true
        },
        "partition": {
          "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
          "type": "string"
        },
        "partitioner": {
          "description": "Override the default murmur2 hashing partitioner.",
          "type": "string",
          "x-advanced": true
        },
        "rack_id": {
          "type": "string"
        },
        "sasl": {
          "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
          "properties": {
            "aws": {
              "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
              "properties": {
                "credentials": {
                  "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                  "properties": {
                    "from_ec2_role": {
                      "default": false,
                      "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                      "type": "boolean",
                      "x-advanced": true
                    },
                    "id": {
                      "default": "",
                      "description": "The ID of credentials to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "profile": {
                      "default": "",
                      "description": "A profile from `~/.aws/credentials` to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "role": {
                      "default": "",
                      "description": "A role ARN to assume.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "role_external_id": {
                      "default": "",
                      "description": "An external ID to provide when assuming a role.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "secret": {
                      "default": "",
                      "description": "The secret for the credentials being used.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "token": {
                      "default": "",
                      "description": "The token for the credentials being used, required when using short term credentials.",
                      "type": "string",
                      "x-advanced": true
                    }
                  },
                  "required": [
                    "profile",
                    "id",
                    "secret",
                    "token",
                    "from_ec2_role",
                    "role",
                    "role_external_id"
                  ],
                  "type": "object",
                  "x-advanced": true
                },
                "endpoint": {
                  "default": "",
                  "description": "Allows you to specify a custom endpoint for the AWS API.",
                  "type": "string",
                  "x-advanced": true
                },
                "region": {
                  "default": "",
                  "description": "The AWS region to target.",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "region",
                "endpoint",
                "credentials"
              ],
              "type": "object",
              "x-advanced": true
            },
            "extensions": {
              "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
              "type": "string",
              "x-advanced": true
            },
            "mechanism": {
              "description": "The SASL mechanism to use.",
              "type": "string",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to provide for PLAIN or SCRAM-* authentication.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token to use for a single session's OAUTHBEARER authentication.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to provide for PLAIN or SCRAM-* authentication.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "mechanism",
            "username",
            "password",
            "token"
          ],
          "type": "object",
          "x-advanced": true
        },
        "seed_brokers": {
          "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
          "type": "string"
        },
        "timeout": {
          "default": "10s",
          "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
          "type": "string",
          "x-advanced": true
        },
        "timestamp": {
          "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
          "type": "string",
          "x-advanced": true
        },
        "timestamp_ms": {
          "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "topic": {
          "description": "A topic to write messages to.",
          "type": "string"
        }
      },
      "required": [
        "max_in_flight",
        "batching",
        "client_id",
        "topic",
        "timeout",
        "seed_brokers",
        "tls",
        "metadata_max_age",
        "idempotent_write",
        "broker_write_max_bytes",
        "rack_id",
        "max_message_bytes"
      ],
      "type": "object"
    },
    "log": {
      "description": "\nThe `level` field determines the log level of the printed events and can be any of the following values: TRACE, DEBUG, INFO, WARN, ERROR.\n\n== Structured fields\n\nIt's also possible add custom fields to logs when the format is set to a structured form such as `json` or `logfmt` with the config field \u003c\u003cfields_mapping, `fields_mapping`\u003e\u003e:\n\n```yaml\npipeline:\n  processors:\n    - log:\n        level: DEBUG\n        message: hello world\n        fields_mapping: |\n          root.reason = \"cus I wana\"\n          root.id = this.id\n          root.age = this.user.age\n          root.kafka_topic = meta(\"kafka_topic\")\n```\n",
      "properties": {
        "fields": {
          "description": "A map of fields to print along with the log message.",
          "type": "string"
        },
        "fields_mapping": {
          "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that can be used to specify extra fields to add to the log. If log fields are also added with the `fields` field then those values will override matching keys from this mapping.",
          "type": "string"
        },
        "level": {
          "default": "INFO",
          "description": "The log level to use.",
          "enum": [
            "ERROR",
            "WARN",
            "INFO",
            "DEBUG",
            "TRACE"
          ],
          "type": "string"
        },
        "message": {
          "default": "",
          "description": "The message to print.",
          "type": "string"
        }
      },
      "required": [
        "level",
        "message"
      ],
      "type": "object"
    },
    "mapping": {
      "description": "\nBloblang is a powerful language that enables a wide range of mapping, transformation and filtering tasks. For more information, see xref:guides:bloblang/about.adoc[].\n\nIf your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"\u003cpath\u003e\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from.\n\nNote: This processor is equivalent to the xref:components:processors/bloblang.adoc#component-rename[Bloblang] one. The latter will be deprecated in a future release.\n\n== Input document immutability\n\nMapping operates by creating an entirely new object during assignments, this has the advantage of treating the original referenced document as immutable and therefore queryable at any stage of your mapping. For example, with the following mapping:\n\n```coffeescript\nroot.id = this.id\nroot.invitees = this.invitees.filter(i -\u003e i.mood \u003e= 0.5)\nroot.rejected = this.invitees.filter(i -\u003e i.mood \u003c 0.5)\n```\n\nNotice that we mutate the value of `invitees` in the resulting document by filtering out objects with a lower mood. However, even after doing so we're still able to reference the unchanged original contents of this value from the input document in order to populate a second field. Within this mapping we also have the flexibility to reference the mutable mapped document by using the keyword `root` (i.e. `root.invitees`) on the right-hand side instead.\n\nMapping documents is advantageous in situations where the result is a document with a dramatically different shape to the input document, since we are effectively rebuilding the document in its entirety and might as well keep a reference to the unchanged input document throughout. However, in situations where we are only performing minor alterations to the input document, the rest of which is unchanged, it might be more efficient to use the xref:components:processors/mutation.adoc[`mutation` processor] instead.\n\n== Error handling\n\nBloblang mappings can fail, in which case the message remains unchanged, errors are logged, and the message is flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].\n\nHowever, Bloblang itself also provides powerful ways of ensuring your mappings do not fail by specifying desired xref:guides:bloblang/about.adoc#error-handling[fallback behavior].\n\t\t\t",
      "type": "object"
    },
    "metric": {
      "description": "\nThis processor works by evaluating an xref:configuration:interpolation.adoc#bloblang-queries[interpolated field `value`] for each message and updating a emitted metric according to the \u003c\u003ctypes, type\u003e\u003e.\n\nCustom metrics such as these are emitted along with Redpanda Connect internal metrics, where you can customize where metrics are sent, which metric names are emitted and rename them as/when appropriate. For more information see the xref:components:metrics/about.adoc[metrics docs].",
      "properties": {
        "labels": {
          "description": "A map of label names and values that can be used to enrich metrics. Labels are not supported by some metric destinations, in which case the metrics series are combined.",
          "type": "string"
        },
        "name": {
          "description": "The name of the metric to create, this must be unique across all Redpanda Connect components otherwise it will overwrite those other metrics.",
          "type": "string"
        },
        "type": {
          "description": "The metric \u003c\u003ctypes, type\u003e\u003e to create.",
          "enum": [
            "counter",
            "counter_by",
            "gauge",
            "timing"
          ],
          "type": "string"
        },
        "value": {
          "default": "",
          "description": "For some metric types specifies a value to set, increment. Certain metrics exporters such as Prometheus support floating point values, but those that do not will cast a floating point value into an integer.",
          "type": "string"
        }
      },
      "required": [
        "type",
        "name",
        "value"
      ],
      "type": "object"
    },
    "modbus": {
      "description": "This input plugin enables Benthos to read data directly from Modbus devices using the Modbus protocol.",
      "properties": {
        "addresses": {
          "description": "List of Modbus addresses to read",
          "properties": {
            "address": {
              "description": "Address of the register to query",
              "type": "number"
            },
            "bit": {
              "default": 0,
              "description": "Bit of the register, only valid for BIT type",
              "type": "number"
            },
            "length": {
              "default": 0,
              "description": "Number of registers, only valid for STRING type",
              "type": "number"
            },
            "name": {
              "description": "Field name",
              "type": "string"
            },
            "output": {
              "default": "",
              "description": "Type of resulting field: 'INT64', 'UINT64', 'FLOAT64', or 'native'",
              "type": "string"
            },
            "register": {
              "default": "holding",
              "description": "Register type: 'coil', 'discrete', 'holding', or 'input'",
              "type": "string"
            },
            "scale": {
              "default": 0,
              "description": "Factor to scale the variable with",
              "type": "number"
            },
            "type": {
              "description": "Data type of the field",
              "type": "string"
            }
          },
          "required": [
            "name",
            "register",
            "address",
            "type",
            "length",
            "bit",
            "scale",
            "output"
          ],
          "type": "object"
        },
        "busyRetries": {
          "default": 3,
          "description": "Maximum number of retries when the device is busy",
          "type": "number",
          "x-advanced": true
        },
        "busyRetriesWait": {
          "default": "200ms",
          "description": "Time to wait between retries when the device is busy",
          "type": "string",
          "x-advanced": true
        },
        "byteOrder": {
          "default": "ABCD",
          "description": "Byte order: 'ABCD', 'DCBA', 'BADC', or 'CDAB'",
          "type": "string",
          "x-advanced": true
        },
        "controller": {
          "default": "tcp://localhost:502",
          "description": "The Modbus controller address, e.g., 'tcp://localhost:502'",
          "type": "string"
        },
        "optimization": {
          "default": "none",
          "description": "Request optimization algorithm: 'none' or 'max_insert'",
          "type": "string",
          "x-advanced": true
        },
        "optimizationMaxRegisterFill": {
          "default": 50,
          "description": "Maximum number of registers to insert for optimization",
          "type": "number",
          "x-advanced": true
        },
        "slaveID": {
          "default": 1,
          "description": "Slave ID of the Modbus device (deprecated: use slaveIDs for single or multiple slaves)",
          "type": "number",
          "x-advanced": true
        },
        "slaveIDs": {
          "default": [
            1
          ],
          "description": "Slave IDs to poll. Benthos polls each slave sequentially in the order specified, reads all configured addresses from each slave, and merges the results into a single message batch. All slaves share the same TCP connection. If a slave encounters an error, Benthos logs the error and continues to the next slave (except for fatal connection errors like broken pipe, which trigger reconnection).",
          "type": "number"
        },
        "timeBetweenReads": {
          "default": "1s",
          "description": "The time between two reads of a Modbus device. Useful if you want to read the device every x seconds. Not to be confused with TimeBetweenRequests.",
          "type": "string"
        },
        "timeout": {
          "default": "1s",
          "description": "Timeout for requests to the Modbus device",
          "type": "string",
          "x-advanced": true
        },
        "transmissionMode": {
          "default": "TCP",
          "description": "Transmission mode: 'TCP', 'RTUOverTCP', or 'ASCIIOverTCP'",
          "type": "string",
          "x-advanced": true
        },
        "workarounds": {
          "description": "Modbus workarounds. Required by some devices to work correctly. Should be left alone by default and must not be changed unless necessary.",
          "properties": {
            "oneRequestPerField": {
              "default": false,
              "description": "Send each field in a separate request",
              "type": "boolean",
              "x-advanced": true
            },
            "pauseAfterConnect": {
              "default": "0s",
              "description": "Pause after connect to delay the first request",
              "type": "string",
              "x-advanced": true
            },
            "readCoilsStartingAtZero": {
              "default": false,
              "description": "Read coils starting at address 0 instead of 1",
              "type": "boolean",
              "x-advanced": true
            },
            "stringRegisterLocation": {
              "default": "",
              "description": "String byte-location in registers: 'lower', 'upper', or empty for both",
              "type": "string",
              "x-advanced": true
            },
            "timeBetweenRequests": {
              "default": "0s",
              "description": "timeBetweenRequests is the time between two requests to the same device. Useful to avoid flooding the device. Not to be confused with TimeBetweenReads.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "pauseAfterConnect",
            "oneRequestPerField",
            "readCoilsStartingAtZero",
            "stringRegisterLocation",
            "timeBetweenRequests"
          ],
          "type": "object",
          "x-advanced": true
        }
      },
      "required": [
        "timeBetweenReads",
        "slaveIDs",
        "addresses",
        "controller"
      ],
      "type": "object"
    },
    "mongodb": {
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "app_name": {
          "default": "benthos",
          "description": "The client application name.",
          "type": "string",
          "x-advanced": true
        },
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "1s",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "30s",
              "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "5s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "collection": {
          "description": "The name of the target collection.",
          "type": "string"
        },
        "database": {
          "description": "The name of the target MongoDB database.",
          "type": "string"
        },
        "document_map": {
          "default": "",
          "description": "A bloblang map representing a document to store within MongoDB, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The document map is required for the operations insert-one, replace-one and update-one.",
          "type": "string"
        },
        "filter_map": {
          "default": "",
          "description": "A bloblang map representing a filter for a MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The filter map is required for all operations except insert-one. It is used to find the document(s) for the operation. For example in a delete-one case, the filter map should have the fields required to locate the document to delete.",
          "type": "string"
        },
        "hint_map": {
          "default": "",
          "description": "A bloblang map representing the hint for the MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. This map is optional and is used with all operations except insert-one. It is used to improve performance of finding the documents in the mongodb.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "max_retries": {
          "default": 3,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "operation": {
          "default": "update-one",
          "description": "The mongodb operation to perform.",
          "enum": [
            "insert-one",
            "delete-one",
            "delete-many",
            "replace-one",
            "update-one"
          ],
          "type": "string"
        },
        "password": {
          "default": "",
          "description": "The password to connect to the database.",
          "type": "string"
        },
        "upsert": {
          "default": false,
          "description": "The upsert setting is optional and only applies for update-one and replace-one operations. If the filter specified in filter_map matches, the document is updated or replaced accordingly, otherwise it is created.",
          "type": "boolean"
        },
        "url": {
          "description": "The URL of the target MongoDB server.",
          "type": "string"
        },
        "username": {
          "default": "",
          "description": "The username to connect to the database.",
          "type": "string"
        },
        "write_concern": {
          "description": "The write concern settings for the mongo connection.",
          "properties": {
            "j": {
              "default": false,
              "description": "J requests acknowledgement from MongoDB that write operations are written to the journal.",
              "type": "boolean"
            },
            "w": {
              "default": "majority",
              "description": "W requests acknowledgement that write operations propagate to the specified number of mongodb instances. Can be the string \"majority\" to wait for a calculated majority of nodes to acknowledge the write operation, or an integer value specifying an minimum number of nodes to acknowledge the operation, or a string specifying the name of a custom write concern configured in the cluster.",
              "type": "string"
            },
            "w_timeout": {
              "default": "",
              "description": "The write concern timeout.",
              "type": "string"
            }
          },
          "required": [
            "w",
            "j",
            "w_timeout"
          ],
          "type": "object"
        }
      },
      "required": [
        "app_name",
        "collection",
        "operation",
        "filter_map",
        "backoff",
        "url",
        "database",
        "username",
        "password",
        "write_concern",
        "upsert",
        "document_map",
        "max_in_flight",
        "batching",
        "hint_map",
        "max_retries"
      ],
      "type": "object"
    },
    "mqtt": {
      "description": "\nThe `topic` field can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "client_id": {
          "default": "",
          "description": "An identifier for the client connection.",
          "type": "string"
        },
        "connect_timeout": {
          "default": "30s",
          "description": "The maximum amount of time to wait in order to establish a connection before the attempt is abandoned.",
          "type": "string"
        },
        "dynamic_client_id_suffix": {
          "description": "Append a dynamically generated suffix to the specified `client_id` on each run of the pipeline. This can be useful when clustering Redpanda Connect producers.",
          "type": "string",
          "x-advanced": true
        },
        "keepalive": {
          "default": 30,
          "description": "Max seconds of inactivity before a keepalive message is sent.",
          "type": "number",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "password": {
          "default": "",
          "description": "A password to connect with.",
          "type": "string",
          "x-advanced": true
        },
        "qos": {
          "default": 1,
          "description": "The QoS value to set for each message. Has options 0, 1, 2.",
          "type": "number"
        },
        "retained": {
          "default": false,
          "description": "Set message as retained on the topic.",
          "type": "boolean"
        },
        "retained_interpolated": {
          "description": "Override the value of `retained` with an interpolable value, this allows it to be dynamically set based on message contents. The value must resolve to either `true` or `false`.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "topic": {
          "description": "The topic to publish messages to.",
          "type": "string"
        },
        "urls": {
          "description": "A list of URLs to connect to. The format should be `scheme://host:port` where `scheme` is one of `tcp`, `ssl`, or `ws`, `host` is the ip-address (or hostname) and `port` is the port on which the broker is accepting connections. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        },
        "user": {
          "default": "",
          "description": "A username to connect with.",
          "type": "string",
          "x-advanced": true
        },
        "will": {
          "description": "Set last will message in case of Redpanda Connect failure",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to enable last will messages.",
              "type": "boolean",
              "x-advanced": true
            },
            "payload": {
              "default": "",
              "description": "Set payload for last will message.",
              "type": "string",
              "x-advanced": true
            },
            "qos": {
              "default": 0,
              "description": "Set QoS for last will message. Valid values are: 0, 1, 2.",
              "type": "number",
              "x-advanced": true
            },
            "retained": {
              "default": false,
              "description": "Set retained for last will message.",
              "type": "boolean",
              "x-advanced": true
            },
            "topic": {
              "default": "",
              "description": "Set topic for last will message.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "qos",
            "retained",
            "topic",
            "payload"
          ],
          "type": "object",
          "x-advanced": true
        },
        "write_timeout": {
          "default": "3s",
          "description": "The maximum amount of time to wait to write data before the attempt is abandoned.",
          "type": "string"
        }
      },
      "required": [
        "client_id",
        "password",
        "urls",
        "connect_timeout",
        "will",
        "user",
        "keepalive",
        "topic",
        "retained",
        "tls",
        "write_timeout",
        "max_in_flight",
        "qos"
      ],
      "type": "object"
    },
    "msgpack": {
      "description": "Converts messages to or from the https://msgpack.org/[MessagePack^] format.",
      "properties": {
        "operator": {
          "description": "The operation to perform on messages.",
          "type": "string"
        }
      },
      "required": [
        "operator"
      ],
      "type": "object"
    },
    "mutation": {
      "description": "\nBloblang is a powerful language that enables a wide range of mapping, transformation and filtering tasks. For more information, see xref:guides:bloblang/about.adoc[].\n\nIf your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"\u003cpath\u003e\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from.\n\n== Input document mutability\n\nA mutation is a mapping that transforms input documents directly, this has the advantage of reducing the need to copy the data fed into the mapping. However, this also means that the referenced document is mutable and therefore changes throughout the mapping. For example, with the following Bloblang:\n\n```coffeescript\nroot.rejected = this.invitees.filter(i -\u003e i.mood \u003c 0.5)\nroot.invitees = this.invitees.filter(i -\u003e i.mood \u003e= 0.5)\n```\n\nNotice that we create a field `rejected` by copying the array field `invitees` and filtering out objects with a high mood. We then overwrite the field `invitees` by filtering out objects with a low mood, resulting in two array fields that are each a subset of the original. If we were to reverse the ordering of these assignments like so:\n\n```coffeescript\nroot.invitees = this.invitees.filter(i -\u003e i.mood \u003e= 0.5)\nroot.rejected = this.invitees.filter(i -\u003e i.mood \u003c 0.5)\n```\n\nThen the new field `rejected` would be empty as we have already mutated `invitees` to exclude the objects that it would be populated by. We can solve this problem either by carefully ordering our assignments or by capturing the original array using a variable (`let invitees = this.invitees`).\n\nMutations are advantageous over a standard mapping in situations where the result is a document with mostly the same shape as the input document, since we can avoid unnecessarily copying data from the referenced input document. However, in situations where we are creating an entirely new document shape it can be more convenient to use the traditional xref:components:processors/mapping.adoc[`mapping` processor] instead.\n\n== Error handling\n\nBloblang mappings can fail, in which case the error is logged and the message is flagged as having failed, allowing you to use xref:configuration:error_handling.adoc[standard processor error handling patterns].\n\nHowever, Bloblang itself also provides powerful ways of ensuring your mappings do not fail by specifying desired xref:guides:bloblang/about.adoc#error-handling[fallback behavior].\n\t\t\t",
      "type": "object"
    },
    "nanomsg": {
      "description": "Currently only PUSH and PUB sockets are supported.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "bind": {
          "default": false,
          "description": "Whether the URLs listed should be bind (otherwise they are connected to).",
          "type": "boolean"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "poll_timeout": {
          "default": "5s",
          "description": "The maximum period of time to wait for a message to send before the request is abandoned and reattempted.",
          "type": "string"
        },
        "socket_type": {
          "default": "PUSH",
          "description": "The socket type to send with.",
          "enum": [
            "PUSH",
            "PUB"
          ],
          "type": "string"
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "urls",
        "bind",
        "socket_type",
        "poll_timeout",
        "max_in_flight"
      ],
      "type": "object"
    },
    "nats": {
      "description": "This output will interpolate functions within the subject field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "properties": {
        "auth": {
          "description": "Optional configuration of NATS authentication parameters.",
          "properties": {
            "nkey": {
              "description": "The NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "nkey_file": {
              "description": "An optional file containing a NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_credentials_file": {
              "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_jwt": {
              "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
              "type": "string",
              "x-advanced": true
            },
            "user_nkey_seed": {
              "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
              "type": "string",
              "x-advanced": true
            }
          },
          "type": "object",
          "x-advanced": true
        },
        "headers": {
          "default": {},
          "description": "Explicit message headers to add to messages.",
          "type": "string"
        },
        "inject_tracing_map": {
          "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "metadata": {
          "description": "Determine which (if any) metadata values should be added to messages as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string"
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string"
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object"
        },
        "subject": {
          "description": "The subject to publish to.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "max_in_flight",
        "tls",
        "auth",
        "urls",
        "subject",
        "headers"
      ],
      "type": "object"
    },
    "nats_jetstream": {
      "description": "== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "properties": {
        "auth": {
          "description": "Optional configuration of NATS authentication parameters.",
          "properties": {
            "nkey": {
              "description": "The NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "nkey_file": {
              "description": "An optional file containing a NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_credentials_file": {
              "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_jwt": {
              "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
              "type": "string",
              "x-advanced": true
            },
            "user_nkey_seed": {
              "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
              "type": "string",
              "x-advanced": true
            }
          },
          "type": "object",
          "x-advanced": true
        },
        "headers": {
          "default": {},
          "description": "Explicit message headers to add to messages.",
          "type": "string"
        },
        "inject_tracing_map": {
          "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 1024,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "metadata": {
          "description": "Determine which (if any) metadata values should be added to messages as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string"
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string"
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object"
        },
        "subject": {
          "description": "A subject to write to.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "tls",
        "auth",
        "urls",
        "subject",
        "headers",
        "max_in_flight"
      ],
      "type": "object"
    },
    "nats_kv": {
      "description": "\nThe field `key` supports\nxref:configuration:interpolation.adoc#bloblang-queries[interpolation functions], allowing\nyou to create a unique key for each message.\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "properties": {
        "auth": {
          "description": "Optional configuration of NATS authentication parameters.",
          "properties": {
            "nkey": {
              "description": "The NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "nkey_file": {
              "description": "An optional file containing a NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_credentials_file": {
              "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_jwt": {
              "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
              "type": "string",
              "x-advanced": true
            },
            "user_nkey_seed": {
              "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
              "type": "string",
              "x-advanced": true
            }
          },
          "type": "object",
          "x-advanced": true
        },
        "bucket": {
          "description": "The name of the KV bucket.",
          "type": "string"
        },
        "key": {
          "description": "The key for each message.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 1024,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "key",
        "max_in_flight",
        "tls",
        "auth",
        "urls",
        "bucket"
      ],
      "type": "object"
    },
    "nats_request_reply": {
      "description": "\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n```text\n- nats_subject\n- nats_sequence_stream\n- nats_sequence_consumer\n- nats_num_delivered\n- nats_num_pending\n- nats_domain\n- nats_timestamp_unix_nano\n```\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].\n\n== Connection name\n\nWhen monitoring and managing a production NATS system, it is often useful to\nknow which connection a message was send/received from. This can be achieved by\nsetting the connection name option when creating a NATS connection.\n\nRedpanda Connect will automatically set the connection name based off the label of the given\nNATS component, so that monitoring tools between NATS and Redpanda Connect can stay in sync.\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].",
      "properties": {
        "auth": {
          "description": "Optional configuration of NATS authentication parameters.",
          "properties": {
            "nkey": {
              "description": "The NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "nkey_file": {
              "description": "An optional file containing a NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_credentials_file": {
              "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_jwt": {
              "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
              "type": "string",
              "x-advanced": true
            },
            "user_nkey_seed": {
              "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
              "type": "string",
              "x-advanced": true
            }
          },
          "type": "object",
          "x-advanced": true
        },
        "headers": {
          "default": {},
          "description": "Explicit message headers to add to messages.",
          "type": "string"
        },
        "inbox_prefix": {
          "description": "Set an explicit inbox prefix for the response subject",
          "type": "string",
          "x-advanced": true
        },
        "metadata": {
          "description": "Determine which (if any) metadata values should be added to messages as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string"
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string"
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object"
        },
        "subject": {
          "description": "A subject to write to.",
          "type": "string"
        },
        "timeout": {
          "default": "3s",
          "description": "A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as 300ms, -1.5h or 2h45m. Valid time units are ns, us (or s), ms, s, m, h.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "subject",
        "headers",
        "tls",
        "auth",
        "urls"
      ],
      "type": "object"
    },
    "nats_stream": {
      "description": "\n[CAUTION]\n.Deprecation notice\n====\nThe NATS Streaming Server is being deprecated. Critical bug fixes and security fixes will be applied until June of 2023. NATS-enabled applications requiring persistence should use https://docs.nats.io/nats-concepts/jetstream[JetStream^].\n====\n\n\n\n== Authentication\n\nThere are several components within Redpanda Connect which uses NATS services. You will find that each of these components\nsupport optional advanced authentication parameters for https://docs.nats.io/nats-server/configuration/securing_nats/auth_intro/nkey_auth[NKeys^]\nand https://docs.nats.io/using-nats/developer/connecting/creds[User Credentials^].\n\nSee an https://docs.nats.io/running-a-nats-service/nats_admin/security/jwt[in-depth tutorial^].\n\n=== NKey file\n\nThe NATS server can use these NKeys in several ways for authentication. The simplest is for the server to be configured\nwith a list of known public keys and for the clients to respond to the challenge by signing it with its private NKey\nconfigured in the `nkey_file` or `nkey` field.\n\nhttps://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[More details^].\n\n=== User credentials\n\nNATS server supports decentralized authentication based on JSON Web Tokens (JWT). Clients need an https://docs.nats.io/nats-server/configuration/securing_nats/jwt#json-web-tokens[user JWT^]\nand a corresponding https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro/nkey_auth[NKey secret^] when connecting to a server\nwhich is configured to use this authentication scheme.\n\nThe `user_credentials_file` field should point to a file containing both the private key and the JWT and can be\ngenerated with the https://docs.nats.io/nats-tools/nsc[nsc tool^].\n\nAlternatively, the `user_jwt` field can contain a plain text JWT and the `user_nkey_seed`can contain\nthe plain text NKey Seed.\n\nhttps://docs.nats.io/using-nats/developer/connecting/creds[More details^].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "auth": {
          "description": "Optional configuration of NATS authentication parameters.",
          "properties": {
            "nkey": {
              "description": "The NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "nkey_file": {
              "description": "An optional file containing a NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_credentials_file": {
              "description": "An optional file containing user credentials which consist of an user JWT and corresponding NKey seed.",
              "type": "string",
              "x-advanced": true
            },
            "user_jwt": {
              "description": "An optional plain text user JWT (given along with the corresponding user NKey Seed).",
              "type": "string",
              "x-advanced": true
            },
            "user_nkey_seed": {
              "description": "An optional plain text user NKey Seed (given along with the corresponding user JWT).",
              "type": "string",
              "x-advanced": true
            }
          },
          "type": "object",
          "x-advanced": true
        },
        "client_id": {
          "default": "",
          "description": "The client ID to connect with.",
          "type": "string"
        },
        "cluster_id": {
          "description": "The cluster ID to publish to.",
          "type": "string"
        },
        "inject_tracing_map": {
          "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] used to inject an object containing tracing propagation information into outbound messages. The specification of the injected fields will match the format used by the service wide tracer.",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "subject": {
          "description": "The subject to publish to.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "client_id",
        "max_in_flight",
        "tls",
        "auth",
        "urls",
        "cluster_id",
        "subject"
      ],
      "type": "object"
    },
    "nodered_js": {
      "description": "Executes user-defined JavaScript code to process messages in a format similar to Node-RED functions.",
      "properties": {
        "code": {
          "description": "The JavaScript code to execute. The code should be a function that processes the message.",
          "type": "string"
        }
      },
      "required": [
        "code"
      ],
      "type": "object"
    },
    "noop": {
      "description": "Noop is a processor that does nothing, the message passes through unchanged. Why? Sometimes doing nothing is the braver option.",
      "type": "object"
    },
    "nsq": {
      "description": "The `topic` field can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "nsqd_tcp_address": {
          "description": "The address of the target NSQD server.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "topic": {
          "description": "The topic to publish to.",
          "type": "string"
        },
        "user_agent": {
          "description": "A user agent to assume when connecting.",
          "type": "string"
        }
      },
      "required": [
        "nsqd_tcp_address",
        "topic",
        "tls",
        "max_in_flight"
      ],
      "type": "object"
    },
    "ockam_kafka": {
      "description": "Ockam",
      "properties": {
        "allow": {
          "default": "self",
          "type": "string"
        },
        "allow_consumer": {
          "default": "self",
          "type": "string"
        },
        "disable_content_encryption": {
          "default": false,
          "type": "boolean"
        },
        "encrypted_fields": {
          "default": [],
          "description": "The fields to encrypt in the kafka messages, assuming the record is a valid JSON map. By default, the whole record is encrypted.",
          "type": "string"
        },
        "enrollment_ticket": {
          "type": "string"
        },
        "identity_name": {
          "type": "string"
        },
        "kafka": {
          "properties": {
            "batching": {
              "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
              "properties": {
                "byte_size": {
                  "default": 0,
                  "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
                  "type": "number"
                },
                "check": {
                  "default": "",
                  "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
                  "type": "string"
                },
                "count": {
                  "default": 0,
                  "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
                  "type": "number"
                },
                "period": {
                  "default": "",
                  "description": "A period in which an incomplete batch should be flushed regardless of its size.",
                  "type": "string"
                },
                "processors": {
                  "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "count",
                "byte_size",
                "period",
                "check"
              ],
              "type": "object"
            },
            "broker_write_max_bytes": {
              "default": "100MiB",
              "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
              "type": "string",
              "x-advanced": true
            },
            "compression": {
              "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
              "enum": [
                "lz4",
                "snappy",
                "gzip",
                "none",
                "zstd"
              ],
              "type": "string",
              "x-advanced": true
            },
            "idempotent_write": {
              "default": true,
              "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
              "type": "boolean",
              "x-advanced": true
            },
            "key": {
              "description": "An optional key to populate for each message.",
              "type": "string"
            },
            "max_in_flight": {
              "default": 10,
              "description": "The maximum number of batches to be sending in parallel at any given time.",
              "type": "number"
            },
            "max_message_bytes": {
              "default": "1MiB",
              "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
              "type": "string",
              "x-advanced": true
            },
            "metadata": {
              "description": "Determine which (if any) metadata values should be added to messages as headers.",
              "properties": {
                "include_patterns": {
                  "default": [],
                  "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
                  "type": "string"
                },
                "include_prefixes": {
                  "default": [],
                  "description": "Provide a list of explicit metadata key prefixes to match against.",
                  "type": "string"
                }
              },
              "required": [
                "include_prefixes",
                "include_patterns"
              ],
              "type": "object"
            },
            "partition": {
              "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
              "type": "string"
            },
            "partitioner": {
              "description": "Override the default murmur2 hashing partitioner.",
              "type": "string",
              "x-advanced": true
            },
            "seed_brokers": {
              "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
              "type": "string"
            },
            "timeout": {
              "default": "10s",
              "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
              "type": "string",
              "x-advanced": true
            },
            "timestamp": {
              "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
              "type": "string",
              "x-advanced": true
            },
            "timestamp_ms": {
              "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
              "type": "string",
              "x-advanced": true
            },
            "tls": {
              "description": "Custom TLS settings can be used to override system defaults.",
              "properties": {
                "client_certs": {
                  "default": [],
                  "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
                  "properties": {
                    "cert": {
                      "default": "",
                      "description": "A plain text certificate to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "cert_file": {
                      "default": "",
                      "description": "The path of a certificate to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "key": {
                      "default": "",
                      "description": "A plain text certificate key to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "key_file": {
                      "default": "",
                      "description": "The path of a certificate key to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "password": {
                      "default": "",
                      "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                      "type": "string",
                      "x-advanced": true
                    }
                  },
                  "required": [
                    "cert",
                    "key",
                    "cert_file",
                    "key_file",
                    "password"
                  ],
                  "type": "object",
                  "x-advanced": true
                },
                "enable_renegotiation": {
                  "default": false,
                  "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
                  "type": "boolean",
                  "x-advanced": true
                },
                "enabled": {
                  "default": false,
                  "description": "Whether custom TLS settings are enabled.",
                  "type": "boolean",
                  "x-advanced": true
                },
                "root_cas": {
                  "default": "",
                  "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                  "type": "string",
                  "x-advanced": true
                },
                "root_cas_file": {
                  "default": "",
                  "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
                  "type": "string",
                  "x-advanced": true
                },
                "skip_cert_verify": {
                  "default": false,
                  "description": "Whether to skip server side certificate verification.",
                  "type": "boolean",
                  "x-advanced": true
                }
              },
              "required": [
                "enabled",
                "skip_cert_verify",
                "enable_renegotiation",
                "root_cas",
                "root_cas_file",
                "client_certs"
              ],
              "type": "object",
              "x-advanced": true
            },
            "topic": {
              "description": "A topic to write messages to.",
              "type": "string"
            }
          },
          "required": [
            "tls",
            "max_in_flight",
            "batching",
            "idempotent_write",
            "timeout",
            "max_message_bytes",
            "broker_write_max_bytes",
            "topic"
          ],
          "type": "object"
        },
        "route_to_consumer": {
          "default": "/ip4/127.0.0.1/tcp/6262",
          "type": "string"
        },
        "route_to_kafka_outlet": {
          "default": "self",
          "type": "string"
        }
      },
      "required": [
        "disable_content_encryption",
        "kafka",
        "route_to_kafka_outlet",
        "allow_consumer",
        "route_to_consumer",
        "encrypted_fields"
      ],
      "type": "object"
    },
    "opcua": {
      "description": "The OPC UA output plugin writes data to an OPC UA server and optionally verifies the write via a read-back handshake.",
      "properties": {
        "autoReconnect": {
          "default": false,
          "description": "Set to true to automatically reconnect to the OPC UA server when the connection is lost.",
          "type": "boolean",
          "x-advanced": true
        },
        "clientCertificate": {
          "default": "",
          "description": "The client certificate to use, base64-encoded.",
          "type": "string",
          "x-advanced": true
        },
        "directConnect": {
          "default": false,
          "description": "Set this to true to directly connect to an OPC UA endpoint. This can be necessary in cases where the OPC UA server does not allow 'endpoint discovery'. This requires having the full endpoint name in endpoint, and securityMode and securityPolicy set.",
          "type": "boolean",
          "x-advanced": true
        },
        "endpoint": {
          "description": "The OPC UA server endpoint to connect to.",
          "type": "string"
        },
        "handshake": {
          "default": {
            "enabled": true,
            "maxWriteAttempts": 1,
            "readbackTimeoutMs": 2000,
            "timeBetweenRetriesMs": 1000
          },
          "description": "Configuration for the read-back handshake.",
          "properties": {
            "enabled": {
              "default": true,
              "description": "Whether to enable read-back verification after writing.",
              "type": "boolean"
            },
            "maxWriteAttempts": {
              "default": 1,
              "description": "Number of write attempts if the server fails.",
              "type": "number"
            },
            "readbackTimeoutMs": {
              "default": 2000,
              "description": "How long to wait for the server to show the updated value.",
              "type": "number"
            },
            "timeBetweenRetriesMs": {
              "default": 1000,
              "description": "Delay between write attempts.",
              "type": "number"
            }
          },
          "required": [
            "enabled",
            "readbackTimeoutMs",
            "maxWriteAttempts",
            "timeBetweenRetriesMs"
          ],
          "type": "object"
        },
        "insecure": {
          "default": false,
          "description": "Set to true to bypass secure connections, useful in case of SSL or certificate issues. Default is secure (false).",
          "type": "boolean",
          "x-advanced": true
        },
        "nodeIDs": {
          "description": "List of OPC-UA node IDs to begin browsing.",
          "type": "string"
        },
        "nodeMappings": {
          "description": "List of node mappings defining which message fields to write to which OPC UA nodes",
          "properties": {
            "dataType": {
              "description": "The OPC UA data type for the value. Supports dynamic values through interpolation.",
              "type": "string"
            },
            "nodeId": {
              "description": "The OPC UA node ID to write to. Supports dynamic values through interpolation.",
              "type": "string"
            },
            "valueFrom": {
              "description": "The field in the input message to get the value from.",
              "type": "string"
            }
          },
          "required": [
            "nodeId",
            "valueFrom",
            "dataType"
          ],
          "type": "object"
        },
        "password": {
          "default": "",
          "description": "The password for authentication.",
          "type": "string",
          "x-advanced": true
        },
        "pollRate": {
          "default": 1000,
          "description": "The rate in milliseconds at which to poll the OPC UA server when not using subscriptions. Defaults to 1000ms (1 second).",
          "type": "number",
          "x-advanced": true
        },
        "queueSize": {
          "default": 10,
          "description": "The size of the queue, which will get filled from the OPC UA server when requesting its data via subscription",
          "type": "number",
          "x-advanced": true
        },
        "reconnectIntervalInSeconds": {
          "default": 5,
          "description": "The interval in seconds at which to reconnect to the OPC UA server when the connection is lost. This is only used if `autoReconnect` is set to true.",
          "type": "number",
          "x-advanced": true
        },
        "samplingInterval": {
          "default": 0,
          "description": "The interval for sampling on the OPC UA server - notice 0.0 will get you updates as fast as possible",
          "type": "number",
          "x-advanced": true
        },
        "securityMode": {
          "default": "",
          "description": "The security mode to use. Options: None, Sign, SignAndEncrypt",
          "type": "string",
          "x-advanced": true
        },
        "securityPolicy": {
          "default": "",
          "description": "The security policy to use. Options: None, Basic128Rsa15, Basic256, Basic256Sha256",
          "type": "string",
          "x-advanced": true
        },
        "serverCertificateFingerprint": {
          "default": "",
          "description": "The server certificate fingerprint to verify, SHA3-512 hash.",
          "type": "string",
          "x-advanced": true
        },
        "sessionTimeout": {
          "default": 10000,
          "description": "The duration in milliseconds that a OPC UA session will last. Is used to ensure that older failed sessions will timeout and that we will not get a TooManySession error.",
          "type": "number",
          "x-advanced": true
        },
        "subscribeEnabled": {
          "default": false,
          "description": "Set to true to subscribe to OPC UA nodes instead of fetching them every seconds. Default is pulling messages every second (false).",
          "type": "boolean"
        },
        "useHeartbeat": {
          "default": false,
          "description": "Set to true to provide an extra message with the servers timestamp as a heartbeat",
          "type": "boolean",
          "x-advanced": true
        },
        "userCertificate": {
          "default": "",
          "description": "User certificate in base64 encoded format of either PEM or DER.",
          "type": "string",
          "x-advanced": true
        },
        "userPrivateKey": {
          "default": "",
          "description": "User private key in base64 format of PEM for user certificate based authentication.",
          "type": "string",
          "x-advanced": true
        },
        "username": {
          "default": "",
          "description": "The username for authentication.",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "nodeMappings",
        "endpoint",
        "handshake",
        "nodeIDs",
        "subscribeEnabled"
      ],
      "type": "object"
    },
    "opensearch": {
      "description": "\nBoth the `id` and `index` fields can be dynamically set using function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here]. When sending batched messages these interpolations are performed per message part.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "action": {
          "description": "The action to take on the document. This field must resolve to one of the following action types: `index`, `update` or `delete`.",
          "type": "string"
        },
        "aws": {
          "description": "Enables and customises connectivity to Amazon Elastic Service.",
          "properties": {
            "credentials": {
              "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
              "properties": {
                "from_ec2_role": {
                  "default": false,
                  "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                  "type": "boolean",
                  "x-advanced": true
                },
                "id": {
                  "default": "",
                  "description": "The ID of credentials to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "profile": {
                  "default": "",
                  "description": "A profile from `~/.aws/credentials` to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "role": {
                  "default": "",
                  "description": "A role ARN to assume.",
                  "type": "string",
                  "x-advanced": true
                },
                "role_external_id": {
                  "default": "",
                  "description": "An external ID to provide when assuming a role.",
                  "type": "string",
                  "x-advanced": true
                },
                "secret": {
                  "default": "",
                  "description": "The secret for the credentials being used.",
                  "type": "string",
                  "x-advanced": true
                },
                "token": {
                  "default": "",
                  "description": "The token for the credentials being used, required when using short term credentials.",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "profile",
                "id",
                "secret",
                "token",
                "from_ec2_role",
                "role",
                "role_external_id"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to connect to Amazon Elastic Service.",
              "type": "boolean",
              "x-advanced": true
            },
            "endpoint": {
              "default": "",
              "description": "Allows you to specify a custom endpoint for the AWS API.",
              "type": "string",
              "x-advanced": true
            },
            "region": {
              "default": "",
              "description": "The AWS region to target.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "region",
            "endpoint",
            "credentials"
          ],
          "type": "object",
          "x-advanced": true
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "id": {
          "description": "The ID for indexed messages. Interpolation should be used in order to create a unique ID for each message.",
          "type": "string"
        },
        "index": {
          "description": "The index to place messages.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "pipeline": {
          "default": "",
          "description": "An optional pipeline id to preprocess incoming documents.",
          "type": "string",
          "x-advanced": true
        },
        "routing": {
          "default": "",
          "description": "The routing key to use for the document.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "urls": {
          "description": "A list of URLs to connect to. If an item of the list contains commas it will be expanded into multiple URLs.",
          "type": "string"
        }
      },
      "required": [
        "routing",
        "max_in_flight",
        "action",
        "id",
        "tls",
        "batching",
        "aws",
        "urls",
        "index",
        "pipeline"
      ],
      "type": "object"
    },
    "parallel": {
      "description": "\nThe field `cap`, if greater than zero, caps the maximum number of parallel processing threads.\n\nThe functionality of this processor depends on being applied across messages that are batched. You can find out more about batching in xref:configuration:batching.adoc[].",
      "properties": {
        "cap": {
          "default": 0,
          "description": "The maximum number of messages to have processing at a given time.",
          "type": "number"
        },
        "processors": {
          "description": "A list of child processors to apply.",
          "type": "string"
        }
      },
      "required": [
        "cap",
        "processors"
      ],
      "type": "object"
    },
    "parquet": {
      "description": "\n== Alternatives\n\nThis processor is now deprecated, it's recommended that you use the new xref:components:processors/parquet_decode.adoc[`parquet_decode`] and xref:components:processors/parquet_encode.adoc[`parquet_encode`] processors as they provide a number of advantages, the most important of which is better error messages for when schemas are mismatched or files could not be consumed.\n\n== Troubleshooting\n\nThis processor is experimental and the error messages that it provides are often vague and unhelpful. An error message of the form `interface \\{} is nil, not \u003cvalue type\u003e` implies that a field of the given type was expected but not found in the processed message when writing parquet files.\n\nUnfortunately the name of the field will sometimes be missing from the error, in which case it's worth double checking the schema you provided to make sure that there are no typos in the field names, and if that doesn't reveal the issue it can help to mark fields as OPTIONAL in the schema and gradually change them back to REQUIRED until the error returns.\n\n== Define the schema\n\nThe schema must be specified as a JSON string, containing an object that describes the fields expected at the root of each document. Each field can itself have more fields defined, allowing for nested structures:\n\n```json\n{\n  \"Tag\": \"name=root, repetitiontype=REQUIRED\",\n  \"Fields\": [\n    {\"Tag\": \"name=name, inname=NameIn, type=BYTE_ARRAY, convertedtype=UTF8, repetitiontype=REQUIRED\"},\n    {\"Tag\": \"name=age, inname=Age, type=INT32, repetitiontype=REQUIRED\"},\n    {\"Tag\": \"name=id, inname=Id, type=INT64, repetitiontype=REQUIRED\"},\n    {\"Tag\": \"name=weight, inname=Weight, type=FLOAT, repetitiontype=REQUIRED\"},\n    {\n      \"Tag\": \"name=favPokemon, inname=FavPokemon, type=LIST, repetitiontype=OPTIONAL\",\n      \"Fields\": [\n        {\"Tag\": \"name=name, inname=PokeName, type=BYTE_ARRAY, convertedtype=UTF8, repetitiontype=REQUIRED\"},\n        {\"Tag\": \"name=coolness, inname=Coolness, type=FLOAT, repetitiontype=REQUIRED\"}\n      ]\n    }\n  ]\n}\n```\n\nA schema can be derived from a source file using https://github.com/xitongsys/parquet-go/tree/master/tool/parquet-tools:\n\n```sh\n./parquet-tools -cmd schema -file foo.parquet\n```",
      "properties": {
        "compression": {
          "default": "snappy",
          "description": "The type of compression to use when writing parquet files, this field is ignored when consuming parquet files.",
          "enum": [
            "uncompressed",
            "snappy",
            "gzip",
            "lz4",
            "zstd"
          ],
          "type": "string"
        },
        "operator": {
          "description": "Determines whether the processor converts messages into a parquet file or expands parquet files into messages. Converting into JSON allows subsequent processors and mappings to convert the data into any other format.",
          "type": "string"
        },
        "schema": {
          "description": "A schema used to describe the parquet files being generated or consumed, the format of the schema is a JSON document detailing the tag and fields of documents. The schema can be found at: https://pkg.go.dev/github.com/xitongsys/parquet-go#readme-json. Either a `schema_file` or `schema` field must be specified when creating Parquet files via the `from_json` operator.",
          "type": "string"
        },
        "schema_file": {
          "description": "A file path containing a schema used to describe the parquet files being generated or consumed, the format of the schema is a JSON document detailing the tag and fields of documents. The schema can be found at: https://pkg.go.dev/github.com/xitongsys/parquet-go#readme-json. Either a `schema_file` or `schema` field must be specified when creating Parquet files via the `from_json` operator.",
          "type": "string"
        }
      },
      "required": [
        "compression",
        "operator"
      ],
      "type": "object"
    },
    "parquet_decode": {
      "description": "\nThis processor uses https://github.com/parquet-go/parquet-go[https://github.com/parquet-go/parquet-go^], which is itself experimental. Therefore changes could be made into how this processor functions outside of major version releases.",
      "properties": {
        "byte_array_as_string": {
          "default": false,
          "description": "Whether to extract BYTE_ARRAY and FIXED_LEN_BYTE_ARRAY values as strings rather than byte slices in all cases. Values with a logical type of UTF8 will automatically be extracted as strings irrespective of this field. Enabling this field makes serializing the data as JSON more intuitive as `[]byte` values are serialized as base64 encoded strings by default.",
          "type": "boolean"
        }
      },
      "required": [
        "byte_array_as_string"
      ],
      "type": "object"
    },
    "parquet_encode": {
      "description": "\nThis processor uses https://github.com/parquet-go/parquet-go[https://github.com/parquet-go/parquet-go^], which is itself experimental. Therefore changes could be made into how this processor functions outside of major version releases.\n",
      "properties": {
        "default_compression": {
          "default": "uncompressed",
          "description": "The default compression type to use for fields.",
          "enum": [
            "uncompressed",
            "snappy",
            "gzip",
            "brotli",
            "zstd",
            "lz4raw"
          ],
          "type": "string"
        },
        "default_encoding": {
          "default": "DELTA_LENGTH_BYTE_ARRAY",
          "description": "The default encoding type to use for fields. A custom default encoding is only necessary when consuming data with libraries that do not support `DELTA_LENGTH_BYTE_ARRAY` and is therefore best left unset where possible.",
          "enum": [
            "DELTA_LENGTH_BYTE_ARRAY",
            "PLAIN"
          ],
          "type": "string",
          "x-advanced": true
        },
        "schema": {
          "description": "Parquet schema.",
          "properties": {
            "fields": {
              "description": "A list of child fields.",
              "type": "string"
            },
            "name": {
              "description": "The name of the column.",
              "type": "string"
            },
            "optional": {
              "default": false,
              "description": "Whether the field is optional.",
              "type": "boolean"
            },
            "repeated": {
              "default": false,
              "description": "Whether the field is repeated.",
              "type": "boolean"
            },
            "type": {
              "description": "The type of the column, only applicable for leaf columns with no child fields. Some logical types can be specified here such as UTF8.",
              "enum": [
                "BOOLEAN",
                "INT32",
                "INT64",
                "FLOAT",
                "DOUBLE",
                "BYTE_ARRAY",
                "UTF8"
              ],
              "type": "string"
            }
          },
          "required": [
            "name",
            "repeated",
            "optional"
          ],
          "type": "object"
        }
      },
      "required": [
        "schema",
        "default_compression",
        "default_encoding"
      ],
      "type": "object"
    },
    "parse_log": {
      "description": "Parses common log \u003c\u003cformats\u003e\u003e into \u003c\u003ccodecs, structured data\u003e\u003e. This is easier and often much faster than xref:components:processors/grok.adoc[`grok`].",
      "properties": {
        "allow_rfc3339": {
          "default": true,
          "description": "Also accept timestamps in rfc3339 format while parsing. Applicable to format `syslog_rfc3164`.",
          "type": "boolean",
          "x-advanced": true
        },
        "best_effort": {
          "default": true,
          "description": "Still returns partially parsed messages even if an error occurs.",
          "type": "boolean",
          "x-advanced": true
        },
        "codec": {
          "type": "string"
        },
        "default_timezone": {
          "default": "UTC",
          "description": "Sets the strategy to decide the timezone for rfc3164 timestamps. Applicable to format `syslog_rfc3164`. This value should follow the https://golang.org/pkg/time/#LoadLocation[time.LoadLocation^] format.",
          "type": "string",
          "x-advanced": true
        },
        "default_year": {
          "default": "current",
          "description": "Sets the strategy used to set the year for rfc3164 timestamps. Applicable to format `syslog_rfc3164`. When set to `current` the current year will be set, when set to an integer that value will be used. Leave this field empty to not set a default year at all.",
          "type": "string",
          "x-advanced": true
        },
        "format": {
          "description": "A common log \u003c\u003cformats, format\u003e\u003e to parse.",
          "enum": [
            "syslog_rfc5424",
            "syslog_rfc3164"
          ],
          "type": "string"
        }
      },
      "required": [
        "format",
        "best_effort",
        "allow_rfc3339",
        "default_year",
        "default_timezone",
        "codec"
      ],
      "type": "object"
    },
    "pinecone": {
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "api_key": {
          "description": "The Pinecone api key.",
          "type": "string"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "host": {
          "description": "The host for the Pinecone index.",
          "type": "string"
        },
        "id": {
          "description": "The ID for the index entry in Pinecone.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "metadata_mapping": {
          "description": "An optional mapping of message to metadata in the Pinecone index entry.",
          "type": "string"
        },
        "namespace": {
          "default": "",
          "description": "The namespace to write to - writes to the default namespace by default.",
          "type": "string",
          "x-advanced": true
        },
        "operation": {
          "default": "upsert-vectors",
          "description": "The operation to perform against the Pinecone index.",
          "enum": [
            "update-vector",
            "upsert-vectors",
            "delete-vectors"
          ],
          "type": "string"
        },
        "vector_mapping": {
          "description": "The mapping to extract out the vector from the document. The result must be a floating point array. Required if not a delete operation.",
          "type": "string"
        }
      },
      "required": [
        "api_key",
        "operation",
        "namespace",
        "id",
        "max_in_flight",
        "batching",
        "host"
      ],
      "type": "object"
    },
    "processors": {
      "description": "This processor is useful in situations where you want to collect several processors under a single resource identifier, whether it is for making your configuration easier to read and navigate, or for improving the testability of your configuration. The behavior of child processors will match exactly the behavior they would have under any other processors block.",
      "type": "object"
    },
    "protobuf": {
      "description": "\nThe main functionality of this processor is to map to and from JSON documents, you can read more about JSON mapping of protobuf messages here: https://developers.google.com/protocol-buffers/docs/proto3#json[https://developers.google.com/protocol-buffers/docs/proto3#json^]\n\nUsing reflection for processing protobuf messages in this way is less performant than generating and using native code. Therefore when performance is critical it is recommended that you use Redpanda Connect plugins instead for processing protobuf messages natively, you can find an example of Redpanda Connect plugins at https://github.com/benthosdev/benthos-plugin-example[https://github.com/benthosdev/benthos-plugin-example^]\n\n== Operators\n\n=== `to_json`\n\nConverts protobuf messages into a generic JSON structure. This makes it easier to manipulate the contents of the document within Benthos.\n\n=== `from_json`\n\nAttempts to create a target protobuf message from a generic JSON structure.\n",
      "properties": {
        "discard_unknown": {
          "default": false,
          "description": "If `true`, the `from_json` operator discards fields that are unknown to the schema.",
          "type": "boolean"
        },
        "import_paths": {
          "default": [],
          "description": "A list of directories containing .proto files, including all definitions required for parsing the target message. If left empty the current directory is used. Each directory listed will be walked with all found .proto files imported.",
          "type": "string"
        },
        "message": {
          "description": "The fully qualified name of the protobuf message to convert to/from.",
          "type": "string"
        },
        "operator": {
          "description": "The \u003c\u003coperators, operator\u003e\u003e to execute",
          "enum": [
            "to_json",
            "from_json"
          ],
          "type": "string"
        },
        "use_proto_names": {
          "default": false,
          "description": "If `true`, the `to_json` operator deserializes fields exactly as named in schema file.",
          "type": "boolean"
        }
      },
      "required": [
        "operator",
        "message",
        "discard_unknown",
        "use_proto_names",
        "import_paths"
      ],
      "type": "object"
    },
    "pulsar": {
      "description": "Write messages to an Apache Pulsar server.",
      "properties": {
        "auth": {
          "description": "Optional configuration of Pulsar authentication methods.",
          "properties": {
            "oauth2": {
              "description": "Parameters for Pulsar OAuth2 authentication.",
              "properties": {
                "audience": {
                  "default": "",
                  "description": "OAuth2 audience.",
                  "type": "string",
                  "x-advanced": true
                },
                "enabled": {
                  "default": false,
                  "description": "Whether OAuth2 is enabled.",
                  "type": "boolean",
                  "x-advanced": true
                },
                "issuer_url": {
                  "default": "",
                  "description": "OAuth2 issuer URL.",
                  "type": "string",
                  "x-advanced": true
                },
                "private_key_file": {
                  "default": "",
                  "description": "The path to a file containing a private key.",
                  "type": "string",
                  "x-advanced": true
                },
                "scope": {
                  "default": "",
                  "description": "OAuth2 scope to request.",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "enabled",
                "audience",
                "issuer_url",
                "scope",
                "private_key_file"
              ],
              "type": "object",
              "x-advanced": true
            },
            "token": {
              "description": "Parameters for Pulsar Token authentication.",
              "properties": {
                "enabled": {
                  "default": false,
                  "description": "Whether Token Auth is enabled.",
                  "type": "boolean",
                  "x-advanced": true
                },
                "token": {
                  "default": "",
                  "description": "Actual base64 encoded token.",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "enabled",
                "token"
              ],
              "type": "object",
              "x-advanced": true
            }
          },
          "type": "object",
          "x-advanced": true
        },
        "key": {
          "default": "",
          "description": "The key to publish messages with.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "ordering_key": {
          "default": "",
          "description": "The ordering key to publish messages with.",
          "type": "string"
        },
        "tls": {
          "description": "Specify the path to a custom CA certificate to trust broker TLS service.",
          "properties": {
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string"
            }
          },
          "required": [
            "root_cas_file"
          ],
          "type": "object"
        },
        "topic": {
          "description": "The topic to publish to.",
          "type": "string"
        },
        "url": {
          "description": "A URL to connect to.",
          "type": "string"
        }
      },
      "required": [
        "ordering_key",
        "max_in_flight",
        "url",
        "topic",
        "tls",
        "key"
      ],
      "type": "object"
    },
    "pusher": {
      "description": "Output for publishing messages to Pusher API (https://pusher.com)",
      "properties": {
        "appId": {
          "description": "Pusher app id",
          "type": "string"
        },
        "batching": {
          "description": "maximum batch size is 10 (limit of the pusher library)",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "channel": {
          "description": "Pusher channel to publish to. Interpolation functions can also be used",
          "type": "string"
        },
        "cluster": {
          "description": "Pusher cluster",
          "type": "string"
        },
        "event": {
          "description": "Event to publish to",
          "type": "string"
        },
        "key": {
          "description": "Pusher key",
          "type": "string"
        },
        "max_in_flight": {
          "default": 1,
          "description": "The maximum number of parallel message batches to have in flight at any given time.",
          "type": "number"
        },
        "secret": {
          "description": "Pusher secret",
          "type": "string"
        },
        "secure": {
          "default": true,
          "description": "Enable SSL encryption",
          "type": "boolean"
        }
      },
      "required": [
        "secure",
        "batching",
        "channel",
        "appId",
        "max_in_flight",
        "event",
        "key",
        "secret",
        "cluster"
      ],
      "type": "object"
    },
    "qdrant": {
      "description": "\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "api_token": {
          "default": "",
          "description": "The Qdrant API token for authentication. Defaults to an empty string.",
          "type": "string"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "collection_name": {
          "description": "The name of the collection in Qdrant.",
          "type": "string"
        },
        "grpc_host": {
          "description": "The gRPC host of the Qdrant server.",
          "type": "string"
        },
        "id": {
          "description": "The ID of the point to insert. Can be a UUID string or positive integer.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "payload_mapping": {
          "default": "root = {}",
          "description": "An optional mapping of message to payload associated with the point.",
          "type": "string"
        },
        "tls": {
          "description": "TLS(HTTPS) config to use when connecting",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "vector_mapping": {
          "description": "The mapping to extract the vector from the document.",
          "type": "string"
        }
      },
      "required": [
        "max_in_flight",
        "batching",
        "grpc_host",
        "api_token",
        "tls",
        "vector_mapping",
        "payload_mapping",
        "collection_name",
        "id"
      ],
      "type": "object"
    },
    "questdb": {
      "description": "Important: We recommend that the dedupe feature is enabled on the QuestDB server. Please visit https://questdb.io/docs/ for more information about deploying, configuring, and using QuestDB.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "address": {
          "description": "Address of the QuestDB server's HTTP port (excluding protocol)",
          "type": "string"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "designated_timestamp_field": {
          "description": "Name of the designated timestamp field",
          "type": "string"
        },
        "designated_timestamp_unit": {
          "default": "auto",
          "description": "Designated timestamp field units",
          "type": "string"
        },
        "doubles": {
          "description": "Columns that should be double type, (int is default)",
          "type": "string"
        },
        "error_on_empty_messages": {
          "default": false,
          "description": "Mark a message as errored if it is empty after field validation",
          "type": "boolean"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "password": {
          "description": "Password for HTTP basic auth",
          "type": "string"
        },
        "request_min_throughput": {
          "description": "Minimum expected throughput in bytes per second for HTTP requests. If the throughput is lower than this value, the connection will time out. This is used to calculate an additional timeout on top of request_timeout. This is useful for large requests. You can set this value to 0 to disable this logic.",
          "type": "number",
          "x-advanced": true
        },
        "request_timeout": {
          "description": "The time to wait for a response from the server. This is in addition to the calculation derived from the request_min_throughput parameter.",
          "type": "string",
          "x-advanced": true
        },
        "retry_timeout": {
          "description": "The time to continue retrying after a failed HTTP request. The interval between retries is an exponential backoff starting at 10ms and doubling after each failed attempt up to a maximum of 1 second.",
          "type": "string",
          "x-advanced": true
        },
        "symbols": {
          "description": "Columns that should be the SYMBOL type (string values default to STRING)",
          "type": "string"
        },
        "table": {
          "description": "Destination table",
          "type": "string"
        },
        "timestamp_string_fields": {
          "description": "String fields with textual timestamps",
          "type": "string"
        },
        "timestamp_string_format": {
          "default": "Jan _2 15:04:05.000000Z0700",
          "description": "Timestamp format, used when parsing timestamp string fields. Specified in golang's time.Parse layout",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "token": {
          "description": "Bearer token for HTTP auth (takes precedence over basic auth username \u0026 password)",
          "type": "string"
        },
        "username": {
          "description": "Username for HTTP basic auth",
          "type": "string"
        }
      },
      "required": [
        "batching",
        "tls",
        "address",
        "max_in_flight",
        "table"
      ],
      "type": "object"
    },
    "rate_limit": {
      "description": "Throttles the throughput of a pipeline according to a specified xref:components:rate_limits/about.adoc[`rate_limit`] resource. Rate limits are shared across components and therefore apply globally to all processing pipelines.",
      "properties": {
        "resource": {
          "description": "The target xref:components:rate_limits/about.adoc[`rate_limit` resource].",
          "type": "string"
        }
      },
      "required": [
        "resource"
      ],
      "type": "object"
    },
    "read_until": {
      "description": "\nMessages are read continuously while the query check returns false, when the query returns true the message that triggered the check is sent out and the input is closed. Use this to define inputs where the stream should end once a certain message appears.\n\nIf the idle timeout is configured, the input will be closed if no new messages arrive after that period of time. Use this field if you want to empty out and close an input that doesn't have a logical end.\n\nSometimes inputs close themselves. For example, when the `file` input type reaches the end of a file it will shut down. By default this type will also shut down. If you wish for the input type to be restarted every time it shuts down until the query check is met then set `restart_input` to `true`.\n\n== Metadata\n\nA metadata key `benthos_read_until` containing the value `final` is added to the first part of the message that triggers the input to stop.",
      "properties": {
        "check": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether the input should now be closed.",
          "type": "string"
        },
        "idle_timeout": {
          "description": "The maximum amount of time without receiving new messages after which the input is closed.",
          "type": "string"
        },
        "input": {
          "description": "The child input to consume from.",
          "type": "string"
        },
        "restart_input": {
          "default": false,
          "description": "Whether the input should be reopened if it closes itself before the condition has resolved to true.",
          "type": "boolean"
        }
      },
      "required": [
        "restart_input",
        "input"
      ],
      "type": "object"
    },
    "redis": {
      "description": "Performs actions against Redis that aren't possible using a xref:components:processors/cache.adoc[`cache`] processor. Actions are\nperformed for each message and the message contents are replaced with the result. In order to merge the result into the original message compose this processor within a xref:components:processors/branch.adoc[`branch` processor].",
      "properties": {
        "args_mapping": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of arguments required for the specified Redis command.",
          "type": "string"
        },
        "command": {
          "description": "The command to execute.",
          "type": "string"
        },
        "key": {
          "description": "A key to use for the target operator.",
          "type": "string"
        },
        "kind": {
          "default": "simple",
          "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
          "enum": [
            "simple",
            "cluster",
            "failover"
          ],
          "type": "string",
          "x-advanced": true
        },
        "master": {
          "default": "",
          "description": "Name of the redis master when `kind` is `failover`",
          "type": "string",
          "x-advanced": true
        },
        "operator": {
          "description": "The operator to apply.",
          "type": "string"
        },
        "retries": {
          "default": 3,
          "description": "The maximum number of retries before abandoning a request.",
          "type": "number",
          "x-advanced": true
        },
        "retry_period": {
          "default": "500ms",
          "description": "The time to wait before consecutive retry attempts.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
          "type": "string"
        }
      },
      "required": [
        "retries",
        "kind",
        "master",
        "tls",
        "retry_period",
        "url"
      ],
      "type": "object"
    },
    "redis_hash": {
      "description": "\nThe field `key` supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions], allowing you to create a unique key for each message.\n\nThe field `fields` allows you to specify an explicit map of field names to interpolated values, also evaluated per message of a batch:\n\n```yaml\noutput:\n  redis_hash:\n    url: tcp://localhost:6379\n    key: ${!json(\"id\")}\n    fields:\n      topic: ${!meta(\"kafka_topic\")}\n      partition: ${!meta(\"kafka_partition\")}\n      content: ${!json(\"document.text\")}\n```\n\nIf the field `walk_metadata` is set to `true` then Redpanda Connect will walk all metadata fields of messages and add them to the list of hash fields to set.\n\nIf the field `walk_json_object` is set to `true` then Redpanda Connect will walk each message as a JSON object, extracting keys and the string representation of their value and adds them to the list of hash fields to set.\n\nThe order of hash field extraction is as follows:\n\n1. Metadata (if enabled)\n2. JSON object (if enabled)\n3. Explicit fields\n\nWhere latter stages will overwrite matching field names of a former stage.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "fields": {
          "default": {},
          "description": "A map of key/value pairs to set as hash fields.",
          "type": "string"
        },
        "key": {
          "description": "The key for each message, function interpolations should be used to create a unique key per message.",
          "type": "string"
        },
        "kind": {
          "default": "simple",
          "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
          "enum": [
            "simple",
            "cluster",
            "failover"
          ],
          "type": "string",
          "x-advanced": true
        },
        "master": {
          "default": "",
          "description": "Name of the redis master when `kind` is `failover`",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
          "type": "string"
        },
        "walk_json_object": {
          "default": false,
          "description": "Whether to walk each message as a JSON object and add each key/value pair to the list of hash fields to set.",
          "type": "boolean"
        },
        "walk_metadata": {
          "default": false,
          "description": "Whether all metadata fields of messages should be walked and added to the list of hash fields to set.",
          "type": "boolean"
        }
      },
      "required": [
        "url",
        "kind",
        "master",
        "tls",
        "key",
        "walk_json_object",
        "fields",
        "walk_metadata",
        "max_in_flight"
      ],
      "type": "object"
    },
    "redis_list": {
      "description": "The field `key` supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions], allowing you to create a unique key for each message.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "command": {
          "default": "rpush",
          "description": "The command used to push elements to the Redis list",
          "enum": [
            "rpush",
            "lpush"
          ],
          "type": "string",
          "x-advanced": true
        },
        "key": {
          "description": "The key for each message, function interpolations can be optionally used to create a unique key per message.",
          "type": "string"
        },
        "kind": {
          "default": "simple",
          "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
          "enum": [
            "simple",
            "cluster",
            "failover"
          ],
          "type": "string",
          "x-advanced": true
        },
        "master": {
          "default": "",
          "description": "Name of the redis master when `kind` is `failover`",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
          "type": "string"
        }
      },
      "required": [
        "master",
        "tls",
        "key",
        "max_in_flight",
        "batching",
        "command",
        "url",
        "kind"
      ],
      "type": "object"
    },
    "redis_pubsub": {
      "description": "\nThis output will interpolate functions within the channel field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "channel": {
          "description": "The channel to publish messages to.",
          "type": "string"
        },
        "kind": {
          "default": "simple",
          "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
          "enum": [
            "simple",
            "cluster",
            "failover"
          ],
          "type": "string",
          "x-advanced": true
        },
        "master": {
          "default": "",
          "description": "Name of the redis master when `kind` is `failover`",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
          "type": "string"
        }
      },
      "required": [
        "url",
        "kind",
        "master",
        "tls",
        "channel",
        "max_in_flight",
        "batching"
      ],
      "type": "object"
    },
    "redis_scan": {
      "description": "Optionally, iterates only elements matching a blob-style pattern. For example:\n\n- `*foo*` iterates only keys which contain `foo` in it.\n- `foo*` iterates only keys starting with `foo`.\n\nThis input generates a message for each key value pair in the following format:\n\n```json\n{\"key\":\"foo\",\"value\":\"bar\"}\n```\n",
      "properties": {
        "auto_replay_nacks": {
          "default": true,
          "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
          "type": "boolean"
        },
        "kind": {
          "default": "simple",
          "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
          "enum": [
            "simple",
            "cluster",
            "failover"
          ],
          "type": "string",
          "x-advanced": true
        },
        "master": {
          "default": "",
          "description": "Name of the redis master when `kind` is `failover`",
          "type": "string",
          "x-advanced": true
        },
        "match": {
          "default": "",
          "description": "Iterates only elements matching the optional glob-style pattern. By default, it matches all elements.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
          "type": "string"
        }
      },
      "required": [
        "kind",
        "master",
        "tls",
        "auto_replay_nacks",
        "match",
        "url"
      ],
      "type": "object"
    },
    "redis_script": {
      "description": "Actions are performed for each message and the message contents are replaced with the result.\n\nIn order to merge the result into the original message compose this processor within a xref:components:processors/branch.adoc[`branch` processor].",
      "properties": {
        "args_mapping": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of arguments required for the specified Redis script.",
          "type": "string"
        },
        "keys_mapping": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of keys matching in size to the number of arguments required for the specified Redis script.",
          "type": "string"
        },
        "kind": {
          "default": "simple",
          "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
          "enum": [
            "simple",
            "cluster",
            "failover"
          ],
          "type": "string",
          "x-advanced": true
        },
        "master": {
          "default": "",
          "description": "Name of the redis master when `kind` is `failover`",
          "type": "string",
          "x-advanced": true
        },
        "retries": {
          "default": 3,
          "description": "The maximum number of retries before abandoning a request.",
          "type": "number",
          "x-advanced": true
        },
        "retry_period": {
          "default": "500ms",
          "description": "The time to wait before consecutive retry attempts.",
          "type": "string",
          "x-advanced": true
        },
        "script": {
          "description": "A script to use for the target operator. It has precedence over the 'command' field.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
          "type": "string"
        }
      },
      "required": [
        "url",
        "kind",
        "master",
        "args_mapping",
        "tls",
        "script",
        "keys_mapping",
        "retries",
        "retry_period"
      ],
      "type": "object"
    },
    "redis_streams": {
      "description": "\nIt's possible to specify a maximum length of the target stream by setting it to a value greater than 0, in which case this cap is applied only when Redis is able to remove a whole macro node, for efficiency.\n\nRedis stream entries are key/value pairs, as such it is necessary to specify the key to be set to the body of the message. All metadata fields of the message will also be set as key/value pairs, if there is a key collision between a metadata item and the body then the body takes precedence.\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.\n\nThis output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "body_key": {
          "default": "body",
          "description": "A key to set the raw body of the message to.",
          "type": "string"
        },
        "kind": {
          "default": "simple",
          "description": "Specifies a simple, cluster-aware, or failover-aware redis client.",
          "enum": [
            "simple",
            "cluster",
            "failover"
          ],
          "type": "string",
          "x-advanced": true
        },
        "master": {
          "default": "",
          "description": "Name of the redis master when `kind` is `failover`",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "max_length": {
          "default": 0,
          "description": "When greater than zero enforces a rough cap on the length of the target stream.",
          "type": "number"
        },
        "metadata": {
          "description": "Specify criteria for which metadata values are included in the message body.",
          "properties": {
            "exclude_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages.",
              "type": "string"
            }
          },
          "required": [
            "exclude_prefixes"
          ],
          "type": "object"
        },
        "stream": {
          "description": "The stream to add messages to.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.\n\n**Troubleshooting**\n\nSome cloud hosted instances of Redis (such as Azure Cache) might need some hand holding in order to establish stable connections. Unfortunately, it is often the case that TLS issues will manifest as generic error messages such as \"i/o timeout\". If you're using TLS and are seeing connectivity problems consider setting `enable_renegotiation` to `true`, and ensuring that the server supports at least TLS version 1.2.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path.",
          "type": "string"
        }
      },
      "required": [
        "kind",
        "master",
        "tls",
        "body_key",
        "metadata",
        "batching",
        "url",
        "stream",
        "max_length",
        "max_in_flight"
      ],
      "type": "object"
    },
    "redpanda": {
      "description": "\nWrites a batch of messages to Kafka brokers and waits for acknowledgement before propagating it back to the input.\n",
      "properties": {
        "broker_write_max_bytes": {
          "default": "100MiB",
          "description": "The upper bound for the number of bytes written to a broker connection in a single write. This field corresponds to Kafka's `socket.request.max.bytes`.",
          "type": "string",
          "x-advanced": true
        },
        "client_id": {
          "default": "benthos",
          "description": "An identifier for the client connection.",
          "type": "string",
          "x-advanced": true
        },
        "compression": {
          "description": "Optionally set an explicit compression type. The default preference is to use snappy when the broker supports it, and fall back to none if not.",
          "enum": [
            "lz4",
            "snappy",
            "gzip",
            "none",
            "zstd"
          ],
          "type": "string",
          "x-advanced": true
        },
        "idempotent_write": {
          "default": true,
          "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER` and can be disabled if this permission is not available.",
          "type": "boolean",
          "x-advanced": true
        },
        "key": {
          "description": "An optional key to populate for each message.",
          "type": "string"
        },
        "max_in_flight": {
          "default": 256,
          "description": "The maximum number of batches to be sending in parallel at any given time.",
          "type": "number"
        },
        "max_message_bytes": {
          "default": "1MiB",
          "description": "The maximum space in bytes than an individual message may take, messages larger than this value will be rejected. This field corresponds to Kafka's `max.message.bytes`.",
          "type": "string",
          "x-advanced": true
        },
        "metadata": {
          "description": "Determine which (if any) metadata values should be added to messages as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string"
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string"
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object"
        },
        "metadata_max_age": {
          "default": "5m",
          "description": "The maximum age of metadata before it is refreshed.",
          "type": "string",
          "x-advanced": true
        },
        "partition": {
          "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.",
          "type": "string"
        },
        "partitioner": {
          "description": "Override the default murmur2 hashing partitioner.",
          "type": "string",
          "x-advanced": true
        },
        "sasl": {
          "description": "Specify one or more methods of SASL authentication. SASL is tried in order; if the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client will pick the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
          "properties": {
            "aws": {
              "description": "Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.",
              "properties": {
                "credentials": {
                  "description": "Optional manual configuration of AWS credentials to use. More information can be found in xref:guides:cloud/aws.adoc[].",
                  "properties": {
                    "from_ec2_role": {
                      "default": false,
                      "description": "Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].",
                      "type": "boolean",
                      "x-advanced": true
                    },
                    "id": {
                      "default": "",
                      "description": "The ID of credentials to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "profile": {
                      "default": "",
                      "description": "A profile from `~/.aws/credentials` to use.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "role": {
                      "default": "",
                      "description": "A role ARN to assume.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "role_external_id": {
                      "default": "",
                      "description": "An external ID to provide when assuming a role.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "secret": {
                      "default": "",
                      "description": "The secret for the credentials being used.",
                      "type": "string",
                      "x-advanced": true
                    },
                    "token": {
                      "default": "",
                      "description": "The token for the credentials being used, required when using short term credentials.",
                      "type": "string",
                      "x-advanced": true
                    }
                  },
                  "required": [
                    "profile",
                    "id",
                    "secret",
                    "token",
                    "from_ec2_role",
                    "role",
                    "role_external_id"
                  ],
                  "type": "object",
                  "x-advanced": true
                },
                "endpoint": {
                  "default": "",
                  "description": "Allows you to specify a custom endpoint for the AWS API.",
                  "type": "string",
                  "x-advanced": true
                },
                "region": {
                  "default": "",
                  "description": "The AWS region to target.",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "region",
                "endpoint",
                "credentials"
              ],
              "type": "object",
              "x-advanced": true
            },
            "extensions": {
              "description": "Key/value pairs to add to OAUTHBEARER authentication requests.",
              "type": "string",
              "x-advanced": true
            },
            "mechanism": {
              "description": "The SASL mechanism to use.",
              "type": "string",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to provide for PLAIN or SCRAM-* authentication.",
              "type": "string",
              "x-advanced": true
            },
            "token": {
              "default": "",
              "description": "The token to use for a single session's OAUTHBEARER authentication.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to provide for PLAIN or SCRAM-* authentication.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "mechanism",
            "username",
            "password",
            "token"
          ],
          "type": "object",
          "x-advanced": true
        },
        "seed_brokers": {
          "description": "A list of broker addresses to connect to in order to establish connections. If an item of the list contains commas it will be expanded into multiple addresses.",
          "type": "string"
        },
        "timeout": {
          "default": "10s",
          "description": "The maximum period of time to wait for message sends before abandoning the request and retrying",
          "type": "string",
          "x-advanced": true
        },
        "timestamp": {
          "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
          "type": "string",
          "x-advanced": true
        },
        "timestamp_ms": {
          "description": "An optional timestamp to set for each message expressed in milliseconds. When left empty, the current timestamp is used.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "topic": {
          "description": "A topic to write messages to.",
          "type": "string"
        }
      },
      "required": [
        "timeout",
        "max_in_flight",
        "client_id",
        "topic",
        "tls",
        "metadata_max_age",
        "max_message_bytes",
        "broker_write_max_bytes",
        "idempotent_write",
        "seed_brokers"
      ],
      "type": "object"
    },
    "redpanda_data_transform": {
      "description": "\nThis processor executes a Redpanda Data Transform WebAssembly module, calling OnRecordWritten for each message being processed.\n\nYou can find out about how transforms work here: https://docs.redpanda.com/current/develop/data-transforms/how-transforms-work/[https://docs.redpanda.com/current/develop/data-transforms/how-transforms-work/^]\n",
      "properties": {
        "input_headers": {
          "description": "Determine which (if any) metadata values should be added to messages as headers.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string"
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string"
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object"
        },
        "input_key": {
          "description": "An optional key to populate for each message.",
          "type": "string"
        },
        "max_memory_pages": {
          "default": 1600,
          "description": "The maximum amount of wasm memory pages (64KiB) that an individual wasm module instance can use",
          "type": "number",
          "x-advanced": true
        },
        "module_path": {
          "description": "The path of the target WASM module to execute.",
          "type": "string"
        },
        "output_key": {
          "description": "An optional name of metadata for an output message key.",
          "type": "string"
        },
        "output_metadata": {
          "description": "Determine which (if any) message headers should be added to the output as metadata.",
          "properties": {
            "include_patterns": {
              "default": [],
              "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against.",
              "type": "string"
            },
            "include_prefixes": {
              "default": [],
              "description": "Provide a list of explicit metadata key prefixes to match against.",
              "type": "string"
            }
          },
          "required": [
            "include_prefixes",
            "include_patterns"
          ],
          "type": "object"
        },
        "timeout": {
          "default": "10s",
          "description": "The maximum period of time for a message to be processed",
          "type": "string",
          "x-advanced": true
        },
        "timestamp": {
          "description": "An optional timestamp to set for each message. When left empty, the current timestamp is used.",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "timeout",
        "max_memory_pages",
        "module_path"
      ],
      "type": "object"
    },
    "reject": {
      "description": "\nThe routing of messages after this output depends on the type of input it came from. For inputs that support propagating nacks upstream such as AMQP or NATS the message will be nacked. However, for inputs that are sequential such as files or Kafka the messages will simply be reprocessed from scratch.\n\nTo learn when this output could be useful, see [the \u003c\u003cexamples\u003e\u003e.",
      "type": "object"
    },
    "reject_errored": {
      "description": "\nThe routing of messages rejected by this output depends on the type of input it came from. For inputs that support propagating nacks upstream such as AMQP or NATS the message will be nacked. However, for inputs that are sequential such as files or Kafka the messages will simply be reprocessed from scratch.",
      "type": "object"
    },
    "resource": {
      "description": "Resources allow you to tidy up deeply nested configs. For example, the config:\n\n```yaml\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n    - kafka:\n        addresses: [ TODO ]\n        topic: foo\n    - gcp_pubsub:\n        project: bar\n        topic: baz\n```\n\nCould also be expressed as:\n\n```yaml\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n    - resource: foo\n    - resource: bar\n\noutput_resources:\n  - label: foo\n    kafka:\n      addresses: [ TODO ]\n      topic: foo\n\n  - label: bar\n    gcp_pubsub:\n      project: bar\n      topic: baz\n```\n\nYou can find out more about resources in xref:configuration:resources.adoc[]",
      "type": "object"
    },
    "retry": {
      "description": "\nAll messages in Redpanda Connect are always retried on an output error, but this would usually involve propagating the error back to the source of the message, whereby it would be reprocessed before reaching the output layer once again.\n\nThis output type is useful whenever we wish to avoid reprocessing a message on the event of a failed send. We might, for example, have a deduplication processor that we want to avoid reapplying to the same message more than once in the pipeline.\n\nRather than retrying the same output you may wish to retry the send using a different output target (a dead letter queue). In which case you should instead use the xref:components:outputs/fallback.adoc[`fallback`] output type.",
      "properties": {
        "backoff": {
          "description": "Control time intervals between retry attempts.",
          "properties": {
            "initial_interval": {
              "default": "500ms",
              "description": "The initial period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            },
            "max_elapsed_time": {
              "default": "0s",
              "description": "The maximum period to wait before retry attempts are abandoned. If zero then no limit is used.",
              "type": "string",
              "x-advanced": true
            },
            "max_interval": {
              "default": "3s",
              "description": "The maximum period to wait between retry attempts.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "initial_interval",
            "max_interval",
            "max_elapsed_time"
          ],
          "type": "object",
          "x-advanced": true
        },
        "max_retries": {
          "default": 0,
          "description": "The maximum number of retries before giving up on the request. If set to zero there is no discrete limit.",
          "type": "number",
          "x-advanced": true
        },
        "output": {
          "description": "A child output.",
          "type": "string"
        }
      },
      "required": [
        "max_retries",
        "backoff",
        "output"
      ],
      "type": "object"
    },
    "s7comm": {
      "description": "This input plugin enables Benthos to read data directly from Siemens S7 PLCs using the S7comm protocol. Configure the plugin by specifying the PLC's IP address, rack and slot numbers, and the data blocks to read.",
      "properties": {
        "addresses": {
          "description": "Format: '\u003carea\u003e.\u003ctype\u003e\u003caddress\u003e[.extra]'. Examples: 'DB5.X3.2' (bit), 'DB5.B3' (byte), 'DB5.C3' (character). Direct area access (DB1 = data block 1). Data types: X (bit), B (byte), W (word), DW (double word).",
          "type": "string"
        },
        "batchMaxSize": {
          "default": 480,
          "description": "Maximum count of addresses to be bundled in one batch-request (PDU size).",
          "type": "number",
          "x-advanced": true
        },
        "disableCPUInfo": {
          "default": false,
          "description": "Set this to true to not fetch CPU information from the PLC. Should be used when you get the error 'Failed to get CPU information'",
          "type": "boolean",
          "x-advanced": true
        },
        "rack": {
          "default": 0,
          "description": "Rack number of the PLC. Identifies the physical location of the CPU within the PLC rack.",
          "type": "number"
        },
        "slot": {
          "default": 1,
          "description": "Slot number of the PLC. Identifies the CPU slot within the rack.",
          "type": "number"
        },
        "tcpDevice": {
          "description": "IP address of the S7 PLC.",
          "type": "string"
        },
        "timeout": {
          "default": 10,
          "description": "The timeout duration in seconds for connection attempts and read requests.",
          "type": "number",
          "x-advanced": true
        }
      },
      "required": [
        "addresses",
        "tcpDevice"
      ],
      "type": "object"
    },
    "schema_registry_decode": {
      "description": "\nDecodes messages automatically from a schema stored within a https://docs.confluent.io/platform/current/schema-registry/index.html[Confluent Schema Registry service^] by extracting a schema ID from the message and obtaining the associated schema from the registry. If a message fails to match against the schema then it will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].\n\nAvro, Protobuf and Json schemas are supported, all are capable of expanding from schema references as of v4.22.0.\n\n== Avro JSON format\n\nThis processor creates documents formatted as https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^] when decoding with Avro schemas. In this format the value of a union is encoded in JSON as follows:\n\n- if its type is `null`, then it is encoded as a JSON `null`;\n- otherwise it is encoded as a JSON object with one name/value pair whose name is the type's name and whose value is the recursively encoded value. For Avro's named types (record, fixed or enum) the user-specified name is used, for other types the type name is used.\n\nFor example, the union schema `[\"null\",\"string\",\"Foo\"]`, where `Foo` is a record name, would encode:\n\n- `null` as `null`;\n- the string `\"a\"` as `{\"string\": \"a\"}`; and\n- a `Foo` instance as `{\"Foo\": {...}}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n\nHowever, it is possible to instead create documents in https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard/raw JSON format^] by setting the field \u003c\u003cavro_raw_json, `avro_raw_json`\u003e\u003e to `true`.\n\n== Protobuf format\n\nThis processor decodes protobuf messages to JSON documents, you can read more about JSON mapping of protobuf messages here: https://developers.google.com/protocol-buffers/docs/proto3#json\n\n== Metadata\n\nThis processor also adds the following metadata to each outgoing message:\n\nschema_id: the ID of the schema in the schema registry that was associated with the message.\n",
      "properties": {
        "avro": {
          "description": "Configuration for how to decode schemas that are of type AVRO.",
          "properties": {
            "mapping": {
              "description": "A custom mapping to apply to Avro schemas JSON representation. This is useful to transform custom types emitted by other tools into standard avro.",
              "type": "string",
              "x-advanced": true
            },
            "preserve_logical_types": {
              "default": false,
              "description": "Whether logical types should be preserved or transformed back into their primitive type. By default, decimals are decoded as raw bytes and timestamps are decoded as plain integers. Setting this field to true keeps decimal types as numbers in bloblang and timestamps as time values.",
              "type": "boolean"
            },
            "raw_unions": {
              "description": "Whether avro messages should be decoded into normal JSON (\"json that meets the expectations of regular internet json\") rather than https://avro.apache.org/docs/current/specification/_print/#json-encoding[JSON as specified in the Avro Spec^].\n\nFor example, if there is a union schema `[\"null\", \"string\", \"Foo\"]` where `Foo` is a record name, with raw_unions as false (the default) you get:\n- `null` as `null`;\n- the string `\"a\"` as `{\"string\": \"a\"}`; and\n- a `Foo` instance as `{\"Foo\": {...}}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n\nWhen raw_unions is set to true then the above union schema is decoded as the following:\n- `null` as `null`;\n- the string `\"a\"` as `\"a\"`; and\n- a `Foo` instance as `{...}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n",
              "type": "boolean"
            }
          },
          "required": [
            "preserve_logical_types"
          ],
          "type": "object"
        },
        "avro_raw_json": {
          "default": false,
          "description": "Whether Avro messages should be decoded into normal JSON (\"json that meets the expectations of regular internet json\") rather than https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^]. If `true` the schema returned from the subject should be decoded as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard json^] instead of as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodec[avro json^]. There is a https://github.com/linkedin/goavro/blob/5ec5a5ee7ec82e16e6e2b438d610e1cab2588393/union.go#L224-L249[comment in goavro^], the https://github.com/linkedin/goavro[underlining library used for avro serialization^], that explains in more detail the difference between the standard json and avro json.",
          "type": "boolean",
          "x-advanced": true
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "jwt": {
          "description": "BETA: Allows you to specify JWT authentication.",
          "properties": {
            "claims": {
              "default": {},
              "description": "A value used to identify the claims that issued the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use JWT authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "headers": {
              "default": {},
              "description": "Add optional key/value headers to the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "private_key_file": {
              "default": "",
              "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
              "type": "string",
              "x-advanced": true
            },
            "signing_method": {
              "default": "",
              "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "private_key_file",
            "signing_method",
            "claims",
            "headers"
          ],
          "type": "object",
          "x-advanced": true
        },
        "oauth": {
          "description": "Allows you to specify open authentication via OAuth version 1.",
          "properties": {
            "access_token": {
              "default": "",
              "description": "A value used to gain access to the protected resources on behalf of the user.",
              "type": "string",
              "x-advanced": true
            },
            "access_token_secret": {
              "default": "",
              "description": "A secret provided in order to establish ownership of a given access token.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_key": {
              "default": "",
              "description": "A value used to identify the client to the service provider.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_secret": {
              "default": "",
              "description": "A secret used to establish ownership of the consumer key.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use OAuth version 1 in requests.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "consumer_key",
            "consumer_secret",
            "access_token",
            "access_token_secret"
          ],
          "type": "object",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The base URL of the schema registry service.",
          "type": "string"
        }
      },
      "required": [
        "jwt",
        "tls",
        "avro_raw_json",
        "avro",
        "url"
      ],
      "type": "object"
    },
    "schema_registry_encode": {
      "description": "\nEncodes messages automatically from schemas obtains from a https://docs.confluent.io/platform/current/schema-registry/index.html[Confluent Schema Registry service^] by polling the service for the latest schema version for target subjects.\n\nIf a message fails to encode under the schema then it will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].\n\nAvro, Protobuf and Json schemas are supported, all are capable of expanding from schema references as of v4.22.0.\n\n== Avro JSON format\n\nBy default this processor expects documents formatted as https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^] when encoding with Avro schemas. In this format the value of a union is encoded in JSON as follows:\n\n- if its type is `null`, then it is encoded as a JSON `null`;\n- otherwise it is encoded as a JSON object with one name/value pair whose name is the type's name and whose value is the recursively encoded value. For Avro's named types (record, fixed or enum) the user-specified name is used, for other types the type name is used.\n\nFor example, the union schema `[\"null\",\"string\",\"Foo\"]`, where `Foo` is a record name, would encode:\n\n- `null` as `null`;\n- the string `\"a\"` as `\\{\"string\": \"a\"}`; and\n- a `Foo` instance as `\\{\"Foo\": {...}}`, where `{...}` indicates the JSON encoding of a `Foo` instance.\n\nHowever, it is possible to instead consume documents in https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard/raw JSON format^] by setting the field \u003c\u003cavro_raw_json, `avro_raw_json`\u003e\u003e to `true`.\n\n=== Known issues\n\nImportant! There is an outstanding issue in the https://github.com/linkedin/goavro[avro serializing library^] that Redpanda Connect uses which means it https://github.com/linkedin/goavro/issues/252[doesn't encode logical types correctly^]. It's still possible to encode logical types that are in-line with the spec if `avro_raw_json` is set to true, though now of course non-logical types will not be in-line with the spec.\n\n== Protobuf format\n\nThis processor encodes protobuf messages either from any format parsed within Redpanda Connect (encoded as JSON by default), or from raw JSON documents, you can read more about JSON mapping of protobuf messages here: https://developers.google.com/protocol-buffers/docs/proto3#json\n\n=== Multiple message support\n\nWhen a target subject presents a protobuf schema that contains multiple messages it becomes ambiguous which message definition a given input data should be encoded against. In such scenarios Redpanda Connect will attempt to encode the data against each of them and select the first to successfully match against the data, this process currently *ignores all nested message definitions*. In order to speed up this exhaustive search the last known successful message will be attempted first for each subsequent input.\n\nWe will be considering alternative approaches in future so please https://redpanda.com/slack[get in touch^] with thoughts and feedback.\n",
      "properties": {
        "avro_raw_json": {
          "default": false,
          "description": "Whether messages encoded in Avro format should be parsed as normal JSON (\"json that meets the expectations of regular internet json\") rather than https://avro.apache.org/docs/current/specification/_print/#json-encoding[Avro JSON^]. If `true` the schema returned from the subject should be parsed as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard json^] instead of as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodec[avro json^]. There is a https://github.com/linkedin/goavro/blob/5ec5a5ee7ec82e16e6e2b438d610e1cab2588393/union.go#L224-L249[comment in goavro^], the https://github.com/linkedin/goavro[underlining library used for avro serialization^], that explains in more detail the difference between standard json and avro json.",
          "type": "boolean",
          "x-advanced": true
        },
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "jwt": {
          "description": "BETA: Allows you to specify JWT authentication.",
          "properties": {
            "claims": {
              "default": {},
              "description": "A value used to identify the claims that issued the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use JWT authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "headers": {
              "default": {},
              "description": "Add optional key/value headers to the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "private_key_file": {
              "default": "",
              "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
              "type": "string",
              "x-advanced": true
            },
            "signing_method": {
              "default": "",
              "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "private_key_file",
            "signing_method",
            "claims",
            "headers"
          ],
          "type": "object",
          "x-advanced": true
        },
        "oauth": {
          "description": "Allows you to specify open authentication via OAuth version 1.",
          "properties": {
            "access_token": {
              "default": "",
              "description": "A value used to gain access to the protected resources on behalf of the user.",
              "type": "string",
              "x-advanced": true
            },
            "access_token_secret": {
              "default": "",
              "description": "A secret provided in order to establish ownership of a given access token.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_key": {
              "default": "",
              "description": "A value used to identify the client to the service provider.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_secret": {
              "default": "",
              "description": "A secret used to establish ownership of the consumer key.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use OAuth version 1 in requests.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "consumer_key",
            "consumer_secret",
            "access_token",
            "access_token_secret"
          ],
          "type": "object",
          "x-advanced": true
        },
        "refresh_period": {
          "default": "10m",
          "description": "The period after which a schema is refreshed for each subject, this is done by polling the schema registry service.",
          "type": "string"
        },
        "subject": {
          "description": "The schema subject to derive schemas from.",
          "type": "string"
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The base URL of the schema registry service.",
          "type": "string"
        }
      },
      "required": [
        "subject",
        "refresh_period",
        "avro_raw_json",
        "jwt",
        "tls",
        "url"
      ],
      "type": "object"
    },
    "select_parts": {
      "description": "\nThe selected parts are added to the new message batch in the same order as the selection array. E.g. with 'parts' set to [ 2, 0, 1 ] and the message parts [ '0', '1', '2', '3' ], the output will be [ '2', '0', '1' ].\n\nIf none of the selected parts exist in the input batch (resulting in an empty output message) the batch is dropped entirely.\n\nMessage indexes can be negative, and if so the part will be selected from the end counting backwards starting from -1. E.g. if index = -1 then the selected part will be the last part of the message, if index = -2 then the part before the last element with be selected, and so on.\n\nThis processor is only applicable to xref:configuration:batching.adoc[batched messages].",
      "properties": {
        "parts": {
          "default": [],
          "description": "An array of message indexes of a batch. Indexes can be negative, and if so the part will be selected from the end counting backwards starting from -1.",
          "type": "number"
        }
      },
      "required": [
        "parts"
      ],
      "type": "object"
    },
    "sensorconnect": {
      "description": "This plugin replaces the 'sensorconnect' microservice as a Benthos plugin.",
      "properties": {
        "device_address": {
          "description": "IP address or hostname of the IFM IO-Link master device",
          "type": "string"
        },
        "devices": {
          "description": "List of devices with specific configuration options",
          "properties": {
            "device_id": {
              "description": "The device ID of the IO-Link device",
              "type": "number"
            },
            "iodd_url": {
              "description": "Fallback URL to download the IODD file if not found in the IODD API",
              "type": "string"
            },
            "vendor_id": {
              "description": "The vendor ID of the IO-Link device",
              "type": "number"
            }
          },
          "required": [
            "device_id",
            "vendor_id",
            "iodd_url"
          ],
          "type": "object"
        },
        "iodd_api": {
          "default": "https://management.umh.app/iodd",
          "description": "URL of the IODD API",
          "type": "string",
          "x-advanced": true
        }
      },
      "required": [
        "device_address",
        "devices"
      ],
      "type": "object"
    },
    "sentry_capture": {
      "description": "Captures log events from messages and submits them to https://sentry.io/[Sentry^].",
      "properties": {
        "context": {
          "description": "A mapping that must evaluate to an object-of-objects or `deleted()`. If this mapping produces a value, then it is set on a sentry event as additional context.",
          "type": "string"
        },
        "dsn": {
          "default": "",
          "description": "The DSN address to send sentry events to. If left empty, then SENTRY_DSN is used.",
          "type": "string"
        },
        "environment": {
          "default": "",
          "description": "The environment to be sent with events. If left empty, then SENTRY_ENVIRONMENT is used.",
          "type": "string"
        },
        "flush_timeout": {
          "default": "5s",
          "description": "The duration to wait when closing the processor to flush any remaining enqueued events.",
          "type": "string"
        },
        "level": {
          "default": "INFO",
          "description": "Sets the level on sentry events similar to logging levels.",
          "enum": [
            "DEBUG",
            "INFO",
            "WARN",
            "ERROR",
            "FATAL"
          ],
          "type": "string"
        },
        "message": {
          "description": "A message to set on the sentry event",
          "type": "string"
        },
        "release": {
          "default": "",
          "description": "The version of the code deployed to an environment. If left empty, then the Sentry client will attempt to detect the release from the environment.",
          "type": "string"
        },
        "sampling_rate": {
          "default": 1,
          "description": "The rate at which events are sent to the server. A value of 0 disables capturing sentry events entirely. A value of 1 results in sending all events to Sentry. Any value in between results sending some percentage of events.",
          "type": "number"
        },
        "tags": {
          "description": "Sets key/value string tags on an event. Unlike context, these are indexed and searchable on Sentry but have length limitations.",
          "type": "string"
        },
        "transport_mode": {
          "default": "async",
          "description": "Determines how events are sent. A sync transport will block when sending each event until a response is received from the Sentry server. The recommended async transport will enqueue events in a buffer and send them in the background.",
          "enum": [
            "async",
            "sync"
          ],
          "type": "string"
        }
      },
      "required": [
        "environment",
        "level",
        "transport_mode",
        "flush_timeout",
        "sampling_rate",
        "dsn",
        "message",
        "release"
      ],
      "type": "object"
    },
    "sequence": {
      "description": "This input is useful for consuming from inputs that have an explicit end but must not be consumed in parallel.",
      "properties": {
        "inputs": {
          "description": "An array of inputs to read from sequentially.",
          "type": "string"
        },
        "sharded_join": {
          "description": "EXPERIMENTAL: Provides a way to perform outer joins of arbitrarily structured and unordered data resulting from the input sequence, even when the overall size of the data surpasses the memory available on the machine.\n\nWhen configured the sequence of inputs will be consumed one or more times according to the number of iterations, and when more than one iteration is specified each iteration will process an entirely different set of messages by sharding them by the ID field. Increasing the number of iterations reduces the memory consumption at the cost of needing to fully parse the data each time.\n\nEach message must be structured (JSON or otherwise processed into a structured form) and the fields will be aggregated with those of other messages sharing the ID. At the end of each iteration the joined messages are flushed downstream before the next iteration begins, hence keeping memory usage limited.",
          "properties": {
            "id_path": {
              "default": "",
              "description": "A xref:configuration:field_paths.adoc[dot path] that points to a common field within messages of each fragmented data set and can be used to join them. Messages that are not structured or are missing this field will be dropped. This field must be set in order to enable joins.",
              "type": "string",
              "x-advanced": true
            },
            "iterations": {
              "default": 1,
              "description": "The total number of iterations (shards), increasing this number will increase the overall time taken to process the data, but reduces the memory used in the process. The real memory usage required is significantly higher than the real size of the data and therefore the number of iterations should be at least an order of magnitude higher than the available memory divided by the overall size of the dataset.",
              "type": "number",
              "x-advanced": true
            },
            "merge_strategy": {
              "default": "array",
              "description": "The chosen strategy to use when a data join would otherwise result in a collision of field values. The strategy `array` means non-array colliding values are placed into an array and colliding arrays are merged. The strategy `replace` replaces old values with new values. The strategy `keep` keeps the old value.",
              "enum": [
                "array",
                "replace",
                "keep"
              ],
              "type": "string",
              "x-advanced": true
            },
            "type": {
              "default": "none",
              "description": "The type of join to perform. A `full-outer` ensures that all identifiers seen in any of the input sequences are sent, and is performed by consuming all input sequences before flushing the joined results. An `outer` join consumes all input sequences but only writes data joined from the last input in the sequence, similar to a left or right outer join. With an `outer` join if an identifier appears multiple times within the final sequence input it will be flushed each time it appears. `full-outter` and `outter` have been deprecated in favour of `full-outer` and `outer`.",
              "enum": [
                "none",
                "full-outer",
                "outer",
                "full-outter",
                "outter"
              ],
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "type",
            "id_path",
            "iterations",
            "merge_strategy"
          ],
          "type": "object",
          "x-advanced": true
        }
      },
      "required": [
        "sharded_join",
        "inputs"
      ],
      "type": "object"
    },
    "sftp": {
      "description": "In order to have a different path for each object you should use function interpolations described xref:configuration:interpolation.adoc#bloblang-queries[here].\n\n== Performance\n\nThis output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.",
      "properties": {
        "address": {
          "description": "The address of the server to connect to.",
          "type": "string"
        },
        "codec": {
          "default": "all-bytes",
          "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
          "type": "string"
        },
        "credentials": {
          "description": "The credentials to use to log into the target server.",
          "properties": {
            "password": {
              "default": "",
              "description": "The password for the username to connect to the SFTP server.",
              "type": "string"
            },
            "private_key_file": {
              "default": "",
              "description": "The private key for the username to connect to the SFTP server.",
              "type": "string"
            },
            "private_key_pass": {
              "default": "",
              "description": "Optional passphrase for private key.",
              "type": "string"
            },
            "username": {
              "default": "",
              "description": "The username to connect to the SFTP server.",
              "type": "string"
            }
          },
          "required": [
            "username",
            "password",
            "private_key_file",
            "private_key_pass"
          ],
          "type": "object"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "path": {
          "description": "The file to save the messages to on the server.",
          "type": "string"
        }
      },
      "required": [
        "address",
        "path",
        "codec",
        "credentials",
        "max_in_flight"
      ],
      "type": "object"
    },
    "sleep": {
      "description": "Sleep for a period of time specified as a duration string for each message. This processor will interpolate functions within the `duration` field, you can find a list of functions xref:configuration:interpolation.adoc#bloblang-queries[here].",
      "properties": {
        "duration": {
          "description": "The duration of time to sleep for each execution.",
          "type": "string"
        }
      },
      "required": [
        "duration"
      ],
      "type": "object"
    },
    "smtp": {
      "description": "This output plugin enables Benthos to send data via email using smtp. Configure the plugin by specifying the stmp server address, port, sender address and recipients.",
      "properties": {
        "InsecureSkipVerify": {
          "default": false,
          "description": "InsecureSkipVerify",
          "type": "boolean"
        },
        "TLS": {
          "default": "",
          "description": "STARTTLS or SMTPS",
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "password": {
          "default": "",
          "description": "password",
          "type": "string"
        },
        "recipients": {
          "description": "List of recipients to send to",
          "type": "string"
        },
        "senderAddress": {
          "description": "sender Address",
          "type": "string"
        },
        "serverAddress": {
          "description": "smtp server address.",
          "type": "string"
        },
        "serverPort": {
          "default": 25,
          "description": "server port. Default 25)",
          "type": "number"
        },
        "username": {
          "default": "",
          "description": "username",
          "type": "string"
        }
      },
      "required": [
        "max_in_flight",
        "serverAddress",
        "serverPort",
        "InsecureSkipVerify",
        "senderAddress",
        "recipients",
        "username",
        "password",
        "TLS"
      ],
      "type": "object"
    },
    "socket": {
      "description": "Connects to a (tcp/udp/unix) server and sends a continuous stream of data, dividing messages according to the specified codec.",
      "properties": {
        "address": {
          "description": "The address to connect to.",
          "type": "string"
        },
        "codec": {
          "default": "lines",
          "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
          "type": "string"
        },
        "network": {
          "description": "A network type to connect as.",
          "enum": [
            "unix",
            "tcp",
            "udp"
          ],
          "type": "string"
        }
      },
      "required": [
        "network",
        "address",
        "codec"
      ],
      "type": "object"
    },
    "socket_server": {
      "description": "Creates a server that receives a stream of messages over a TCP, UDP or Unix socket.",
      "properties": {
        "address": {
          "description": "The address to listen from.",
          "type": "string"
        },
        "address_cache": {
          "description": "An optional xref:components:caches/about.adoc[`cache`] within which this input should write it's bound address once known. The key of the cache item containing the address will be the label of the component suffixed with `_address` (e.g. `foo_address`), or `socket_server_address` when a label has not been provided. This is useful in situations where the address is dynamically allocated by the server (`127.0.0.1:0`) and you want to store the allocated address somewhere for reference by other systems and components.",
          "type": "string"
        },
        "auto_replay_nacks": {
          "default": true,
          "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
          "type": "boolean"
        },
        "codec": {
          "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
          "type": "string"
        },
        "max_buffer": {
          "default": 1000000,
          "type": "number"
        },
        "network": {
          "description": "A network type to accept.",
          "enum": [
            "unix",
            "tcp",
            "udp",
            "tls"
          ],
          "type": "string"
        },
        "scanner": {
          "default": {
            "lines": {}
          },
          "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
          "type": "string"
        },
        "tls": {
          "description": "TLS specific configuration, valid when the `network` is set to `tls`.",
          "properties": {
            "cert_file": {
              "description": "PEM encoded certificate for use with TLS.",
              "type": "string"
            },
            "client_auth": {
              "default": "no",
              "description": "How client authentication is handled.",
              "type": "string"
            },
            "key_file": {
              "description": "PEM encoded private key for use with TLS.",
              "type": "string"
            },
            "self_signed": {
              "default": false,
              "description": "Whether to generate self signed certificates.",
              "type": "boolean"
            }
          },
          "required": [
            "self_signed",
            "client_auth"
          ],
          "type": "object"
        }
      },
      "required": [
        "network",
        "address",
        "auto_replay_nacks",
        "max_buffer"
      ],
      "type": "object"
    },
    "sparkplug_b": {
      "description": "The Sparkplug B output acts as an Edge Node, publishing data to Sparkplug MQTT topics \nwith complete session lifecycle management. It handles BIRTH/DEATH certificates, maintains sequence \nnumbers, manages alias mappings, and ensures full Sparkplug B compliance.\n\nKey features:\n- Always operates as Edge Node (no role configuration needed)\n- Automatic NBIRTH/DBIRTH on connect with metric definitions\n- NDEATH/DDEATH Last Will Testament on disconnect\n- Sequence number management with proper wrapping\n- Alias-based metric publishing for bandwidth efficiency\n- Automatic type detection and conversion\n- Configurable metric definitions with aliases\n- Robust reconnection handling with proper rebirth\n- UNS metadata integration for seamless data flow\n\nThe output connects to an MQTT broker, publishes BIRTH certificates to announce available metrics,\nand then publishes DATA messages as Benthos messages flow through the pipeline.",
      "properties": {
        "behaviour": {
          "description": "Processing behavior configuration",
          "properties": {
            "auto_extract_tag_name": {
              "default": true,
              "description": "Whether to automatically extract tag_name from message metadata",
              "type": "boolean"
            },
            "retain_last_values": {
              "default": true,
              "description": "Whether to retain last known values for BIRTH messages after reconnection",
              "type": "boolean"
            }
          },
          "required": [
            "auto_extract_tag_name",
            "retain_last_values"
          ],
          "type": "object"
        },
        "identity": {
          "description": "Sparkplug identity configuration",
          "properties": {
            "device_id": {
              "default": "",
              "description": "Device ID under the edge node (optional, if not specified acts as node-level)",
              "type": "string"
            },
            "edge_node_id": {
              "description": "Edge Node ID within the group (e.g., 'Line3'). If empty, auto-generated from location_path metadata using Parris Method",
              "type": "string"
            },
            "group_id": {
              "description": "Sparkplug Group ID (e.g., 'FactoryA')",
              "type": "string"
            }
          },
          "required": [
            "group_id"
          ],
          "type": "object"
        },
        "metrics": {
          "description": "Metric definitions for BIRTH messages and alias mapping",
          "properties": {
            "alias": {
              "description": "Numeric alias for this metric (1-65535)",
              "type": "number"
            },
            "name": {
              "description": "Metric name as it will appear in BIRTH messages",
              "type": "string"
            },
            "type": {
              "default": "double",
              "description": "Data type: int8, int16, int32, int64, uint8, uint16, uint32, uint64, float, double, boolean, string",
              "type": "string"
            },
            "value_from": {
              "default": "value",
              "description": "JSONPath or field name in the message to extract value from",
              "type": "string"
            }
          },
          "required": [
            "name",
            "alias",
            "type",
            "value_from"
          ],
          "type": "object"
        },
        "mqtt": {
          "description": "MQTT transport configuration",
          "properties": {
            "clean_session": {
              "default": true,
              "description": "MQTT clean session flag",
              "type": "boolean"
            },
            "client_id": {
              "default": "benthos-sparkplug-output",
              "description": "MQTT client ID for this edge node",
              "type": "string"
            },
            "connect_timeout": {
              "default": "30s",
              "description": "MQTT connection timeout",
              "type": "string"
            },
            "credentials": {
              "description": "MQTT authentication credentials",
              "properties": {
                "password": {
                  "default": "",
                  "description": "MQTT password for authentication",
                  "type": "string"
                },
                "username": {
                  "default": "",
                  "description": "MQTT username for authentication",
                  "type": "string"
                }
              },
              "type": "object"
            },
            "keep_alive": {
              "default": "60s",
              "description": "MQTT keep alive interval",
              "type": "string"
            },
            "qos": {
              "default": 1,
              "description": "QoS level for MQTT publishing (0, 1, or 2)",
              "type": "number"
            },
            "urls": {
              "default": [
                "tcp://localhost:1883"
              ],
              "description": "List of MQTT broker URLs to connect to",
              "type": "string"
            }
          },
          "required": [
            "urls",
            "client_id",
            "qos",
            "keep_alive",
            "connect_timeout",
            "clean_session"
          ],
          "type": "object"
        }
      },
      "required": [
        "mqtt",
        "identity"
      ],
      "type": "object"
    },
    "spicedb_watch": {
      "description": "\nThe SpiceDB input allows you to consume messages from the Watch API of a SpiceDB instance.\nThis input is useful for applications that need to react to changes in the data managed by SpiceDB in real-time.\n\n== Credentials\n\nYou need to provide the endpoint of your SpiceDB instance and a Bearer token for authentication.\n\n== Cache\n\nThe zed token of the newest update consumed and acked is stored in a cache in order to start reading from it each time the input is initialised.\nIdeally this cache should be persisted across restarts.\n",
      "properties": {
        "bearer_token": {
          "default": "",
          "description": "The SpiceDB Bearer token used to authenticate against the SpiceDB instance.",
          "type": "string"
        },
        "cache": {
          "description": "A cache resource to use for performing unread message backfills, the ID of the last message received will be stored in this cache and used for subsequent requests.",
          "type": "string"
        },
        "cache_key": {
          "default": "authzed.com/spicedb/watch/last_zed_token",
          "description": "The key identifier used when storing the ID of the last message received.",
          "type": "string",
          "x-advanced": true
        },
        "endpoint": {
          "description": "The SpiceDB endpoint.",
          "type": "string"
        },
        "max_receive_message_bytes": {
          "default": "4MB",
          "description": "Maximum message size in bytes the SpiceDB client can receive.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        }
      },
      "required": [
        "max_receive_message_bytes",
        "cache",
        "cache_key",
        "tls",
        "endpoint",
        "bearer_token"
      ],
      "type": "object"
    },
    "split": {
      "description": "\nThis processor is for breaking batches down into smaller ones. In order to break a single message out into multiple messages use the xref:components:processors/unarchive.adoc[`unarchive` processor].\n\nIf there is a remainder of messages after splitting a batch the remainder is also sent as a single batch. For example, if your target size was 10, and the processor received a batch of 95 message parts, the result would be 9 batches of 10 messages followed by a batch of 5 messages.",
      "properties": {
        "byte_size": {
          "default": 0,
          "description": "An optional target of total message bytes.",
          "type": "number"
        },
        "size": {
          "default": 1,
          "description": "The target number of messages.",
          "type": "number"
        }
      },
      "required": [
        "size",
        "byte_size"
      ],
      "type": "object"
    },
    "sql": {
      "description": "\n== Alternatives\n\nFor basic inserts use the xref:components:outputs/sql.adoc[`sql_insert`] output. For more complex queries use the xref:components:outputs/sql_raw.adoc[`sql_raw`] output.",
      "properties": {
        "args_mapping": {
          "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
          "type": "string"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "data_source_name": {
          "description": "Data source name.",
          "type": "string"
        },
        "driver": {
          "description": "A database \u003c\u003cdrivers, driver\u003e\u003e to use.",
          "enum": [
            "mysql",
            "postgres",
            "clickhouse",
            "mssql",
            "sqlite",
            "oracle",
            "snowflake",
            "trino",
            "gocosmos",
            "spanner"
          ],
          "type": "string"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of inserts to run in parallel.",
          "type": "number"
        },
        "query": {
          "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
          "type": "string"
        }
      },
      "required": [
        "max_in_flight",
        "batching",
        "driver",
        "data_source_name",
        "query"
      ],
      "type": "object"
    },
    "sql_insert": {
      "description": "Inserts a row into an SQL database for each message.",
      "properties": {
        "args_mapping": {
          "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of columns specified.",
          "type": "string"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "columns": {
          "description": "A list of columns to insert.",
          "type": "string"
        },
        "conn_max_idle": {
          "default": 2,
          "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value \u003c= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
          "type": "number",
          "x-advanced": true
        },
        "conn_max_idle_time": {
          "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value \u003c= 0`, connections are not closed due to a connections idle time.",
          "type": "string",
          "x-advanced": true
        },
        "conn_max_life_time": {
          "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value \u003c= 0`, connections are not closed due to a connections age.",
          "type": "string",
          "x-advanced": true
        },
        "conn_max_open": {
          "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value \u003c= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
          "type": "number",
          "x-advanced": true
        },
        "driver": {
          "description": "A database \u003c\u003cdrivers, driver\u003e\u003e to use.",
          "enum": [
            "mysql",
            "postgres",
            "clickhouse",
            "mssql",
            "sqlite",
            "oracle",
            "snowflake",
            "trino",
            "gocosmos",
            "spanner"
          ],
          "type": "string"
        },
        "dsn": {
          "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1\u0026...\u0026paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1\u0026...\u0026paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1\u0026...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname\u0026param1=value1\u0026...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param\u0026=value1\u0026...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2\u0026server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value\u0026...\u0026paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=\u003ccosmosdb-endpoint\u003e;AccountKey=\u003ccosmosdb-account-key\u003e[;TimeoutMs=\u003ctimeout-in-ms\u003e\\][;Version=\u003ccosmosdb-api-version\u003e\\][;DefaultDb/Db=\u003cdb-name\u003e\\][;AutoId=\u003ctrue/false\u003e\\][;InsecureSkipVerify=\u003ctrue/false\u003e\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `\u003csnowflake_user\u003e@\u003csnowflake_account\u003e/\u003cdb_name\u003e/\u003cschema_name\u003e?warehouse=\u003cwarehouse\u003e\u0026role=\u003crole\u003e\u0026authenticator=snowflake_jwt\u0026privateKey=\u003cbase64_url_encoded_private_key\u003e`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
          "type": "string"
        },
        "init_files": {
          "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
          "type": "string",
          "x-advanced": true
        },
        "init_statement": {
          "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of inserts to run in parallel.",
          "type": "number"
        },
        "options": {
          "description": "A list of keyword options to add before the INTO clause of the query.",
          "type": "string",
          "x-advanced": true
        },
        "prefix": {
          "description": "An optional prefix to prepend to the insert query (before INSERT).",
          "type": "string",
          "x-advanced": true
        },
        "suffix": {
          "description": "An optional suffix to append to the insert query.",
          "type": "string",
          "x-advanced": true
        },
        "table": {
          "description": "The table to insert to.",
          "type": "string"
        }
      },
      "required": [
        "dsn",
        "columns",
        "batching",
        "table",
        "args_mapping",
        "driver",
        "max_in_flight"
      ],
      "type": "object"
    },
    "sql_raw": {
      "description": "Executes an arbitrary SQL query for each message.",
      "properties": {
        "args_mapping": {
          "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
          "type": "string"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "conn_max_idle": {
          "default": 2,
          "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value \u003c= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
          "type": "number",
          "x-advanced": true
        },
        "conn_max_idle_time": {
          "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value \u003c= 0`, connections are not closed due to a connections idle time.",
          "type": "string",
          "x-advanced": true
        },
        "conn_max_life_time": {
          "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value \u003c= 0`, connections are not closed due to a connections age.",
          "type": "string",
          "x-advanced": true
        },
        "conn_max_open": {
          "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value \u003c= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
          "type": "number",
          "x-advanced": true
        },
        "driver": {
          "description": "A database \u003c\u003cdrivers, driver\u003e\u003e to use.",
          "enum": [
            "mysql",
            "postgres",
            "clickhouse",
            "mssql",
            "sqlite",
            "oracle",
            "snowflake",
            "trino",
            "gocosmos",
            "spanner"
          ],
          "type": "string"
        },
        "dsn": {
          "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1\u0026...\u0026paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1\u0026...\u0026paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1\u0026...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname\u0026param1=value1\u0026...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param\u0026=value1\u0026...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2\u0026server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value\u0026...\u0026paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=\u003ccosmosdb-endpoint\u003e;AccountKey=\u003ccosmosdb-account-key\u003e[;TimeoutMs=\u003ctimeout-in-ms\u003e\\][;Version=\u003ccosmosdb-api-version\u003e\\][;DefaultDb/Db=\u003cdb-name\u003e\\][;AutoId=\u003ctrue/false\u003e\\][;InsecureSkipVerify=\u003ctrue/false\u003e\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `\u003csnowflake_user\u003e@\u003csnowflake_account\u003e/\u003cdb_name\u003e/\u003cschema_name\u003e?warehouse=\u003cwarehouse\u003e\u0026role=\u003crole\u003e\u0026authenticator=snowflake_jwt\u0026privateKey=\u003cbase64_url_encoded_private_key\u003e`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
          "type": "string"
        },
        "init_files": {
          "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
          "type": "string",
          "x-advanced": true
        },
        "init_statement": {
          "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
          "type": "string",
          "x-advanced": true
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of statements to execute in parallel.",
          "type": "number"
        },
        "queries": {
          "description": "A list of statements to run in addition to `query`. When specifying multiple statements, they are all executed within a transaction.",
          "properties": {
            "args_mapping": {
              "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`.",
              "type": "string"
            },
            "query": {
              "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
              "type": "string"
            }
          },
          "required": [
            "query"
          ],
          "type": "object"
        },
        "query": {
          "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\n| Driver | Placeholder Style |\n|---|---|\n| `clickhouse` | Dollar sign |\n| `mysql` | Question mark |\n| `postgres` | Dollar sign |\n| `mssql` | Question mark |\n| `sqlite` | Question mark |\n| `oracle` | Colon |\n| `snowflake` | Question mark |\n| `trino` | Question mark |\n| `gocosmos` | Colon |\n",
          "type": "string"
        },
        "unsafe_dynamic_query": {
          "default": false,
          "description": "Whether to enable xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions] in the query. Great care should be made to ensure your queries are defended against injection attacks.",
          "type": "boolean",
          "x-advanced": true
        }
      },
      "required": [
        "unsafe_dynamic_query",
        "max_in_flight",
        "batching",
        "driver",
        "dsn"
      ],
      "type": "object"
    },
    "sql_select": {
      "description": "\nIf the query fails to execute then the message will remain unchanged and the error can be caught using xref:configuration:error_handling.adoc[error handling methods].",
      "properties": {
        "args_mapping": {
          "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `where`.",
          "type": "string"
        },
        "columns": {
          "description": "A list of columns to query.",
          "type": "string"
        },
        "conn_max_idle": {
          "default": 2,
          "description": "An optional maximum number of connections in the idle connection pool. If conn_max_open is greater than 0 but less than the new conn_max_idle, then the new conn_max_idle will be reduced to match the conn_max_open limit. If `value \u003c= 0`, no idle connections are retained. The default max idle connections is currently 2. This may change in a future release.",
          "type": "number",
          "x-advanced": true
        },
        "conn_max_idle_time": {
          "description": "An optional maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If `value \u003c= 0`, connections are not closed due to a connections idle time.",
          "type": "string",
          "x-advanced": true
        },
        "conn_max_life_time": {
          "description": "An optional maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If `value \u003c= 0`, connections are not closed due to a connections age.",
          "type": "string",
          "x-advanced": true
        },
        "conn_max_open": {
          "description": "An optional maximum number of open connections to the database. If conn_max_idle is greater than 0 and the new conn_max_open is less than conn_max_idle, then conn_max_idle will be reduced to match the new conn_max_open limit. If `value \u003c= 0`, then there is no limit on the number of open connections. The default is 0 (unlimited).",
          "type": "number",
          "x-advanced": true
        },
        "driver": {
          "description": "A database \u003c\u003cdrivers, driver\u003e\u003e to use.",
          "enum": [
            "mysql",
            "postgres",
            "clickhouse",
            "mssql",
            "sqlite",
            "oracle",
            "snowflake",
            "trino",
            "gocosmos",
            "spanner"
          ],
          "type": "string"
        },
        "dsn": {
          "description": "A Data Source Name to identify the target database.\n\n==== Drivers\n\n:driver-support: mysql=certified, postgres=certified, clickhouse=community, mssql=community, sqlite=certified, oracle=certified, snowflake=community, trino=community, gocosmos=community, spanner=community\n\nThe following is a list of supported drivers, their placeholder style, and their respective DSN formats:\n\n|===\n| Driver | Data Source Name Format\n\n| `clickhouse` \n| https://github.com/ClickHouse/clickhouse-go#dsn[`clickhouse://[username[:password\\]@\\][netloc\\][:port\\]/dbname[?param1=value1\u0026...\u0026paramN=valueN\\]`^] \n\n| `mysql` \n| `[username[:password]@][protocol[(address)]]/dbname[?param1=value1\u0026...\u0026paramN=valueN]` \n\n| `postgres` \n| `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1\u0026...]` \n\n| `mssql` \n| `sqlserver://[user[:password]@][netloc][:port][?database=dbname\u0026param1=value1\u0026...]` \n\n| `sqlite` \n| `file:/path/to/filename.db[?param\u0026=value1\u0026...]` \n\n| `oracle` \n| `oracle://[username[:password]@][netloc][:port]/service_name?server=server2\u0026server=server3` \n\n| `snowflake` \n| `username[:password]@account_identifier/dbname/schemaname[?param1=value\u0026...\u0026paramN=valueN]` \n\n| `trino` \n| https://github.com/trinodb/trino-go-client#dsn-data-source-name[`http[s\\]://user[:pass\\]@host[:port\\][?parameters\\]`^] \n\n| `gocosmos` \n| https://pkg.go.dev/github.com/microsoft/gocosmos#readme-example-usage[`AccountEndpoint=\u003ccosmosdb-endpoint\u003e;AccountKey=\u003ccosmosdb-account-key\u003e[;TimeoutMs=\u003ctimeout-in-ms\u003e\\][;Version=\u003ccosmosdb-api-version\u003e\\][;DefaultDb/Db=\u003cdb-name\u003e\\][;AutoId=\u003ctrue/false\u003e\\][;InsecureSkipVerify=\u003ctrue/false\u003e\\]`^] \n\n| `spanner` \n| projects/[PROJECT]/instances/[INSTANCE]/databases/[DATABASE] \n|===\n\nPlease note that the `postgres` driver enforces SSL by default, you can override this with the parameter `sslmode=disable` if required.\n\nThe `snowflake` driver supports multiple DSN formats. Please consult https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_String[the docs^] for more details. For https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[key pair authentication^], the DSN has the following format: `\u003csnowflake_user\u003e@\u003csnowflake_account\u003e/\u003cdb_name\u003e/\u003cschema_name\u003e?warehouse=\u003cwarehouse\u003e\u0026role=\u003crole\u003e\u0026authenticator=snowflake_jwt\u0026privateKey=\u003cbase64_url_encoded_private_key\u003e`, where the value for the `privateKey` parameter can be constructed from an unencrypted RSA private key file `rsa_key.p8` using `openssl enc -d -base64 -in rsa_key.p8 | basenc --base64url -w0` (you can use `gbasenc` insted of `basenc` on OSX if you install `coreutils` via Homebrew). If you have a password-encrypted private key, you can decrypt it using `openssl pkcs8 -in rsa_key_encrypted.p8 -out rsa_key.p8`. Also, make sure fields such as the username are URL-encoded.\n\nThe https://pkg.go.dev/github.com/microsoft/gocosmos[`gocosmos`^] driver is still experimental, but it has support for https://learn.microsoft.com/en-us/azure/cosmos-db/hierarchical-partition-keys[hierarchical partition keys^] as well as https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-query-container#cross-partition-query[cross-partition queries^]. Please refer to the https://github.com/microsoft/gocosmos/blob/main/SQL.md[SQL notes^] for details.",
          "type": "string"
        },
        "init_files": {
          "description": "\nAn optional list of file paths containing SQL statements to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Glob patterns are supported, including super globs (double star).\n\nCare should be taken to ensure that the statements are idempotent, and therefore would not cause issues when run multiple times after service restarts. If both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf a statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
          "type": "string",
          "x-advanced": true
        },
        "init_statement": {
          "description": "\nAn optional SQL statement to execute immediately upon the first connection to the target database. This is a useful way to initialise tables before processing data. Care should be taken to ensure that the statement is idempotent, and therefore would not cause issues when run multiple times after service restarts.\n\nIf both `init_statement` and `init_files` are specified the `init_statement` is executed _after_ the `init_files`.\n\nIf the statement fails for any reason a warning log will be emitted but the operation of this component will not be stopped.\n",
          "type": "string",
          "x-advanced": true
        },
        "prefix": {
          "description": "An optional prefix to prepend to the query (before SELECT).",
          "type": "string",
          "x-advanced": true
        },
        "suffix": {
          "description": "An optional suffix to append to the select query.",
          "type": "string",
          "x-advanced": true
        },
        "table": {
          "description": "The table to query.",
          "type": "string"
        },
        "where": {
          "description": "An optional where clause to add. Placeholder arguments are populated with the `args_mapping` field. Placeholders should always be question marks, and will automatically be converted to dollar syntax when the postgres or clickhouse drivers are used.",
          "type": "string"
        }
      },
      "required": [
        "driver",
        "dsn",
        "table",
        "columns"
      ],
      "type": "object"
    },
    "stdin": {
      "description": "Consumes data piped to stdin, chopping it into individual messages according to the specified scanner.",
      "properties": {
        "auto_replay_nacks": {
          "default": true,
          "description": "Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.",
          "type": "boolean"
        },
        "codec": {
          "description": "The way in which the bytes of a data source should be converted into discrete messages, codecs are useful for specifying how large files or continuous streams of data might be processed in small chunks rather than loading it all in memory. It's possible to consume lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter. Codecs can be chained with `/`, for example a gzip compressed CSV file can be consumed with the codec `gzip/csv`.",
          "type": "string"
        },
        "max_buffer": {
          "default": 1000000,
          "type": "number"
        },
        "scanner": {
          "default": {
            "lines": {}
          },
          "description": "The xref:components:scanners/about.adoc[scanner] by which the stream of bytes consumed will be broken out into individual messages. Scanners are useful for processing large sources of data without holding the entirety of it within memory. For example, the `csv` scanner allows you to process individual CSV rows without loading the entire CSV file in memory at once.",
          "type": "string"
        }
      },
      "required": [
        "max_buffer",
        "auto_replay_nacks"
      ],
      "type": "object"
    },
    "stdout": {
      "description": "Prints messages to stdout as a continuous stream of data.",
      "properties": {
        "codec": {
          "default": "lines",
          "description": "The way in which the bytes of messages should be written out into the output data stream. It's possible to write lines using a custom delimiter with the `delim:x` codec, where x is the character sequence custom delimiter.",
          "type": "string"
        }
      },
      "required": [
        "codec"
      ],
      "type": "object"
    },
    "stream_processor": {
      "description": "The stream_processor is a specialized Benthos processor designed to collect timeseries data from multiple UNS sources,\nmaintain state for variable mappings, and generate transformed messages using JavaScript expressions. It operates exclusively with UNS input/output.\n\nThe processor implements dependency-based evaluation:\n- Static mappings (no variable dependencies) are evaluated on every incoming message\n- Dynamic mappings are only evaluated when their dependent variables are received\n\nConfiguration structure:\n- mode: Processing mode (currently only \"timeseries\" is supported)\n- model: Model name and version for data contract generation\n- output_topic: Base topic for output messages\n- sources: Map of variable aliases to UNS topic paths\n- mapping: JavaScript expressions for field transformations\n\nOutput topics are constructed as: \u003coutput_topic\u003e.\u003cdata_contract\u003e.\u003cvirtual_path\u003e\nWhere data_contract is \"_\u003cmodel_name\u003e_\u003cmodel_version\u003e\" and virtual_path is the mapping field path.",
      "properties": {
        "mapping": {
          "description": "JavaScript expressions for field transformations",
          "type": "object"
        },
        "mode": {
          "default": "timeseries",
          "description": "Processing mode",
          "type": "string"
        },
        "model": {
          "description": "Model configuration for data contract",
          "properties": {
            "name": {
              "description": "Model name for data contract generation",
              "type": "string"
            },
            "version": {
              "description": "Model version for data contract generation",
              "type": "string"
            }
          },
          "required": [
            "name",
            "version"
          ],
          "type": "object"
        },
        "output_topic": {
          "description": "Base topic for output messages",
          "type": "string"
        },
        "sources": {
          "description": "Map of variable aliases to UNS topic paths",
          "type": "string"
        }
      },
      "required": [
        "mode",
        "model",
        "output_topic",
        "sources"
      ],
      "type": "object"
    },
    "subprocess": {
      "description": "\nMessages are written according to a specified codec. The process is expected to terminate gracefully when stdin is closed.\n\nIf the subprocess exits unexpectedly then Redpanda Connect will log anything printed to stderr and will log the exit code, and will attempt to execute the command again until success.\n\nThe execution environment of the subprocess is the same as the Redpanda Connect instance, including environment variables and the current working directory.",
      "properties": {
        "args": {
          "default": [],
          "description": "A list of arguments to provide the command.",
          "type": "string"
        },
        "codec": {
          "default": "lines",
          "description": "The way in which messages should be written to the subprocess.",
          "enum": [
            "lines"
          ],
          "type": "string"
        },
        "name": {
          "description": "The command to execute as a subprocess.",
          "type": "string"
        }
      },
      "required": [
        "codec",
        "name",
        "args"
      ],
      "type": "object"
    },
    "switch": {
      "description": "Messages that do not pass the check of a single output case are effectively dropped. In order to prevent this outcome set the field \u003c\u003cstrict_mode, `strict_mode`\u003e\u003e to `true`, in which case messages that do not pass at least one case are considered failed and will be nacked and/or reprocessed depending on your input.",
      "properties": {
        "cases": {
          "description": "A list of switch cases, outlining outputs that can be routed to.",
          "properties": {
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should be routed to the case output. If left empty the case always passes.",
              "type": "string"
            },
            "continue": {
              "default": false,
              "description": "Indicates whether, if this case passes for a message, the next case should also be tested.",
              "type": "boolean",
              "x-advanced": true
            },
            "output": {
              "description": "An xref:components:outputs/about.adoc[output] for messages that pass the check to be routed to.",
              "type": "string"
            }
          },
          "required": [
            "check",
            "output",
            "continue"
          ],
          "type": "object"
        },
        "retry_until_success": {
          "default": false,
          "description": "\nIf a selected output fails to send a message this field determines whether it is reattempted indefinitely. If set to false the error is instead propagated back to the input level.\n\nIf a message can be routed to \u003e1 outputs it is usually best to set this to true in order to avoid duplicate messages being routed to an output.",
          "type": "boolean"
        },
        "strict_mode": {
          "default": false,
          "description": "This field determines whether an error should be reported if no condition is met. If set to true, an error is propagated back to the input level. The default behavior is false, which will drop the message.",
          "type": "boolean",
          "x-advanced": true
        }
      },
      "required": [
        "retry_until_success",
        "strict_mode",
        "cases"
      ],
      "type": "object"
    },
    "sync_response": {
      "description": "\nFor most inputs this mechanism is ignored entirely, in which case the sync response is dropped without penalty. It is therefore safe to use this output even when combining input types that might not have support for sync responses. An example of an input able to utilize this is the `http_server`.\n\nIt is safe to combine this output with others using broker types. For example, with the `http_server` input we could send the payload to a Kafka topic and also send a modified payload back with:\n\n```yaml\ninput:\n  http_server:\n    path: /post\noutput:\n  broker:\n    pattern: fan_out\n    outputs:\n      - kafka:\n          addresses: [ TODO:9092 ]\n          topic: foo_topic\n      - sync_response: {}\n        processors:\n          - mapping: 'root = content().uppercase()'\n```\n\nUsing the above example and posting the message 'hello world' to the endpoint `/post` Redpanda Connect would send it unchanged to the topic `foo_topic` and also respond with 'HELLO WORLD'.\n\nFor more information please read xref:guides:sync_responses.adoc[synchronous responses].",
      "type": "object"
    },
    "tag_processor": {
      "description": "The tagProcessor sets up a canonical metadata structure for constructing standardized topic and payload schemas.\nIt applies defaults, conditional transformations, and optional advanced processing using a Node-RED style JavaScript environment.\n\nRequired metadata fields:\n- location_path: Hierarchical location path in dot notation (e.g., \"enterprise.site.area.line.workcell.plc123\")\n- data_contract: Data schema identifier (e.g., \"_historian\", \"_analytics\")\n- tag_name: Name of the tag/variable (e.g., \"temperature\")\n\nOptional metadata fields:\n- virtual_path: Logical, non-physical grouping path in dot notation (e.g., \"axis.x.position\")\n\nThe final topic will be constructed as:\numh.v1.\u003clocation_path\u003e.\u003cdata_contract\u003e.\u003cvirtual_path\u003e.\u003ctag_name\u003e\n\nEmpty or undefined fields will be omitted from the topic.",
      "properties": {
        "advancedProcessing": {
          "default": "",
          "description": "Optional JavaScript code for advanced message processing",
          "type": "string"
        },
        "conditions": {
          "description": "List of conditions to evaluate",
          "properties": {
            "if": {
              "description": "JavaScript condition expression",
              "type": "string"
            },
            "then": {
              "description": "JavaScript code to execute if condition is true",
              "type": "string"
            }
          },
          "required": [
            "if",
            "then"
          ],
          "type": "object"
        },
        "defaults": {
          "default": "",
          "description": "JavaScript code to set initial metadata values",
          "type": "string"
        }
      },
      "required": [
        "defaults"
      ],
      "type": "object"
    },
    "timeplus": {
      "description": "\nThis output can send message to Timeplus Enterprise Cloud, Timeplus Enterprise (self-hosted) or directly to timeplusd.\n\nThis output accepts structured message only. It also expects all message contains the same keys and matches the schema of the destination stream. If the upstream source or pipeline returns\nunstructured message such as string, please refer to the \"Unstructured message\" example.",
      "properties": {
        "apikey": {
          "description": "The API key. Required if you are sending message to Timeplus Enterprise Cloud",
          "type": "string"
        },
        "batching": {
          "description": "\nAllows you to configure a xref:configuration:batching.adoc[batching policy].",
          "properties": {
            "byte_size": {
              "default": 0,
              "description": "An amount of bytes at which the batch should be flushed. If `0` disables size based batching.",
              "type": "number"
            },
            "check": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.",
              "type": "string"
            },
            "count": {
              "default": 0,
              "description": "A number of messages at which the batch should be flushed. If `0` disables count based batching.",
              "type": "number"
            },
            "period": {
              "default": "",
              "description": "A period in which an incomplete batch should be flushed regardless of its size.",
              "type": "string"
            },
            "processors": {
              "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "count",
            "byte_size",
            "period",
            "check"
          ],
          "type": "object"
        },
        "max_in_flight": {
          "default": 64,
          "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput.",
          "type": "number"
        },
        "password": {
          "description": "The password. Required if you are sending message to Timeplus Enterprise (self-hosted) or timeplusd",
          "type": "string"
        },
        "stream": {
          "description": "The name of the stream. Make sure the schema of the stream matches the input",
          "type": "string"
        },
        "target": {
          "default": "timeplus",
          "description": "The destination type, either Timeplus Enterprise or timeplusd",
          "enum": [
            "timeplus",
            "timeplusd"
          ],
          "type": "string"
        },
        "url": {
          "default": "https://us-west-2.timeplus.cloud",
          "description": "The url should always include schema and host.",
          "type": "string"
        },
        "username": {
          "description": "The username. Required if you are sending message to Timeplus Enterprise (self-hosted) or timeplusd",
          "type": "string"
        },
        "workspace": {
          "description": "ID of the workspace. Required if target is `timeplus`.",
          "type": "string"
        }
      },
      "required": [
        "target",
        "url",
        "max_in_flight",
        "stream",
        "batching"
      ],
      "type": "object"
    },
    "topic_browser": {
      "description": "The topic browser processor processes messages into UNS bundles for the topic browser.\n\nThe processor will read the message headers and body to extract the UNS information and event table entries.\n\nThe processor will then return a message with the UNS bundle as the body, encoded as a protobuf.\n\nThe processor requires that the following metadata fields are set:\n\n- topic: The topic of the message.\n",
      "properties": {
        "emit_interval": {
          "default": "1s",
          "description": "Maximum time to buffer messages before emission",
          "type": "string",
          "x-advanced": true
        },
        "lru_size": {
          "default": 50000,
          "description": "The size of the LRU cache used to deduplicate topic names and store topic information.",
          "type": "number",
          "x-advanced": true
        },
        "max_buffer_size": {
          "default": 10000,
          "description": "Maximum number of messages to buffer (safety limit)",
          "type": "number",
          "x-advanced": true
        },
        "max_events_per_topic_per_interval": {
          "default": 1,
          "description": "Maximum events per topic per emit interval",
          "type": "number",
          "x-advanced": true
        }
      },
      "required": [
        "max_events_per_topic_per_interval",
        "max_buffer_size",
        "lru_size",
        "emit_interval"
      ],
      "type": "object"
    },
    "try": {
      "description": "\nThis processor behaves similarly to the xref:components:processors/for_each.adoc[`for_each`] processor, where a list of child processors are applied to individual messages of a batch. However, if a message has failed any prior processor (before or during the try block) then that message will skip all following processors.\n\nFor example, with the following config:\n\n```yaml\npipeline:\n  processors:\n    - resource: foo\n    - try:\n      - resource: bar\n      - resource: baz\n      - resource: buz\n```\n\nIf the processor `bar` fails for a particular message, that message will skip the processors `baz` and `buz`. Similarly, if `bar` succeeds but `baz` does not then `buz` will be skipped. If the processor `foo` fails for a message then none of `bar`, `baz` or `buz` are executed on that message.\n\nThis processor is useful for when child processors depend on the successful output of previous processors. This processor can be followed with a xref:components:processors/catch.adoc[catch] processor for defining child processors to be applied only to failed messages.\n\nMore information about error handing can be found in xref:configuration:error_handling.adoc[].\n\n== Nest within a catch block\n\nIn some cases it might be useful to nest a try block within a catch block, since the xref:components:processors/catch.adoc[`catch` processor] only clears errors _after_ executing its child processors this means a nested try processor will not execute unless the errors are explicitly cleared beforehand.\n\nThis can be done by inserting an empty catch block before the try block like as follows:\n\n```yaml\npipeline:\n  processors:\n    - resource: foo\n    - catch:\n      - log:\n          level: ERROR\n          message: \"Foo failed due to: ${! error() }\"\n      - catch: [] # Clear prior error\n      - try:\n        - resource: bar\n        - resource: baz\n```",
      "type": "object"
    },
    "twitter_search": {
      "description": "Continuously polls the https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent[Twitter recent search V2 API^] for tweets that match a given search query.\n\nEach tweet received is emitted as a JSON object message, with a field `id` and `text` by default. Extra fields https://developer.twitter.com/en/docs/twitter-api/fields[can be obtained from the search API^] when listed with the `tweet_fields` field.\n\nIn order to paginate requests that are made the ID of the latest received tweet is stored in a xref:components:caches/about.adoc[cache resource], which is then used by subsequent requests to ensure only tweets after it are consumed. It is recommended that the cache you use is persistent so that Redpanda Connect can resume searches at the correct place on a restart.\n\nAuthentication is done using OAuth 2.0 credentials which can be generated within the https://developer.twitter.com[Twitter developer portal^].\n",
      "properties": {
        "api_key": {
          "description": "An API key for OAuth 2.0 authentication. It is recommended that you populate this field using xref:configuration:interpolation.adoc[environment variables].",
          "type": "string"
        },
        "api_secret": {
          "description": "An API secret for OAuth 2.0 authentication. It is recommended that you populate this field using xref:configuration:interpolation.adoc[environment variables].",
          "type": "string"
        },
        "backfill_period": {
          "default": "5m",
          "description": "A duration string indicating the maximum age of tweets to acquire when starting a search.",
          "type": "string"
        },
        "cache": {
          "description": "A cache resource to use for request pagination.",
          "type": "string"
        },
        "cache_key": {
          "default": "last_tweet_id",
          "description": "The key identifier used when storing the ID of the last tweet received.",
          "type": "string",
          "x-advanced": true
        },
        "poll_period": {
          "default": "1m",
          "description": "The length of time (as a duration string) to wait between each search request. This field can be set empty, in which case requests are made at the limit set by the rate limit. This field also supports cron expressions.",
          "type": "string"
        },
        "query": {
          "description": "A search expression to use.",
          "type": "string"
        },
        "rate_limit": {
          "default": "",
          "description": "An optional rate limit resource to restrict API requests with.",
          "type": "string",
          "x-advanced": true
        },
        "tweet_fields": {
          "default": [],
          "description": "An optional list of additional fields to obtain for each tweet, by default only the fields `id` and `text` are returned. For more info refer to the https://developer.twitter.com/en/docs/twitter-api/fields[twitter API docs^].",
          "type": "string"
        }
      },
      "required": [
        "query",
        "backfill_period",
        "cache_key",
        "api_secret",
        "tweet_fields",
        "poll_period",
        "cache",
        "rate_limit",
        "api_key"
      ],
      "type": "object"
    },
    "unarchive": {
      "description": "\nWhen a message is unarchived the new messages replace the original message in the batch. Messages that are selected but fail to unarchive (invalid format) will remain unchanged in the message batch but will be flagged as having failed, allowing you to xref:configuration:error_handling.adoc[error handle them].\n\n== Metadata\n\nThe metadata found on the messages handled by this processor will be copied into the resulting messages. For the unarchive formats that contain file information (tar, zip), a metadata field is also added to each message called `archive_filename` with the extracted filename.\n",
      "properties": {
        "format": {
          "description": "The unarchiving format to apply.",
          "type": "string"
        }
      },
      "required": [
        "format"
      ],
      "type": "object"
    },
    "uns": {
      "description": "\nInside UMH Core you usually configure **nothing**:\n\n    output:\n      uns: {}\n\nThe plugin connects to Redpanda on localhost:9092, batches 100 records\nor 100 ms, and writes them to *umh.messages*.  The Kafka key is taken\nfrom '${! meta(\"umh_topic\") }' (set automatically by the tag_processor,\nBloblang, or Node-RED JS).  Outside UMH Core you may override the broker\nor add a custom 'bridged_by' header for traceability.\n",
      "properties": {
        "bridged_by": {
          "default": "umh_core",
          "description": "\nTraceability header.  Defaults to 'umh-core' but is automatically\noverwritten by UMH Core when the container runs as a protocol-converter:\n'protocol-converter-\u003cINSTANCE\u003e-\u003cNAME\u003e'.\n",
          "type": "string"
        },
        "broker_address": {
          "default": "localhost:9092",
          "description": "\nKafka / Redpanda bootstrap list.  Comma-separated if you have multiple\nbrokers, e.g. \"broker1:9092,broker2:9092\".\n\nDefault 'localhost:9092' is correct for every UMH Core installation.\n",
          "type": "string"
        },
        "schema_registry_url": {
          "description": "\nSchema registry URL for data contract validation.  If not provided, it\nwill be automatically derived from the first broker in the broker_address\nlist by changing the port to 8081.\n\nExample: If broker_address is \"localhost:9092\", the schema registry URL\nwill be \"http://localhost:8081\".\n",
          "type": "string"
        },
        "umh_topic": {
          "default": "${! meta(\"umh_topic\") }",
          "description": "\nThe **Kafka key** for every record.  Must follow the UMH naming pattern\n'umh.v1.\u003centerprise\u003e.\u003csite\u003e.\u003carea\u003e.\u003cdata_contract\u003e[.\u003cvirtual_path\u003e].\u003ctag\u003e'.\n\nLeave it at the default '${! meta(\"umh_topic\") }' if you use the tag_processor\nor set it in Bloblang / Node-RED JS.\n\nAny character not matching [a-zA-Z0-9._-] is replaced by '_'.\n",
          "type": "string"
        }
      },
      "required": [
        "umh_topic",
        "broker_address",
        "bridged_by"
      ],
      "type": "object"
    },
    "wasm": {
      "description": "\nThis processor uses https://github.com/tetratelabs/wazero[Wazero^] to execute a WASM module (with support for WASI), calling a specific function for each message being processed. From within the WASM module it is possible to query and mutate the message being processed via a suite of functions exported to the module.\n\nThis ecosystem is delicate as WASM doesn't have a single clearly defined way to pass strings back and forth between the host and the module. In order to remedy this we're gradually working on introducing libraries and examples for multiple languages which can be found in https://github.com/redpanda-data/benthos/tree/main/public/wasm/README.md[the codebase^].\n\nThese examples, as well as the processor itself, is a work in progress.\n\n== Parallelism\n\nIt's not currently possible to execute a single WASM runtime across parallel threads with this processor. Therefore, in order to support parallel processing this processor implements pooling of module runtimes. Ideally your WASM module shouldn't depend on any global state, but if it does then you need to ensure the processor xref:configuration:processing_pipelines.adoc[is only run on a single thread].\n",
      "properties": {
        "function": {
          "default": "process",
          "description": "The name of the function exported by the target WASM module to run for each message.",
          "type": "string"
        },
        "module_path": {
          "description": "The path of the target WASM module to execute.",
          "type": "string"
        }
      },
      "required": [
        "module_path",
        "function"
      ],
      "type": "object"
    },
    "websocket": {
      "description": "Sends messages to an HTTP server via a websocket connection.",
      "properties": {
        "basic_auth": {
          "description": "Allows you to specify basic authentication.",
          "properties": {
            "enabled": {
              "default": false,
              "description": "Whether to use basic authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "password": {
              "default": "",
              "description": "A password to authenticate with.",
              "type": "string",
              "x-advanced": true
            },
            "username": {
              "default": "",
              "description": "A username to authenticate as.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "username",
            "password"
          ],
          "type": "object",
          "x-advanced": true
        },
        "jwt": {
          "description": "BETA: Allows you to specify JWT authentication.",
          "properties": {
            "claims": {
              "default": {},
              "description": "A value used to identify the claims that issued the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use JWT authentication in requests.",
              "type": "boolean",
              "x-advanced": true
            },
            "headers": {
              "default": {},
              "description": "Add optional key/value headers to the JWT.",
              "type": "string",
              "x-advanced": true
            },
            "private_key_file": {
              "default": "",
              "description": "A file with the PEM encoded via PKCS1 or PKCS8 as private key.",
              "type": "string",
              "x-advanced": true
            },
            "signing_method": {
              "default": "",
              "description": "A method used to sign the token such as RS256, RS384, RS512 or EdDSA.",
              "type": "string",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "private_key_file",
            "signing_method",
            "claims",
            "headers"
          ],
          "type": "object",
          "x-advanced": true
        },
        "oauth": {
          "description": "Allows you to specify open authentication via OAuth version 1.",
          "properties": {
            "access_token": {
              "default": "",
              "description": "A value used to gain access to the protected resources on behalf of the user.",
              "type": "string",
              "x-advanced": true
            },
            "access_token_secret": {
              "default": "",
              "description": "A secret provided in order to establish ownership of a given access token.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_key": {
              "default": "",
              "description": "A value used to identify the client to the service provider.",
              "type": "string",
              "x-advanced": true
            },
            "consumer_secret": {
              "default": "",
              "description": "A secret used to establish ownership of the consumer key.",
              "type": "string",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether to use OAuth version 1 in requests.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "consumer_key",
            "consumer_secret",
            "access_token",
            "access_token_secret"
          ],
          "type": "object",
          "x-advanced": true
        },
        "proxy_url": {
          "description": "An optional HTTP proxy URL.",
          "type": "string",
          "x-advanced": true
        },
        "tls": {
          "description": "Custom TLS settings can be used to override system defaults.",
          "properties": {
            "client_certs": {
              "default": [],
              "description": "A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.",
              "properties": {
                "cert": {
                  "default": "",
                  "description": "A plain text certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "cert_file": {
                  "default": "",
                  "description": "The path of a certificate to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key": {
                  "default": "",
                  "description": "A plain text certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "key_file": {
                  "default": "",
                  "description": "The path of a certificate key to use.",
                  "type": "string",
                  "x-advanced": true
                },
                "password": {
                  "default": "",
                  "description": "A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.\n\nBecause the obsolete pbeWithMD5AndDES-CBC algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.\n",
                  "type": "string",
                  "x-advanced": true
                }
              },
              "required": [
                "cert",
                "key",
                "cert_file",
                "key_file",
                "password"
              ],
              "type": "object",
              "x-advanced": true
            },
            "enable_renegotiation": {
              "default": false,
              "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.",
              "type": "boolean",
              "x-advanced": true
            },
            "enabled": {
              "default": false,
              "description": "Whether custom TLS settings are enabled.",
              "type": "boolean",
              "x-advanced": true
            },
            "root_cas": {
              "default": "",
              "description": "An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "root_cas_file": {
              "default": "",
              "description": "An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.",
              "type": "string",
              "x-advanced": true
            },
            "skip_cert_verify": {
              "default": false,
              "description": "Whether to skip server side certificate verification.",
              "type": "boolean",
              "x-advanced": true
            }
          },
          "required": [
            "enabled",
            "skip_cert_verify",
            "enable_renegotiation",
            "root_cas",
            "root_cas_file",
            "client_certs"
          ],
          "type": "object",
          "x-advanced": true
        },
        "url": {
          "description": "The URL to connect to.",
          "type": "string"
        }
      },
      "required": [
        "jwt",
        "url",
        "tls"
      ],
      "type": "object"
    },
    "while": {
      "description": "\nThe field `at_least_once`, if true, ensures that the child processors are always executed at least one time (like a do .. while loop.)\n\nThe field `max_loops`, if greater than zero, caps the number of loops for a message batch to this value.\n\nIf following a loop execution the number of messages in a batch is reduced to zero the loop is exited regardless of the condition result. If following a loop execution there are more than 1 message batches the query is checked against the first batch only.\n\nThe conditions of this processor are applied across entire message batches. You can find out more about batching xref:configuration:batching.adoc[in this doc].",
      "properties": {
        "at_least_once": {
          "default": false,
          "description": "Whether to always run the child processors at least one time.",
          "type": "boolean"
        },
        "check": {
          "default": "",
          "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether the while loop should execute again.",
          "type": "string"
        },
        "max_loops": {
          "default": 0,
          "description": "An optional maximum number of loops to execute. Helps protect against accidentally creating infinite loops.",
          "type": "number",
          "x-advanced": true
        },
        "processors": {
          "description": "A list of child processors to execute on each loop.",
          "type": "string"
        }
      },
      "required": [
        "at_least_once",
        "max_loops",
        "check",
        "processors"
      ],
      "type": "object"
    },
    "workflow": {
      "description": "\n== Why use a workflow\n\n=== Performance\n\nMost of the time the best way to compose processors is also the simplest, just configure them in series. This is because processors are often CPU bound, low-latency, and you can gain vertical scaling by increasing the number of processor pipeline threads, allowing Redpanda Connect to process xref:configuration:processing_pipelines.adoc[multiple messages in parallel].\n\nHowever, some processors such as xref:components:processors/http.adoc[`http`], xref:components:processors/aws_lambda.adoc[`aws_lambda`] or xref:components:processors/cache.adoc[`cache`] interact with external services and therefore spend most of their time waiting for a response. These processors tend to be high-latency and low CPU activity, which causes messages to process slowly.\n\nWhen a processing pipeline contains multiple network processors that aren't dependent on each other we can benefit from performing these processors in parallel for each individual message, reducing the overall message processing latency.\n\n=== Simplifying processor topology\n\nA workflow is often expressed as a https://en.wikipedia.org/wiki/Directed_acyclic_graph[DAG^] of processing stages, where each stage can result in N possible next stages, until finally the flow ends at an exit node.\n\nFor example, if we had processing stages A, B, C and D, where stage A could result in either stage B or C being next, always followed by D, it might look something like this:\n\n```text\n     /--\u003e B --\\\nA --|          |--\u003e D\n     \\--\u003e C --/\n```\n\nThis flow would be easy to express in a standard Redpanda Connect config, we could simply use a xref:components:processors/switch.adoc[`switch` processor] to route to either B or C depending on a condition on the result of A. However, this method of flow control quickly becomes unfeasible as the DAG gets more complicated, imagine expressing this flow using switch processors:\n\n```text\n      /--\u003e B -------------|--\u003e D\n     /                   /\nA --|          /--\u003e E --|\n     \\--\u003e C --|          \\\n               \\----------|--\u003e F\n```\n\nAnd imagine doing so knowing that the diagram is subject to change over time. Yikes! Instead, with a workflow we can either trust it to automatically resolve the DAG or express it manually as simply as `order: [ [ A ], [ B, C ], [ E ], [ D, F ] ]`, and the conditional logic for determining if a stage is executed is defined as part of the branch itself.",
      "properties": {
        "branch_resources": {
          "default": [],
          "description": "An optional list of xref:components:processors/branch.adoc[`branch` processor] names that are configured as \u003c\u003cresources\u003e\u003e. These resources will be included in the workflow with any branches configured inline within the \u003c\u003cbranches, `branches`\u003e\u003e field. The order and parallelism in which branches are executed is automatically resolved based on the mappings of each branch. When using resources with an explicit order it is not necessary to list resources in this field.",
          "type": "string",
          "x-advanced": true
        },
        "branches": {
          "default": {},
          "description": "An object of named xref:components:processors/branch.adoc[`branch` processors] that make up the workflow. The order and parallelism in which branches are executed can either be made explicit with the field `order`, or if omitted an attempt is made to automatically resolve an ordering based on the mappings of each branch.",
          "properties": {
            "processors": {
              "description": "A list of processors to apply to mapped requests. When processing message batches the resulting batch must match the size and ordering of the input batch, therefore filtering, grouping should not be performed within these processors.",
              "type": "string"
            },
            "request_map": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how to create a request payload suitable for the child processors of this branch. If left empty then the branch will begin with an exact copy of the origin message (including metadata).",
              "type": "string"
            },
            "result_map": {
              "default": "",
              "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] that describes how the resulting messages from branched processing should be mapped back into the original payload. If left empty the origin message will remain unchanged (including metadata).",
              "type": "string"
            }
          },
          "required": [
            "request_map",
            "processors",
            "result_map"
          ],
          "type": "object"
        },
        "meta_path": {
          "default": "meta.workflow",
          "description": "A xref:configuration:field_paths.adoc[dot path] indicating where to store and reference \u003c\u003cstructured-metadata, structured metadata\u003e\u003e about the workflow execution.",
          "type": "string"
        },
        "order": {
          "default": [],
          "description": "An explicit declaration of branch ordered tiers, which describes the order in which parallel tiers of branches should be executed. Branches should be identified by the name as they are configured in the field `branches`. It's also possible to specify branch processors configured \u003c\u003cresources, as a resource\u003e\u003e.",
          "type": "string"
        }
      },
      "required": [
        "meta_path",
        "order",
        "branch_resources",
        "branches"
      ],
      "type": "object"
    },
    "xml": {
      "description": "\n== Operators\n\n=== `to_json`\n\nConverts an XML document into a JSON structure, where elements appear as keys of an object according to the following rules:\n\n- If an element contains attributes they are parsed by prefixing a hyphen, `-`, to the attribute label.\n- If the element is a simple element and has attributes, the element value is given the key `#text`.\n- XML comments, directives, and process instructions are ignored.\n- When elements are repeated the resulting JSON value is an array.\n\nFor example, given the following XML:\n\n```xml\n\u003croot\u003e\n  \u003ctitle\u003eThis is a title\u003c/title\u003e\n  \u003cdescription tone=\"boring\"\u003eThis is a description\u003c/description\u003e\n  \u003celements id=\"1\"\u003efoo1\u003c/elements\u003e\n  \u003celements id=\"2\"\u003efoo2\u003c/elements\u003e\n  \u003celements\u003efoo3\u003c/elements\u003e\n\u003c/root\u003e\n```\n\nThe resulting JSON structure would look like this:\n\n```json\n{\n  \"root\":{\n    \"title\":\"This is a title\",\n    \"description\":{\n      \"#text\":\"This is a description\",\n      \"-tone\":\"boring\"\n    },\n    \"elements\":[\n      {\"#text\":\"foo1\",\"-id\":\"1\"},\n      {\"#text\":\"foo2\",\"-id\":\"2\"},\n      \"foo3\"\n    ]\n  }\n}\n```\n\nWith cast set to true, the resulting JSON structure would look like this:\n\n```json\n{\n  \"root\":{\n    \"title\":\"This is a title\",\n    \"description\":{\n      \"#text\":\"This is a description\",\n      \"-tone\":\"boring\"\n    },\n    \"elements\":[\n      {\"#text\":\"foo1\",\"-id\":1},\n      {\"#text\":\"foo2\",\"-id\":2},\n      \"foo3\"\n    ]\n  }\n}\n```",
      "properties": {
        "cast": {
          "default": false,
          "description": "Whether to try to cast values that are numbers and booleans to the right type. Default: all values are strings.",
          "type": "boolean"
        },
        "operator": {
          "default": "",
          "description": "An XML \u003c\u003coperators, operation\u003e\u003e to apply to messages.",
          "enum": [
            "to_json"
          ],
          "type": "string"
        }
      },
      "required": [
        "operator",
        "cast"
      ],
      "type": "object"
    }
  },
  "description": "JSON Schema for Benthos UMH protocol plugins",
  "title": "Benthos UMH Configuration Schema"
}