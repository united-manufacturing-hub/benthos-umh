// Copyright 2025 UMH Systems GmbH
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Vector Generation Tool for Sparkplug B Plugin
// Single Go tool to generate static test vectors (no Python/Docker complexity)
// Generates test_vectors.go with Base64-encoded Sparkplug B payloads

package main

import (
	"encoding/base64"
	"fmt"
	"log"
	"time"

	sparkplugb "github.com/united-manufacturing-hub/benthos-umh/sparkplug_plugin/sparkplugb"
	"google.golang.org/protobuf/proto"
)

// TestVector represents a test payload with metadata
type TestVector struct {
	Name        string
	Base64Data  string
	Description string
	MessageType string
	MetricCount int
}

func main() {
	fmt.Println("// Generated by gen-vectors - DO NOT EDIT")
	fmt.Println("// Static test vectors for Sparkplug B plugin")
	fmt.Println("package sparkplug_plugin")
	fmt.Println()
	fmt.Println("// TestVector represents a test payload with metadata")
	fmt.Println("type TestVector struct {")
	fmt.Println("	Name        string")
	fmt.Println("	Base64Data  string")
	fmt.Println("	Description string")
	fmt.Println("	MessageType string")
	fmt.Println("	MetricCount int")
	fmt.Println("}")
	fmt.Println()
	fmt.Println("// TestVectors contains all static test vectors")
	fmt.Println("var TestVectors = []TestVector{")

	// Generate happy path vectors
	generateHappyPathVectors()

	// Generate edge case vectors
	generateEdgeCaseVectors()

	// Generate performance test vectors
	generatePerformanceVectors()

	fmt.Println("}")
	fmt.Println()
	fmt.Println("// GetTestVector retrieves a test vector by name")
	fmt.Println("func GetTestVector(name string) *TestVector {")
	fmt.Println("	for _, vector := range TestVectors {")
	fmt.Println("		if vector.Name == name {")
	fmt.Println("			return &vector")
	fmt.Println("		}")
	fmt.Println("	}")
	fmt.Println("	return nil")
	fmt.Println("}")
}

func generateHappyPathVectors() {
	fmt.Println("	// Happy path vectors - basic protocol flow")

	// NBIRTH with corrected format from expert.md
	nbirth := createNBirth(0, []Metric{
		{Name: "bdSeq", Alias: 1, DataType: uint32(8), Value: uint64(88)},
		{Name: "Node Control/Rebirth", Alias: 2, DataType: uint32(11), Value: false},
		{Name: "Temperature", Alias: 100, DataType: uint32(10), Value: 21.5},
	})
	fmt.Printf("	{\"NBIRTH_V1\", \"%s\", \"Basic node birth with temperature\", \"NBIRTH\", 3},\n",
		b64(nbirth))

	// NDATA with temperature update
	ndata := createNData(1, []Metric{
		{Alias: 100, DataType: uint32(10), Value: 22.5},
	})
	fmt.Printf("	{\"NDATA_V1\", \"%s\", \"Temperature update by alias\", \"NDATA\", 1},\n",
		b64(ndata))

	// NDEATH
	ndeath := createNDeath([]Metric{
		{Name: "bdSeq", DataType: uint32(8), Value: uint64(0)},
	})
	fmt.Printf("	{\"NDEATH_V1\", \"%s\", \"Node death certificate\", \"NDEATH\", 1},\n",
		b64(ndeath))
}

func generateEdgeCaseVectors() {
	fmt.Println("	// Edge case vectors - boundary conditions and error cases")

	// Sequence gap
	ndataGap := createNData(5, []Metric{
		{Alias: 100, DataType: uint32(10), Value: 27.0},
	})
	fmt.Printf("	{\"NDATA_GAP\", \"%s\", \"Sequence gap 1→5\", \"NDATA\", 1},\n",
		b64(ndataGap))

	// Pre-birth data
	ndataPreBirth := createNData(1, []Metric{
		{Alias: 100, DataType: uint32(10), Value: 25.0},
	})
	fmt.Printf("	{\"NDATA_BEFORE_BIRTH\", \"%s\", \"Data without birth context\", \"NDATA\", 1},\n",
		b64(ndataPreBirth))

	// Sequence wraparound
	ndataWrap := createNData(0, []Metric{
		{Alias: 100, DataType: uint32(10), Value: 30.0},
	})
	fmt.Printf("	{\"NDATA_WRAPAROUND\", \"%s\", \"Sequence wraparound 255→0\", \"NDATA\", 1},\n",
		b64(ndataWrap))
}

func generatePerformanceVectors() {
	fmt.Println("	// Performance test vectors - large payloads")

	// Large NBIRTH with many metrics
	var metrics []Metric
	metrics = append(metrics, Metric{Name: "bdSeq", Alias: 1, DataType: uint32(8), Value: uint64(88)})
	metrics = append(metrics, Metric{Name: "Node Control/Rebirth", Alias: 2, DataType: uint32(11), Value: false})

	for i := 1; i <= 100; i++ {
		metrics = append(metrics, Metric{
			Name:     fmt.Sprintf("Metric_%d", i),
			Alias:    uint64(i),
			DataType: uint32(10),
			Value:    float64(i) * 1.5,
		})
	}

	largeNBirth := createNBirth(0, metrics)
	fmt.Printf("	{\"NBIRTH_LARGE\", \"%s\", \"Large NBIRTH with 100+ metrics\", \"NBIRTH\", %d},\n",
		b64(largeNBirth), len(metrics))
}

// Metric helper struct
type Metric struct {
	Name     string
	Alias    uint64
	DataType uint32
	Value    interface{}
}

func createNBirth(seq uint64, metrics []Metric) []byte {
	timestamp := uint64(time.Now().UnixMilli())
	payload := &sparkplugb.Payload{
		Timestamp: &timestamp,
		Seq:       &seq,
		Metrics:   make([]*sparkplugb.Payload_Metric, len(metrics)),
	}

	for i, metric := range metrics {
		payload.Metrics[i] = createProtoMetric(metric, true) // Include names in birth
	}

	data, err := proto.Marshal(payload)
	if err != nil {
		log.Fatalf("Failed to marshal NBIRTH: %v", err)
	}
	return data
}

func createNData(seq uint64, metrics []Metric) []byte {
	timestamp := uint64(time.Now().UnixMilli())
	payload := &sparkplugb.Payload{
		Timestamp: &timestamp,
		Seq:       &seq,
		Metrics:   make([]*sparkplugb.Payload_Metric, len(metrics)),
	}

	for i, metric := range metrics {
		payload.Metrics[i] = createProtoMetric(metric, false) // Aliases only in data
	}

	data, err := proto.Marshal(payload)
	if err != nil {
		log.Fatalf("Failed to marshal NDATA: %v", err)
	}
	return data
}

func createNDeath(metrics []Metric) []byte {
	timestamp := uint64(time.Now().UnixMilli())
	seq := uint64(0) // Death messages reset sequence
	payload := &sparkplugb.Payload{
		Timestamp: &timestamp,
		Seq:       &seq,
		Metrics:   make([]*sparkplugb.Payload_Metric, len(metrics)),
	}

	for i, metric := range metrics {
		payload.Metrics[i] = createProtoMetric(metric, true) // Include names in death
	}

	data, err := proto.Marshal(payload)
	if err != nil {
		log.Fatalf("Failed to marshal NDEATH: %v", err)
	}
	return data
}

func createProtoMetric(metric Metric, includeName bool) *sparkplugb.Payload_Metric {
	datatype := uint32(metric.DataType)
	protoMetric := &sparkplugb.Payload_Metric{
		Datatype: &datatype,
	}

	if includeName && metric.Name != "" {
		protoMetric.Name = &metric.Name
	}

	// Always set alias for metrics that have one defined
	protoMetric.Alias = &metric.Alias

	// Set value based on type
	switch v := metric.Value.(type) {
	case bool:
		protoMetric.Value = &sparkplugb.Payload_Metric_BooleanValue{BooleanValue: v}
	case uint64:
		protoMetric.Value = &sparkplugb.Payload_Metric_LongValue{LongValue: v}
	case float64:
		protoMetric.Value = &sparkplugb.Payload_Metric_DoubleValue{DoubleValue: v}
	case string:
		protoMetric.Value = &sparkplugb.Payload_Metric_StringValue{StringValue: v}
	default:
		log.Fatalf("Unsupported metric value type: %T", v)
	}

	return protoMetric
}

func b64(data []byte) string {
	return base64.StdEncoding.EncodeToString(data)
}
