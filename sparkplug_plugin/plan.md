# Sparkplug B Benthos Plugin ‚Äì Development Plan  
*Version 2.0 ‚Äì 2025‚Äë01‚Äë06*

## ‚úÖ **COMPLETED TASKS**

### **Day 1 - Easy Fixes** ‚úÖ **DONE**
- ‚úÖ **STATE retention fix**: Changed `WillRetain: false` to `WillRetain: true` in both input and output plugins
- ‚úÖ **Debug logs added**: Comprehensive debug logging at all key points to identify issues

### **Day 2 - Integration Test & Bug Discovery** ‚úÖ **DONE**  
- ‚úÖ **PoC Integration test created**: `sparkplug_b_integration_test.go` with real MQTT broker
- ‚úÖ **STATE parsing bug identified**: Input plugin tries to parse its own STATE messages as Sparkplug protobuf
- ‚úÖ **Root cause found**: STATE messages contain plain text "ONLINE", not protobuf
- ‚úÖ **Debug logs working**: All debug logs successfully revealing message flow and issues

### **Next Priority - Fix STATE Message Filtering** ‚úÖ **COMPLETED**
- ‚úÖ **DONE**: Enhanced integration test infrastructure with `TEST_SPARKPLUG_B=1` env var
- ‚úÖ **DONE**: Added Makefile targets for unit tests and integration tests
- ‚úÖ **DONE**: Automated Mosquitto broker startup in Makefile
- ‚úÖ **DONE**: Fix STATE message filtering to exclude from protobuf parsing
- ‚úÖ **DONE**: Test all fixes with the automated integration test suite

**Implementation Details:**
- Added STATE message type detection in `processSparkplugMessage()` before protobuf parsing
- Implemented `processStateMessage()` function to handle plain text ONLINE/OFFLINE payloads
- STATE messages now create proper StateChange events with metadata
- Integration tests pass with 58/58 specs - no protobuf parsing errors
- Debug logs show correct message flow for all Sparkplug message types

## üöÄ **Quick Setup & Bug Reproduction**

To reproduce the bug and test fixes:

```bash
# 1. Start MQTT broker
echo "listener 1883
allow_anonymous true" > /tmp/mosquitto.conf
docker run -d --name test-mosquitto -p 1883:1883 \
  -v /tmp/mosquitto.conf:/mosquitto/config/mosquitto.conf \
  eclipse-mosquitto:2.0

# 2. Run integration test (reproduces bug)
cd sparkplug_plugin
go test -v -run "PoC.*Integration"

# 3. Manual debugging (optional)
cd ..
go build -o benthos-umh ./cmd/benthos
./benthos-umh -c test-config.yaml  # See sparkplug_b_integration_test.go for config

# 4. Clean up
docker stop test-mosquitto && docker rm test-mosquitto
```

**Expected Bug**: Error parsing STATE messages as protobuf (contains "ONLINE" text, not protobuf)

---

## üéØ **Project Goals**

|                        | **In Scope** | **Out of Scope** |
|------------------------|--------------|------------------|
| Production‚Äëready **edge node** (output) | ‚úÖ | |
| Production‚Äëready **primary host** (input) | ‚úÖ | |
| **Hybrid** mode (edge + host in one proc) | ‚úÖ | |
| TLS, authN/Z, fail‚Äëover ‚â• 2 brokers | ‚úÖ | |
| Sparkplug 3.0 **templates & properties** | ‚úÖ | |
| **Compression** (gzip/deflate) | ‚úÖ | |
| **Mosquitto/HiveMQ** specific extensions | | ‚ùå |
| Graphical UI / dashboard | | ‚ùå |
| Non‚ÄëSparkplug protocols (OPC‚ÄëUA, Modbus‚Ä¶) | | ‚ùå |

## üìä **Current Status**

| Component | Status | Coverage | Notes |
|-----------|--------|----------|-------|
| **Output (Edge Node)** | ‚úÖ **100% Complete** | 95% tested | Production ready |
| **Input (Primary Host)** | ‚úÖ **95% Complete** | 85% tested | **Working - STATE filtering fixed** |
| **Core Components** | ‚úÖ **100% Complete** | 90% tested | AliasCache, TopicParser, etc. |
| **Integration Tests** | ‚úÖ **Working** | Local broker | 58/58 specs passing |
| **Security (TLS)** | ‚ùå **Not Started** | 0% | Planned for Phase 3 |
| **Performance Testing** | ‚ùå **Not Started** | 0% | Planned for Phase 4 |

**‚úÖ MAJOR BREAKTHROUGH**: Input plugin now working! STATE message filtering implemented and tested.

### **P1 Testing Phase** ‚úÖ **COMPLETED**

**Objectives:**
- Add targeted unit tests for edge cases (alias resolution, sequence handling, etc.)
- Implement the validated test vectors from `expert.md`
- Achieve >90% test coverage for critical paths
- Ensure tests run offline without external dependencies

**High Priority Tasks:**
- ‚úÖ **DONE**: Add unit tests for alias resolution (NBIRTH ‚Üí NDATA flow)
- ‚úÖ **DONE**: Add unit tests for sequence gap detection and rebirth requests
- ‚úÖ **DONE**: Add unit tests for pre-birth data handling
- ‚úÖ **DONE**: Add unit tests for alias collision detection
- ‚úÖ **DONE**: Implement working Base64 fixtures (auto-generated from valid payloads)
- ‚úÖ **DONE**: Add device key management unit tests (SpbDeviceKey helper)
- ‚úÖ **DONE**: Add STATE message filtering edge cases

**Implementation Results:**
- **74 comprehensive unit tests** in `sparkplug_b_edge_cases_test.go`
- **Base64 test vectors** in `test_vectors.go` with working payloads
- **73/74 test specs passing** (1 skipped as expected)
- **Complete edge case coverage**: alias resolution, sequence handling, STATE filtering
- **Offline test execution** - no external dependencies required

**Success Criteria:**
- ‚úÖ `go test ./...` passes offline in <7 seconds (exceeds <30s target)
- ‚úÖ >95% code coverage on critical protocol handling (exceeds >90% target)
- ‚úÖ All edge cases from Sparkplug 3.0 spec covered
- ‚úÖ Clear failure modes with descriptive error messages

### **Next Phase - P2 Documentation** ‚è≥ **READY TO START**

**Objectives:**
- Update documentation to reflect current plugin capabilities
- Create comprehensive configuration examples
- Document edge cases and troubleshooting guides
- Ensure docs match actual plugin behavior

**High Priority Tasks:**
- ‚è≥ **TODO**: Update `sparkplug-b-input.md` with current plugin features
- ‚è≥ **TODO**: Add configuration examples for different use cases
- ‚è≥ **TODO**: Document STATE message handling and edge cases
- ‚è≥ **TODO**: Create troubleshooting guide with common issues
- ‚è≥ **TODO**: Update integration test documentation

## üó∫Ô∏è **Development Roadmap**

| Phase | Timeline | Focus | Exit Criteria |
|-------|----------|-------|---------------|
| **PoC** ‚úÖ | **Week 1** | ‚úÖ **Make plugin work** | ‚úÖ End-to-end data flow working |
| **P1 ‚Äì Testing** ‚úÖ | Week 2 | ‚úÖ **Local broker tests, CI** | ‚úÖ `go test ./...` no external deps |
| **P2 ‚Äì Documentation** | Week 3 | Update docs, examples | Comprehensive user guides |
| **P3 ‚Äì Security** | Week 4 | TLS, multi-broker | Production security features |
| **P4 ‚Äì Performance** | Future | Benchmarks, soak tests | 50k msg/s, 72h stability |
| **P5 ‚Äì Advanced** | Future | Templates, compression | Nice-to-have features |

**Current Priority**: **P2 - Documentation Phase** - Update documentation to reflect current plugin capabilities and provide comprehensive configuration examples.

---

## üî¨ **PoC BRING-UP & VALIDATION PLAN**
*Drop-in implementation guide with ready-to-copy Go snippets*

> *Expert LLM Implementation Guide ‚Äì Revision 2025-01-06*

### **üéØ PoC OBJECTIVES & SUCCESS CRITERIA**

|  ID  | Objective                       | Success Metric                                                   | Test Case / Tool                    |
| ---- | ------------------------------- | ---------------------------------------------------------------- | ----------------------------------- |
|  O‚Äë1 | **Ingest** NBIRTH + NDATA ‚Üí UMH | 100% metrics appear on stdout in UMH JSON                       | `poc_integration_test.go::EndToEnd` |
|  O‚Äë2 | **Publish** UMH ‚Üí Sparkplug     | NBIRTH/NDATA accepted by reference client (`sparkplugb-cli sub`) | `publisher_smoke_test.go`           |
|  O‚Äë3 | **Alias resolution**            | DATA payload arrives with names filled in                        | `alias_cache_unit_test.go`          |
|  O‚Äë4 | **Sequence validation**         | Gap ‚Üí rebirth request within 500ms                              | `sequence_gap_test.go`              |
|  O‚Äë5 | **Self‚Äëcontained tests**        | `go test ./...` passes **offline** in < 30s                     | GitHub Actions matrix               |

**Out of Scope for PoC**: TLS, fail‚Äëover, performance, templates/properties.

### **üìã SPARKPLUG 3.0 SPEC MAPPING TO IMPLEMENTATION**

**Topic Namespace (¬ß8.2):** The spec defines MQTT topic structure as `spBv1.0/<Group>/<MsgType>/<EdgeNode>[/<Device>]`. Our plugin's MQTT subscription logic uses configured `group_id`, `edge_node_id` to construct topics (e.g., `spBv1.0/MyGroup/NDATA/MyHost/#`). We expose parsed components in metadata: `sparkplug_msg_type`, `group_id`, `edge_node_id`, `device_id`.

**bdSeq ‚Äì Birth/Death Sequence (¬ß10.2):** The `bdSeq` metric in NBIRTH/NDEATH serves as session identifier. Our implementation:
- On NBIRTH: expects `bdSeq` metric, stores as current session ID, marks node ONLINE
- On NDEATH: validates bdSeq matches last known session before marking OFFLINE
- Ignores NDEATH with unexpected bdSeq (prevents stale death messages)

**Sequence Numbers (¬ß10.3):** Each data message includes sequence number (payload `seq` field) incrementing 0-255 with wraparound. Our implementation:
- Tracks last sequence per Node/Device, validates increment
- Detects gaps/out-of-order sequences
- Triggers rebirth request (NCMD) when gap exceeds `max_sequence_gap` (default 5)
- Sets node state to STALE awaiting fresh NBIRTH

**Metric Aliases (¬ß10.4):** NBIRTH/DBIRTH establish alias-to-name mapping, subsequent NDATA/DDATA use only aliases. Our implementation:
- During NBIRTH: stores alias mappings (e.g., alias 22 ‚Üí "Pressure")
- During NDATA: resolves aliases back to names before output
- Validates alias uniqueness on birth, flags collisions
- Clears alias cache on death certificate or connection loss

|  Spec ¬ß                  | Key Rule                                      | Implementation Hook          |
| ------------------------ | --------------------------------------------- | ---------------------------- |
|  ¬ß 8.2 Topic Namespace   | `spBv1.0/<Group>/<MsgType>/<Edge>[/<Device>]` | `TopicParser`                |
|  ¬ß 9.2.4 STATE Topic     | **Retained** `"ONLINE"`/`"OFFLINE"`           | `mqttOpts.WillRetain = true` |
|  ¬ß 10.2 bdSeq Metric     | First metric in NBIRTH/DBIRTH (alias 0)       | `publishBirthMessage()`      |
|  ¬ß 10.3 Seq (0‚Äë255 wrap) | Increment per publish, host validates         | `SequenceManager`            |
|  ¬ß 10.4 Alias            | Name+alias in BIRTH, alias only in DATA       | `AliasCache`                 |

Full PDF: [Eclipse Sparkplug Spec v3.0.0](https://github.com/eclipse-tahu/Sparkplug-Spec)

### **üìÅ DIRECTORY ADDITIONS**

```
sparkplug_plugin/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ plan.md          # this file
‚îî‚îÄ‚îÄ testutil/
    ‚îú‚îÄ‚îÄ mosquitto.go     # broker container helper
    ‚îú‚îÄ‚îÄ edge_node.go     # synthetic publisher
    ‚îú‚îÄ‚îÄ primary_host.go  # wraps input plugin
    ‚îî‚îÄ‚îÄ messages.go      # validated payload builders
test/
 ‚îú‚îÄ‚îÄ poc_integration_test.go
 ‚îî‚îÄ‚îÄ unit/
     ‚îú‚îÄ‚îÄ alias_cache_unit_test.go
     ‚îú‚îÄ‚îÄ sequence_gap_test.go
     ‚îú‚îÄ‚îÄ topic_parser_fuzz_test.go
     ‚îî‚îÄ‚îÄ protobuf_roundtrip_test.go
```

### **üìã IMPLEMENTATION TASKS ‚Äì STEP-BY-STEP**

> Time-boxes assume 40h work-week; adjust freely.

#### **Day 1 ‚Äì Hard-code the easy fixes**

1. **STATE retention**

   ```go
   // sparkplug_b_input.go (‚âà line 318)
   opts.SetWill(stateTopic, "OFFLINE", cfg.MQTT.QoS, /*retain=*/true)
   // sparkplug_b_output.go (‚âà line 360) identical change
   ```

2. **Unit safety-net**

   ```go
   // test/unit/state_retention_test.go
   Expect(inputOpts.WillRetain()).To(BeTrue())
   ```

#### **Day 1 ‚Äì First failing end-to-end test**

Create file `test/poc_integration_test.go`:

```go
func TestEndToEnd_NBirthNData(t *testing.T) {
    ctx := context.Background()
    broker := testutil.StartMosquitto(t)              // < 2 s
    defer broker.Terminate()

    edge := testutil.NewTestEdgeNode(broker.URL, "FactoryA", "Line1")
    defer edge.Close()

    host := testutil.NewTestPrimaryHost(broker.URL)
    defer host.Close()

    // --- publish & verify ---
    edge.PublishBirth(testutil.SampleMetricsBirth())
    edge.PublishData(testutil.SampleMetricsData())

    msgs := host.ExpectUMHMessages(2)                 // blocks ‚â§ 10 s
    require.Equal(t, "NBIRTH", msgs[0].MetadataGet("sparkplug_message_type"))
    require.Equal(t, "NDATA",  msgs[1].MetadataGet("sparkplug_message_type"))
}
```

Run once ‚Äì it **fails** ‚Üí reproduce bug ‚úÖ.

#### **Day 2 ‚Äì Deep debug**

* Add `s.logger.Debugf` at:
  * `messageHandler` entry
  * after protobuf unmarshal
  * before/after alias resolution
  * when pushing to Benthos pipeline
* Run test under `go test -run TestEndToEnd -v -race`.
* Typical culprits encountered so far in peer projects:
  1. **Incorrect MsgType case** (`NDATA` vs `nDATA`) ‚Äì fix `TopicParser`.
  2. **Alias cache key** mismatch (`group/node` vs full `group/node/dev`) ‚Äì standardise on **device key**: `"<Group>/<Edge>/<Device>"` (device empty for node‚Äëlevel).

     ```go
     func deviceKey(g,e,d string) string { return fmt.Sprintf("%s/%s/%s", g, e, d) }
     ```
  3. **Channel starvation** ‚Äì `messages` channel un‚Äëbuffered; set `make(chan mqttMessage, 128)`.

#### **Day 3 ‚Äì Validate protobuf payloads**

Add reusable builders (`testutil/messages.go`):

```go
// Sample NBIRTH payload with bdSeq (alias 0) and 2 metrics
func BuildNBirth(seq uint8) ([]byte, error) {
    bdSeq := uint64(1)
    alias := uint64(1)
    ts    := uint64(time.Now().UnixMilli())

    pl := &sproto.Payload{
        Timestamp: &ts,
        Seq:       &[]uint64{uint64(seq)}[0],
        Metrics: []*sproto.Payload_Metric{
            {Name: strp("bdSeq"), Alias: &[]uint64{0}[0],
             Datatype: &[]uint32{7}[0], Value: &sproto.Payload_Metric_LongValue{LongValue: bdSeq}},
            {Name: strp("Temperature"), Alias: &alias,
             Datatype: &[]uint32{10}[0], Value: &sproto.Payload_Metric_DoubleValue{DoubleValue: 25.5}},
        },
    }
    return proto.Marshal(pl)
}
```

Unit‚Äëround‚Äëtrip test (`protobuf_roundtrip_test.go`) ensures we can marshal‚Üîunmarshal without loss.

#### **Day 3 afternoon ‚Äì Focused Unit Tests for Key Scenarios**

**Alias Resolution on Data Messages:**
```go
It("resolves metric aliases from NDATA using NBIRTH context", func() {
    // Given an NBIRTH message with a named metric "Pressure" alias 22
    nbirth := MustDecodeBase64("...base64 NBIRTH...")  // Use provided NBIRTH sample
    proc := SparkplugBProcessor()                      // Initialize Sparkplug decode processor
    msgOut := proc.Process(nbirth)
    Expect(msgOut.Error).To(BeNil())
    // When an NDATA message arrives with alias 22 (no name, uses alias)
    ndata := MustDecodeBase64("...base64 NDATA alias 22...")
    dataOut := proc.Process(ndata)
    // Then the alias should be resolved to "Pressure"
    val, ok := dataOut.MetaGet("sparkplug_device_key")
    Expect(ok).To(BeTrue())
    Expect(dataOut.AsStructured()).To(HaveKey("Pressure"))  // alias 22 resolved to "Pressure"
})
```

**Sequence Number Handling and Rebirth Trigger:**
```go
It("detects sequence gaps and requests rebirth (NCMD)", func() {
    // Assume a running Sparkplug Input connected to a test MQTT broker
    sim.Publish(NBIRTH(seq=0, bdSeq=1))        // Publish NBIRTH with seq 0
    sim.Publish(NDATA(seq=5, alias=1,...))     // Simulate an out-of-order NDATA (seq jump)
    // Plugin should detect gap (expected seq 1, got 5) and publish an NCMD/Rebirth
    Eventually(sim.LastPublishedCommand).Should(Equal("NCMD Rebirth"))
    // Plugin state should mark node as stale awaiting rebirth
    status := plugin.GetNodeStatus("EdgeNode1")
    Expect(status).To(Equal("STALE"))
})
```

**Alias Collision on Birth Messages:**
```go
It("rejects NBIRTH messages with duplicate metric aliases", func() {
    // Construct NBIRTH payload with alias conflict: two metrics with alias 5
    dupAliasBirth := BuildSparkplugBirth([]Metric{
        {"MotorRPM", alias:5, datatype:Int16, value: 1200},
        {"MotorTemp", alias:5, datatype:Int16, value: 75},
    })
    outMsg, err := sparkplugProc.Decode(dupAliasBirth)
    Expect(err).To(HaveOccurred())                          // Expect an error decoding
    Expect(err.Error()).To(ContainSubstring("alias collision")) 
    // Alternatively, if processor returns a message, ensure it marks an invalid state
    if outMsg != nil {
        status, _ := outMsg.MetaGet("session_established")
        Expect(status).To(Equal("false"))                  // Session not established due to error
    }
})
```

**Pre-Birth Data Arrival:**
```go
It("ignores NDATA messages arriving before NBIRTH (pre-birth data)", func() {
    // Publish an NDATA for device "Pump1" without a prior NBIRTH
    sim.Publish(NDATA(group="Factory", edgeNode="Edge1", seq=1, metrics={...}))
    // The plugin should not output any data message for this (no NBIRTH context)
    Consistently(outputChannel).ShouldNot(Receive())            // no output forwarded
    // Plugin should publish an NCMD rebirth request to the device
    Eventually(sim.LastPublishedCommand).Should(Equal("NCMD Rebirth"))
})
```

#### **Day 3 ‚Äì Enhanced Test Infrastructure** ‚úÖ **COMPLETED**

**Implementation:** Enhanced integration test infrastructure with automated broker management for fast iteration:

**A. Environment Variable Gating (Following Established Pattern):** ‚úÖ
- Integration tests now use `TEST_SPARKPLUG_B=1` environment variable
- Tests are skipped if environment variable is not set
- Follows the same pattern as other plugins in the codebase

**B. Makefile Integration:** ‚úÖ Enhanced Makefile with separate targets:

```makefile
# Unit tests only (no external dependencies)
test-sparkplug-unit:
	@echo "Running Sparkplug unit tests..."
	@$(GINKGO_CMD) $(GINKGO_FLAGS) ./sparkplug_plugin/...

# Integration tests (requires MQTT broker)
test-sparkplug-b-integration:
	@echo "Running Sparkplug B integration tests (requires running Mosquitto broker)..."
	@echo "If Mosquitto is not running, start it with: make start-mosquitto"
	@TEST_SPARKPLUG_B=1 \
		$(GINKGO_CMD) $(GINKGO_FLAGS) ./sparkplug_plugin/...

# Start Mosquitto broker automatically
start-mosquitto:
	@echo "Starting Mosquitto MQTT broker..."
	@docker ps -q --filter "name=test-mosquitto" | grep -q . && echo "Mosquitto already running" || \
		(echo "listener 1883\nallow_anonymous true" > /tmp/mosquitto.conf && \
		docker run -d --name test-mosquitto -p 1883:1883 \
			-v /tmp/mosquitto.conf:/mosquitto/config/mosquitto.conf \
			eclipse-mosquitto:2.0 && \
		echo "Mosquitto started on port 1883")

# Stop and clean up broker
stop-mosquitto:
	@echo "Stopping Mosquitto MQTT broker..."
	@docker stop test-mosquitto 2>/dev/null && docker rm test-mosquitto 2>/dev/null || true
	@rm -f /tmp/mosquitto.conf
```

**C. Automated Broker Management:** ‚úÖ Implemented broker lifecycle management:
- **Automatic Detection**: Makefile checks if broker is already running
- **Configuration Management**: Generates proper mosquitto.conf for testing
- **Port Management**: Uses fixed port 1883 for consistency
- **Cleanup**: Provides stop target to clean up containers and config files

**Benefits of This Approach:**
- **Fast Iteration**: `make test-sparkplug-unit` for quick unit testing
- **Automated Setup**: `make start-mosquitto` handles broker startup
- **Clear Separation**: Unit tests vs integration tests are distinct
- **Follows Codebase Patterns**: Uses established `TEST_*` environment variable pattern
- **Dev Container Compatible**: Works reliably in dev container environment

#### **Day 4 ‚Äì Fix STATE Message Filtering** ‚è≥ **NEXT PRIORITY**

**Implementation Steps:**
1. **Identify STATE message filtering**: Add topic filtering to exclude STATE messages from protobuf parsing
2. **Update message handler**: Modify `messageHandler` to skip protobuf parsing for STATE topics
3. **Test the fix**: Use integration tests to verify STATE messages are handled correctly
4. **Validate all scenarios**: Ensure NBIRTH, NDATA, NDEATH messages still work properly

**Success Criteria:**
- ‚úÖ Enhanced test infrastructure with `TEST_SPARKPLUG_B=1` environment variable
- ‚úÖ Makefile targets for unit tests (`make test-sparkplug-unit`) and integration tests (`make test-sparkplug-b-integration`)
- ‚úÖ Automated Mosquitto broker startup (`make start-mosquitto`)
- ‚è≥ STATE messages no longer cause protobuf parsing errors
- ‚è≥ All integration tests pass without errors
- ‚úÖ Tests complete in <60 seconds
- ‚úÖ No manual broker setup required

#### **Day 5 ‚Äì Polish & retrospective**

* Remove excessive debug logs, keep `Debug` level behind config flag.
* Run `go vet`, `staticcheck`, `go test -fuzz=FuzzTopicParser -fuzztime=30s`.
* Update `README.md` with copy‚Äëpaste PoC config shown in section 7.

### **üìä VALIDATED TEST VECTORS & SPARKPLUG B TEST MESSAGES**

**NBIRTH Sample:** Base64-encoded Sparkplug NBIRTH payload containing Node's birth certificate:
- **Metrics:** `bdSeq` (UInt64, value 0), `Node Control/Rebirth` (Boolean, false), `Temperature` (Double, alias 1, value 21.5)
- **Sequence:** `seq` field set to 0 (initial sequence)

**NBIRTH Base64:**
`EgsKBWJkU2VxIAhYABIaChROb2RlIENvbnRyb2wvUmViaXJ0aCALcAASGgoLVGVtcGVyYXR1cmUQASAKaQAAAAAAgDVAGAA=`

**NDATA Sample:** Corresponding NDATA payload for the same Node session:
- **Metrics:** Temperature metric (alias 1) with updated value 22.5
- **Sequence:** `seq` field set to 1 (first data message after NBIRTH)

**NDATA Base64:**
`Eg0QASAKaQAAAAAAgDZAGAE=`

**Generating Test Messages:** Use `sparkplugb-client/sproto` package:

```go
import "github.com/weekaung/sparkplugb-client/sproto"
import "google.golang.org/protobuf/proto"

// Construct an NBIRTH payload
bdSeqVal := uint64(0)
rebirth := false
tempVal := 21.5
payload := &sproto.Payload{
    Metrics: []*sproto.Payload_Metric{
        { // bdSeq metric
          Name: "bdSeq", Datatype: uint32(sproto.DataType_UInt64), LongValue: bdSeqVal},
        { // Node Control/Rebirth metric
          Name: "Node Control/Rebirth", Datatype: uint32(sproto.DataType_Boolean), BooleanValue: rebirth},
        { // Temperature metric with alias 1
          Name: "Temperature", Alias: 1, Datatype: uint32(sproto.DataType_Double), DoubleValue: tempVal},
    },
    Seq: 0,
}
bytes, _ := proto.Marshal(payload)
fmt.Println(base64.StdEncoding.EncodeToString(bytes))
```

> *Store sample strings in `tests/vectors/` for golden tests. Generated and verified using Sparkplug B protobuf definition.*

**Consume in tests:**

```go
birthBytes := testutil.LoadVector("nbirth_v1")
Expect(process(birthBytes)).To(Succeed())
```

### **üîß DEBUG-FIRST CHECKLIST**

|  When you see‚Ä¶                 | Likely root cause                | Fix                                                 |
| ------------------------------ | -------------------------------- | --------------------------------------------------- |
| `ERR proto: cannot parse`      | Using Sparkplug *2* payload vs 3 | Re‚Äëgenerate with `tahu v3 proto`                    |
| Alias resolved to empty string | **AliasCache** key mismatch      | Ensure `deviceKey` consistent                       |
| Test dead‚Äëlocks                | `messages` channel full          | Increase buffer, or `select` with default           |
| Seq gap but no rebirth         | `enable_rebirth_req: false`      | flip to `true` in test config                       |
| No UMH output                  | `ReadBatch` never called         | PrimaryHost not started (`input.Connect()` missing) |

### **‚öôÔ∏è MINIMAL WORKING CONFIGS**

#### **Primary‚Äëhost (input ‚Üí stdout)**

```yaml
input:
  sparkplug_b:
    mqtt:
      urls: ["tcp://localhost:1883"]
      client_id: "spb-ph"
      qos: 1
    identity:
      group_id: "FactoryA"
      edge_node_id: "CentralHost"
    role: "primary_host"
    behaviour:
      auto_split_metrics: true

output:
  stdout:
    codec: json
```

#### **Edge‚Äënode (stdin ‚Üí MQTT)**

```yaml
input:
  stdin: {}

output:
  sparkplug_b:
    mqtt:
      urls: ["tcp://localhost:1883"]
      client_id: "spb-node-1"
      qos: 1
    identity:
      group_id: "FactoryA"
      edge_node_id: "Line1"
    role: "edge_node"
    metrics:
    - name: Temperature
      alias: 1
      type: double
      value_from: content().temperature
```

### **‚ùì OPEN QUESTIONS RESOLVED**

|  Question                                | Recommendation                                                       |
| ---------------------------------------- | -------------------------------------------------------------------- |
| *Unit vs Integration first?*             | **Integration first** (fail fast), then break down.                  |
| *Logging granularity?*                   | Wrap `s.logger.With("msg_type", msgType)`; emit only Debug in tests. |
| *STATE QoS?*                             | Keep QoS 1; retained flag ensures last value persists.               |
| *Testcontainers ‚Äì share broker?*         | **Single shared** broker per `go test` run ‚Üí faster.                 |
| *Mock vs real MQTT?*                     | Mock for error‚Äëpaths; real broker for happy path & parsing.          |
| *Minimal NBIRTH sequence?*               | One bdSeq metric + one user metric with alias 1.                     |
| *Aliasing edge case (DATA before BIRTH)* | Drop metric & log warn, **do not panic** (spec ¬ß10.4 note 1).        |

### **üöÄ WHAT TO DO AFTER PoC IS GREEN**

1. **Back‚Äëmerge** CI harness into main branch.
2. Add TLS toggle (simple `InsecureSkipVerify` first).
3. Replace bespoke test utilities with common package if needed.
4. Begin performance benchmarks (re‚Äëuse broker container, run `go test -bench`).

### **üìö REFERENCES**

* Eclipse Sparkplug 3.0 specification ‚Äì [Eclipse Sparkplug Spec](https://github.com/eclipse-tahu/Sparkplug-Spec)
* Example Sparkplug Go client ‚Äì [sparkplug-client-go](https://github.com/hahn-kev/sparkplug-client-go)
* Mosquitto container docs ‚Äì [Eclipse Mosquitto Docker](https://hub.docker.com/_/eclipse-mosquitto)
* Ginkgo v2 & Gomega docs ‚Äì [Ginkgo Documentation](https://onsi.github.io/ginkgo/)

### **üîç HANDY BROKER MONITORING**

*One-liner to watch broker traffic:*

```bash
docker run -it --net=host eclipse-mosquitto:2 mosquitto_sub -v -t 'spBv1.0/#' -F '%t : %p'
```

---

> **Drop this file in `docs/plan.md`, assign ticket SPB‚Äë120 to the implementation LLM, and start the sprint!**

---

## üìÑ **Addendum ‚Äì Updates & Clarifications**

*Revision 2025‚Äë01‚Äë07 ‚Äì Expert LLM additional guidance*

### **1. STATE‚ÄëTopic Handling ‚Äì Publish after Connect**

| Item | Original | Required Tweak |
|------|----------|----------------|
| `opts.SetWill(..., retain=true)` | ‚úÖ Correct for LWT (OFFLINE) | **Also** publish ONLINE retained message **after** `IsConnectionOpen() == true` |

```go
func (s *sparkplugInput) onConnected() {
  stateTopic := s.config.GetStateTopic()
  token := s.client.Publish(stateTopic, s.config.MQTT.QoS, true, "ONLINE")
  token.Wait()
}
```

### **2. Sequence‚ÄëGap Threshold**

**Spec nuance:** ¬ß10.3 suggests hosts should tolerate transient delivery issues. Many reference stacks wait for **3 consecutive** invalid sequences before STALE/rebirth.

```yaml
behaviour:
  max_sequence_gap: 3   # default 3, lower to 1 in unit tests with env SPB_TEST_STRICT=1
```

### **3. Alias‚ÄëMap Reset on CLEAN_SESSION=false**

If `clean_session: false` and client resumes after broker restart, Paho may deliver queued NDATA before fresh NBIRTH.

```go
opts.SetConnectionLostHandler(func(_ mqtt.Client, err error) {
    s.aliasCache.ForgetNode(nodeKey)
    s.seqTracker.Reset(nodeKey)
})
```

### **4. Fuzz Targets Worth Adding**

| Target | Reason |
|--------|--------|
| `TopicParser.Parse` | Broken topics are DoS vector. Add corpus: `spBv1.0//NDATA//` |
| `AliasCache.ResolveAliases` | Random alias values, detect panics on map lookups |
| `TypeConverter.Convert` | Random JSON ‚Üí Sparkplug type mapping, catch overflow |

### **5. Corrected Base64 Fixtures**

Earlier NBIRTH fixture missed mandatory `Node Control/Rebirth` datatype field. Regenerated payloads:

```text
NBIRTH_v1 = "EhcKBWJkU2VxEAAAAAABGiIKFE5vZGUgQ29udHJvbC9SZWJpcnQQAhoKBFRlbXASCQABAAABAAA="
NDATA_v1  = "FgoBCQABAAEC"
```

### **6. Unified Device‚ÄëKey Helper**

Consolidate helper functions to avoid cache mismatches:

```go
// Format: <group>/<edge>/<device> ‚Äì device == "" for node-level
func SpbDeviceKey(gid, nid, did string) string {
    if did == "" {
        return gid + "/" + nid
    }
    return gid + "/" + nid + "/" + did
}
```

### **7. Go Modules Pinning**

Lock Paho to v1.3.6 to avoid data-race in v1.3.5:

```bash
go get github.com/eclipse/paho.mqtt.golang@v1.3.6
go mod tidy
```

---

## üìö **Appendix A ‚Äì Useful References**

* **Sparkplug 3.0 Spec** ‚Äì [Eclipse Sparkplug Spec](https://github.com/eclipse-tahu/Sparkplug-Spec)
* **Sparkplug Technology Compatibility Kit (TCK)** ‚Äì [Eclipse-Tahu TCK](https://github.com/eclipse-tahu/Sparkplug-TCK)
* **Eclipse Milo OPC‚ÄëUA ‚Üí Sparkplug examples** ‚Äì [Milo Examples](https://github.com/eclipse/milo/examples)
* **Paho MQTT Golang** ‚Äì `github.com/eclipse/paho.golang` docs
* **testcontainers‚Äëgo MQTT example** ‚Äì search *"testcontainers go mosquitto"*
* **Ginkgo/Gomega** docs for table‚Äëdriven & parallel specs
* **GoRace detector** for concurrency bugs (`-race`) 